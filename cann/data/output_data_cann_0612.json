[
    {
        "id": 142,
        "source_id": "02113175593420797113",
        "title": "编译安装基于CANN的opencv的cannops模块报错",
        "body": "<div class=\"cke-article\"><p style=\"text-align: justify;\">我使用200L DK A2设备编译安装opencv，想要使用其中的cannops模块，出现问题，希望知道如何解决报错，十分感谢！</p>  <p style=\"text-align: justify;\">报错及过程如下：</p>  <ol>  <li style=\"text-align: justify;\"><span><span><span><span>制卡</span></span></span></span>   <p><span class=\"easyimage easyimage-full\"><img alt=\"%E5%9B%BE%E7%89%871.png\" src=\"cid:pic_0\"></span><span><span><span><span>​​​​​​​</span></span></span></span></p>  </li>  <li style=\"text-align: justify;\"><span><span><span><span>安装cann与算子包</span></span></span></span>  <p></p>   <p style=\"text-align: justify;\"><span><span><span><span>使用的toolkit与算子包版本，如下图：</span></span></span></span></p>   <p style=\"text-align: justify;\"><span class=\"easyimage easyimage-full\"><img alt=\"%E5%9B%BE%E7%89%872.png\" src=\"cid:pic_1\"></span></p>   <p style=\"text-align: justify;\"></p>   <p style=\"text-align: justify;\"><span><span><span><span>使用下面的连接安装CANN，安装无报错</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><a href=\"cid:link_1\"><span><span style=\"color: rgb(0,0,255);\"><span style=\"text-decoration: underline;\"><span>cid:link_1</span></span></span></span></a></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>安装算子包之前需要安装NNAE、NNRT</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>按照下面的教程安装上面两个包</span></span></span></span></p>   <p><a href=\"https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/800alpha001/softwareinst/instg/instg_0008.html?Mode=PmIns&amp;OS=Ubuntu&amp;Software=cannToolKit\"><span><span style=\"color: rgb(0,0,255);\"><span style=\"text-decoration: underline;\"><span>https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/800alpha001/softwareinst/instg/instg_0008.html?Mode=PmIns&amp;OS=Ubuntu&amp;Software=cannToolKit</span></span></span></span></a></p>   <p style=\"text-align: justify;\"><span><span><span><span>安装完成，且没有报错，对全部用户生效，并且添加了路径。</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>算子包安装了动态库和静态库。</span></span></span></span></p>  </li>  <li style=\"text-align: justify;\"><span><span><span><span>按照帖子编译opencv</span></span></span></span>  <p></p>   <p style=\"text-align: justify;\"><span><span><a href=\"cid:link_2\"><span><span style=\"color: rgb(0,0,255);\"><span style=\"text-decoration: underline;\"><span>cid:link_2</span></span></span></span></a></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>新建虚拟环境等均正常，并且虚拟环境安装了部分必要的依赖，</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>cmake命令如下：</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>cmake -D CMAKE_BUILD_TYPE=RELEASE \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D CMAKE_INSTALL_PREFIX=$(pwd)/install \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D WITH_DEBUG=0 \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D OPENCV_EXTRA_MODULES_PATH=/root/opencv/opencv_contrib/modules \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D WITH_CUDA=0 \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D WITH_CANN=1 \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D PYTHON3_EXECUTABLE=/usr/local/miniconda3/envs/opencv/bin/python \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D PYTHON_LIBRARY=/usr/local/miniconda3/envs/opencv/lib/libpython3.10.so \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D PYTHON_INCLUDE_DIR=/usr/local/miniconda3/envs/opencv/include/python3.10/ \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D BUILD_opencv_wechat_qrcode=OFF \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D BUILD_opencv_xfeatures2d=OFF \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D BUILD_opencv_face=OFF \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D BUILD_opencv_dnn=OFF \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D BUILD_opencv_features2d=OFF \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D WITH_CAROTENE=OFF \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D WITH_IPP=OFF \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D BUILD_DOCS=ON \\</span></span></span></span></p>   <p style=\"text-align: justify;\"><span><span><span><span>    -D BUILD_EXAMPLES=ON ..</span></span></span></span></p>   <p>​​​​​​​</p>   <p></p>   <p></p>   <p></p>   <p></p>   <p></p>   <p style=\"text-align: justify;\"><span style=\"font-size: 20.0px;\"><span style=\"color: rgb(230,62,60);\"><span style=\"text-decoration: underline;\"><em><strong>Make -j5开始安装，报错如下：</strong></em></span></span></span></p>   <p></p>   <p style=\"text-align: justify;\"><span style=\"font-size: 20.0px;\"><span style=\"color: rgb(230,62,60);\"><span style=\"text-decoration: underline;\"><em><strong>​​​​​​​</strong></em></span></span></span></p>  </li> </ol></div>",
        "url": "https://www.hiascend.com/forum/thread-02113175593420797113-1-1.html",
        "clean_data": "在200L DK A2设备上编译OpenCV 启用WITH CANN 1 时，make  j5阶段报错。已按官方教程安装CANN Community Edition及算子包 动态 静态库均安装 ，且cmake参数配置正常，但未附具体错误日志需进一步核实。",
        "created_at": "2025-02-22T07:57:01+08:00",
        "topic_summary": "昇腾CANN开发者如何解决cmake无法启用WITH_CANN选项的编译问题",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-05T06:52:38+08:00"
    },
    {
        "id": 622,
        "source_id": "20799697",
        "title": "CVE-2022-4779",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-4779](https://nvd.nist.gov/vuln/detail/CVE-2022-4779)\n漏洞归属组件：streamx\n漏洞归属的版本：2.21.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nStreamX applications from versions 6.02.01 to 6.04.34 are affected by a logic bug that allows to bypass the implemented authentication scheme.\nStreamX applications using StreamView HTML component with the public web server feature activated are affected. \n\n漏洞公开时间：2022-12-29 08:15:09\n漏洞创建时间：2025-06-09 21:40:46\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-4779\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDT5D",
        "clean_data": "CVE 2022 4779：StreamX 组件版本2 21 0 在启用公共Web服务器功能的场景中，StreamView HTML组件存在身份验证逻辑缺陷，可能被绕过。参考链接：https   nvd nist gov vuln detail CVE 2022 4779",
        "created_at": "2025-06-09T21:40:46+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T21:40:46+08:00"
    },
    {
        "id": 179,
        "source_id": "0236177061428378064",
        "title": "add算子下载的过程中发现存在samples文件夹导致出错",
        "body": "<div class=\"cke-article\"><p><span class=\"easyimage easyimage-full\"><img alt=\"cke_149.jpeg\" src=\"cid:pic_0\" style=\"width: 1064.0px;height: 479.0px;\"></span></p>  <p>在add算子下载的过程中发现存在samples文件夹导致出错，原因是因为在目录中已经存在了该文件夹名相同的目录导致无法下载，所以需要cd 进入到Downloads中重新下载，运行命令后下载成功</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0236177061428378064-1-1.html",
        "clean_data": "问题复现与解决要点  ：ADD算子下载失败，因当前目录存在 samples 文件夹冲突，需切换至Downloads目录重新下载。",
        "created_at": "2025-03-11T07:43:48+08:00",
        "topic_summary": "开发者在开发中对API使用，数据类型支持，参数格式等方面要求以及复现样例时对样例的适用范围和环境要求不清晰",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-11T07:43:48+08:00"
    },
    {
        "id": 551,
        "source_id": "20772460",
        "title": "triton profile功能补齐output shape、dtype",
        "body": "一、需求场景&价值\ntriton已经支持profiler功能，但是对于生成kernel_detial.csv中output 没有shape、dtype、formats属性\nexample/tutorials/07-profiler.py 可以测试获取profiler文件。",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICD84S",
        "clean_data": "需求：Triton profiler功能需补充output的shape、dtype、formats字段至kernel detail csv   现状：当前profiler生成的CSV文件缺少输出属性信息，参考example tutorials 07 profiler py测试用例   价值：用于精确分析算子输出特征，辅助性能优化和调试",
        "created_at": "2025-06-06T17:28:58+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:39:28+08:00"
    },
    {
        "id": 16,
        "source_id": "19209117",
        "title": "【API】compare API支持tensor与tensor比较",
        "body": "### 该问题是怎么引起的？\n\n\n\n### 重现步骤\n\n\n\n### 报错信息\n\n\n\n\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFPUL",
        "clean_data": "compare API是否支持两个tensor直接进行比较？或需要额外参数配置才能实现？当前文档未明确说明该限制或使用方法。",
        "created_at": "2025-01-05T11:02:49+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-05T11:08:37+08:00"
    },
    {
        "id": 553,
        "source_id": "20777700",
        "title": "案例inference/modelInference/sampleResnetAIPP 没有aipp.cfg配置文件",
        "body": "案例inference/modelInference/sampleResnetAIPP\r\n\r\natc转模型时--insert_op_conf=aipp.cfg,  没有aipp.cfg配置文件",
        "url": "https://gitee.com/ascend/samples/issues/ICDC6C",
        "clean_data": "标题中提到的sampleResnetAIPP案例缺少aipp cfg配置文件，导致ATC转模型时因  insert op conf参数指定的配置文件缺失而报错。需明确说明案例名称与配置文件缺失的具体关联，并说明如何解决该配置文件缺失问题。",
        "created_at": "2025-06-07T15:31:12+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-11T18:19:42+08:00"
    },
    {
        "id": 623,
        "source_id": "20805381",
        "title": "编译部分算子如(roi_ailgn_rotated)行为不符合预期， 错误的代码也能编译通过",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\n我使用bash build.sh -n roi_align_rotated 命令编译roi_align_rotated算子，\r\n当我修改roi_align_rotated/op_kernel下的文件，人为引入错误时，\r\n这个命令依然能够显示编译成功。\r\n\r\n错误样例： roi_align_rotated/op_kernel/roi_align_raotated.cpp\r\n\r\n#include \"roi_align_rotated.h\"\r\n\r\n// extern \"C\" __global__ __aicore__ void roi_align_rotated(\r\n    GM_ADDR input,\r\n    GM_ADDR rois,\r\n    GM_ADDR output,\r\n    GM_ADDR workspace,\r\n    GM_ADDR tiling)\r\n{\r\n    GET_TILING_DATA(tiling_data, tiling);\r\n    // RoiAlignRotated op;\r\n    op.Init(input, rois, output, &tiling_data);\r\n    if (TILING_KEY_IS(1)) {\r\n        op.Process();\r\n    }\r\n}\r\n\r\n\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\n硬件型号 Ascend910B4\r\ncann版本8.2.rc1\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n修改src/objdetect/roi_align_rotated/op_kernel/roi_align_rotated.cpp文件如下\r\n#include \"roi_align_rotated.h\"\r\n\r\n// extern \"C\" __global__ __aicore__ void roi_align_rotated(\r\n    GM_ADDR input,\r\n    GM_ADDR rois,\r\n    GM_ADDR output,\r\n    GM_ADDR workspace,\r\n    GM_ADDR tiling)\r\n{\r\n    GET_TILING_DATA(tiling_data, tiling);\r\n    // RoiAlignRotated op;\r\n    op.Init(input, rois, output, &tiling_data);\r\n    if (TILING_KEY_IS(1)) {\r\n        op.Process();\r\n    }\r\n}\r\n\r\n编译bash build.sh -n roi_align_rotated -c ascendc910b\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\n编译报错，因为引入了明显的语法错误，例如op未经声明就使用，以及核函数声明错误\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\nCRC: 2219593844\r\nSHA256: 9b0c4df7fc51bcc25417a8df66046401df5af33d6704325679af8d398fffce27\r\nSkipping md5sum at user request\r\n\r\nSelf-extractable archive \"CANN-custom_ops--linux.aarch64.run\" successfully created.\r\nCopy /data/h30043849/cann-ops/build/_CPack_Packages/Linux/External/CANN-custom_ops--linux.aarch64.run/CANN-custom_ops--linux.aarch64.run to /data/h30043849/cann-ops/build/\r\nCopy /data/h30043849/cann-ops/build/_CPack_Packages/Linux/External/CANN-custom_ops--linux.aarch64.run/CANN-custom_ops--linux.aarch64.run to /data/h30043849/cann-ops/build_out/\r\nCPack: - package: /data/h30043849/cann-ops/build/CANN-custom_ops--linux.aarch64.run.json generated.\r\nCPack: - package: /data/h30043849/cann-ops/build/CANN-custom_ops--linux.aarch64.run generated.\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/ICDXJ9",
        "clean_data": "编译ROI Align Rotated算子时未识别核函数声明错误及未定义变量，错误代码仍可通过build sh生成自提取包。是否与CANN 8 2 rc1版本编译校验机制相关？",
        "created_at": "2025-06-10T11:31:49+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-10T11:31:49+08:00"
    },
    {
        "id": 106,
        "source_id": "20731111",
        "title": "冗余代码",
        "body": "一、问题现象（附报错日志上下文）：\r\nxxxx\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICCC87",
        "clean_data": "冗余代码",
        "created_at": "2025-06-04T08:16:18+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T08:16:23+08:00"
    },
    {
        "id": 176,
        "source_id": "0201177644078168003",
        "title": "aclnn_online_model是怎么调用的用户算子开发中的shape推导，kernel和函数等接口的",
        "body": "<div class=\"cke-article\">请教一下，aclnn_online_model是怎么调用的shape推导，kernel和函数等接口的？ <p>在用户的界面里只能看到加载模型和推理，我现在想看一下内部是怎么调用的，能指点一下不</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0201177644078168003-1-1.html",
        "clean_data": "问题描述：用户询问aclnn online model在自定义算子开发中shape推导、kernel和函数调用的机制。用户界面仅暴露模型加载与推理接口，但需明确内部如何实现接口绑定和动态调用。",
        "created_at": "2025-03-18T01:34:38+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-18T01:34:38+08:00"
    },
    {
        "id": 69,
        "source_id": "20552937",
        "title": "[Bug-Report|缺陷反馈]: sscal在Atlas 200I DK A2测试泛化性不足，部分shape运行结果精度异常",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\nDescribe the current behavior / 问题描述 (Mandatory / 必填)\r\nsscal算子报错为：/home/trybest/cann-ops/build/binary/ascend310b/src/sscal/sscal.cpp:165:18: error: the ranges of 1st parameter must be [2,6],[10, 10]: pipe barrier(PIPE V),\r\n1 error generated\r\n\r\n\r\n\r\n0-42样例通过测试\r\n-----------------------------下面未通过测试---------------------------------------\r\n============test 43=============\r\n43\r\n{'id': 43, 'shape': [131073, 17, 1, 1, 20], 'alpha': 6.0, 'n': 131073, 'incx': 1, 'dtype': 'fp32', 'inputSize': 44564820}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\nERROR: run case 43 timeout !\r\ncase_43 2025-05-17 17:56:44\r\n\r\n============test 44=============\r\n44\r\n{'id': 44, 'shape': [21, 1, 19, 255, 1, 9, 8, 9], 'alpha': 9.0, 'n': 21, 'incx': 1, 'dtype': 'fp32', 'inputSize': 65930760}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\nERROR: run case 44 timeout !\r\ncase_44 2025-05-17 17:57:23\r\n\r\n============test 45=============\r\n45\r\n{'id': 45, 'shape': [15, 9, 255, 21, 17, 8], 'alpha': 1.0, 'n': 15, 'incx': 1, 'dtype': 'fp32', 'inputSize': 98317800}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\nERROR: run case 45 timeout !\r\ncase_45 2025-05-17 17:58:15\r\n\r\n============test 46=============\r\n46\r\n{'id': 46, 'shape': [1, 7, 15, 16, 17, 15, 20, 16], 'alpha': 7.0, 'n': 1, 'incx': 1, 'dtype': 'fp32', 'inputSize': 137088000}\r\nrun_all.sh: line 67: 190321 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 190560 Killed                  timeout 15 ./execute_sscal_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_46 : 2025-05-17 17:58:38\r\n\r\n============test 47=============\r\n47\r\n{'id': 47, 'shape': [7, 8, 131073, 19], 'alpha': 7.0, 'n': 7, 'incx': 1, 'dtype': 'fp32', 'inputSize': 139461672}\r\nrun_all.sh: line 67: 190577 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 190977 Killed                  timeout 15 ./execute_sscal_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_47 : 2025-05-17 17:59:01\r\n\r\n============test 48=============\r\n48\r\n{'id': 48, 'shape': [9, 17, 21, 20, 19, 15, 1, 8], 'alpha': 2.0, 'n': 9, 'incx': 1, 'dtype': 'fp32', 'inputSize': 146512800}\r\nrun_all.sh: line 67: 190994 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 191397 Killed                  timeout 15 ./execute_sscal_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_48 : 2025-05-17 17:59:26\r\n\r\n============test 49=============\r\n49\r\n{'id': 49, 'shape': [15, 15, 19, 20, 8, 17, 19, 1], 'alpha': 6.0, 'n': 15, 'incx': 1, 'dtype': 'fp32', 'inputSize': 220932000}\r\nrun_all.sh: line 67: 191613 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 191619 Killed                  timeout 15 ./execute_sscal_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_49 : 2025-05-17 17:59:52\r\n\r\nEnd Time 2025-05-17 17:59:52\r\n\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\nAtlas 200I DK A2\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n算子增加.AddConfig后在Atlas 200I DK A2测试；\r\n仅保留src中common以及sscal算子目录，其余算子目录均删除。\r\n因为编译报错，后续测试结果将PIPE_V修改为PIPE_ALL，重新编译运行\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\ncase全部通过测试\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\n![输入图片说明](https://foruda.gitee.com/images/1747477157970863671/c58bd27b_13572081.png \"屏幕截图 2025-05-17 181848.png\")\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/IC8IQX",
        "clean_data": "标题： Bug Report 缺陷反馈   sscal在Atlas 200I DK A2测试泛化性不足，部分shape运行结果精度异常      问题描述  ：   sscal算子在Atlas 200I DK A2上测试时，部分非规则shape输入 如 131073  17  1  1  20 等 出现精度异常和运行失败。具体表现为：   1    编译阶段报错  ： sscal cpp 165 18  error  the ranges of 1st parameter must be  2 6   10  10   pipe barrier PIPE V     2    运行阶段失败  ：case 43 49在执行时均超时或中断 Killed ，部分因input x bin生成失败导致输出结果文件缺失。   3    测试结果不符预期  ：0 42用例通过，43 49用例均未通过。      环境  ：Atlas 200I DK A2     重现步骤  ：修改算子配置后，仅保留sscal算子目录取测试；运行时部分shape用例超时或因资源中断失败。     预期结果  ：所有测试用例均正常通过，无精度异常或运行失败。",
        "created_at": "2025-05-17T18:19:36+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-17T18:19:37+08:00"
    },
    {
        "id": 182,
        "source_id": "0240175252856772078",
        "title": "昇腾对于模型的兼容性",
        "body": "<div class=\"cke-article\">昇腾目前适配QWen模型了么</div>",
        "url": "https://www.hiascend.com/forum/thread-0240175252856772078-1-1.html",
        "clean_data": "昇腾是否支持QWen模型适配",
        "created_at": "2025-02-18T09:20:57+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-18T09:20:57+08:00"
    },
    {
        "id": 21,
        "source_id": "19454610",
        "title": "deepseek MLA",
        "body": "一、需求场景&价值\ndeepseekV3模型参数量巨大，在使用MHA模式的时候，大batch/input_len的数据因为显存问题不能推理，无法推理发挥优势。\n",
        "url": "https://gitee.com/ascend/torchair/issues/IBKZ9U",
        "clean_data": "问题描述：deepseekV3在MHA模式下因显存占用过高无法处理大batch input len推理，需确认MLA模式是否可替代并优化显存效率。",
        "created_at": "2025-02-08T17:52:48+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-08T17:53:00+08:00"
    },
    {
        "id": 19,
        "source_id": "19281132",
        "title": "运行上手代码时报错，显示undefined symbol",
        "body": "一、问题现象（附报错日志上下文）：\r\n运行上手代码时报错，显示undefined symbol\r\n![输入图片说明](https://foruda.gitee.com/images/1736677807419934171/99b70d53_11331675.png \"屏幕截图\")\r\n报错：\r\n\r\n![输入图片说明](https://foruda.gitee.com/images/1736677861438328974/5e5ae1c7_11331675.png \"屏幕截图\")\r\n",
        "url": "https://gitee.com/ascend/torchair/issues/IBH9F0",
        "clean_data": "核心问题：执行代码时出现undefined symbol错误，可能原因：  1  检查动态库路径 LD LIBRARY PATH  2  确认昇腾依赖库版本一致性 3  验证ATC转换参数是否遗漏算子核配置 4  排查CANN版本与驱动兼容性",
        "created_at": "2025-01-12T18:31:07+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-21T18:06:06+08:00"
    },
    {
        "id": 59,
        "source_id": "20435245",
        "title": "优化 PagedMultiLatentAttentionCombineCacheMaskNdKernel 算子 性能",
        "body": "\r\n该场景下（deepseek-r1），cube利用率较低，需要优化\r\n\r\nPagedMultiLatentAttentionCombineCacheMaskNdKernel ，\r\nInput Shapes：  \"1,8,576;905,128,1,576;1,1;;;;;;\" FLOAT16;FLOAT16;INT32;  \r\nOutput Shape： \"1,8,512\" FLOAT16 \r\ncube_utilization(%)：28%\r\n\r\n",
        "url": "https://gitee.com/ascend/ascend-transformer-boost/issues/IC5ZXP",
        "clean_data": "PagedMultiLatentAttentionCombineCacheMaskNdKernel算子在deepseek r1场景下因输入输出维度不匹配 905 128 1 576 1 8 512 导致Cube利用率仅28 。需通过调整维度分块策略、优化INT32型掩码数据处理路径、改进memory访问模式以提升利用率至较高水平。",
        "created_at": "2025-05-07T15:06:35+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-07T15:06:35+08:00"
    },
    {
        "id": 41,
        "source_id": "20311752",
        "title": "check i:0 name:input in size:38400 needsize:102400 not match  ",
        "body": "一、问题现象（附报错日志上下文）：\r\n[ERROR] check i:0 name:input in size:38400 needsize:102400 not match\r\n\r\n[ERROR] check input vector failed ret:-1\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\n这个needsize和input in size是如何计算的，需要查看源代码，然而源代码又臭又长，没有说明如何修改",
        "url": "https://gitee.com/ascend/tools/issues/IC3CNC",
        "clean_data": "CANN模型加载报错：输入尺寸38400与需求尺寸102400不匹配。需明确输入形状计算逻辑并调整，源代码中未提供清晰配置说明，请求解决方案指导。",
        "created_at": "2025-04-23T15:00:24+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-23T15:00:24+08:00"
    },
    {
        "id": 68,
        "source_id": "20552935",
        "title": "[Bug-Report|缺陷反馈]: sscal在Atlas 200I DK A2测试泛化性不足，部分shape运行结果精度异常",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\nDescribe the current behavior / 问题描述 (Mandatory / 必填)\r\nsscal算子报错为：/home/trybest/cann-ops/build/binary/ascend310b/src/sscal/sscal.cpp:165:18: error: the ranges of 1st parameter must be [2,6],[10, 10]: pipe barrier(PIPE V),\r\n1 error generated\r\n\r\n\r\n\r\n0-42样例通过测试\r\n-----------------------------下面未通过测试---------------------------------------\r\n============test 43=============\r\n43\r\n{'id': 43, 'shape': [131073, 17, 1, 1, 20], 'alpha': 6.0, 'n': 131073, 'incx': 1, 'dtype': 'fp32', 'inputSize': 44564820}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\nERROR: run case 43 timeout !\r\ncase_43 2025-05-17 17:56:44\r\n\r\n============test 44=============\r\n44\r\n{'id': 44, 'shape': [21, 1, 19, 255, 1, 9, 8, 9], 'alpha': 9.0, 'n': 21, 'incx': 1, 'dtype': 'fp32', 'inputSize': 65930760}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\nERROR: run case 44 timeout !\r\ncase_44 2025-05-17 17:57:23\r\n\r\n============test 45=============\r\n45\r\n{'id': 45, 'shape': [15, 9, 255, 21, 17, 8], 'alpha': 1.0, 'n': 15, 'incx': 1, 'dtype': 'fp32', 'inputSize': 98317800}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\nERROR: run case 45 timeout !\r\ncase_45 2025-05-17 17:58:15\r\n\r\n============test 46=============\r\n46\r\n{'id': 46, 'shape': [1, 7, 15, 16, 17, 15, 20, 16], 'alpha': 7.0, 'n': 1, 'incx': 1, 'dtype': 'fp32', 'inputSize': 137088000}\r\nrun_all.sh: line 67: 190321 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 190560 Killed                  timeout 15 ./execute_sscal_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_46 : 2025-05-17 17:58:38\r\n\r\n============test 47=============\r\n47\r\n{'id': 47, 'shape': [7, 8, 131073, 19], 'alpha': 7.0, 'n': 7, 'incx': 1, 'dtype': 'fp32', 'inputSize': 139461672}\r\nrun_all.sh: line 67: 190577 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 190977 Killed                  timeout 15 ./execute_sscal_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_47 : 2025-05-17 17:59:01\r\n\r\n============test 48=============\r\n48\r\n{'id': 48, 'shape': [9, 17, 21, 20, 19, 15, 1, 8], 'alpha': 2.0, 'n': 9, 'incx': 1, 'dtype': 'fp32', 'inputSize': 146512800}\r\nrun_all.sh: line 67: 190994 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 191397 Killed                  timeout 15 ./execute_sscal_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_48 : 2025-05-17 17:59:26\r\n\r\n============test 49=============\r\n49\r\n{'id': 49, 'shape': [15, 15, 19, 20, 8, 17, 19, 1], 'alpha': 6.0, 'n': 15, 'incx': 1, 'dtype': 'fp32', 'inputSize': 220932000}\r\nrun_all.sh: line 67: 191613 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 191619 Killed                  timeout 15 ./execute_sscal_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/sscal/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_49 : 2025-05-17 17:59:52\r\n\r\nEnd Time 2025-05-17 17:59:52\r\n\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\nAtlas 200I DK A2\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n算子增加.AddConfig后在Atlas 200I DK A2测试；\r\n仅保留src中common以及sscal算子目录，其余算子目录均删除。\r\n因为编译报错，后续测试结果将PIPE_V修改为PIPE_ALL，重新编译运行\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\ncase全部通过测试\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\n![输入图片说明](https://foruda.gitee.com/images/1747477157970863671/c58bd27b_13572081.png \"屏幕截图 2025-05-17 181848.png\")\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/IC8IQV",
        "clean_data": "问题描述：     sscal算子在Atlas 200I DK A2上测试泛化性不足，部分shape 如 131073  17  1  1  20 、 21  1  19  255  1  9  8  9 等 运行时出现超时、输入数据生成失败 Killed信号 及输出文件缺失 FileNotFoundError ，导致精度异常。      重现条件：       使用原始CANN构建流程并添加 AddConfig     删除非sscal算子目录后编译，报错后将PIPE V改为PIPE ALL重新运行测试      预期结果：     所有测试用例均通过，无超时或文件读写失败现象。",
        "created_at": "2025-05-17T18:19:34+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-17T18:19:34+08:00"
    },
    {
        "id": 57,
        "source_id": "20432312",
        "title": "编译失败，有未开源代码仓：ascend-op-common-lib 和 secodefuzz",
        "body": "一、问题现象：\r\n编译时发现存在未开源的代码仓\r\n![输入图片说明](https://foruda.gitee.com/images/1746588538610926394/f360c192_8773665.png \"屏幕截图\")\r\n\r\n\r\n二、软件版本:\r\n- CANN 版本:  \r\n8.1.RC1.alpha001\r\n- Pytorch 版本:\r\ntorch                        2.1.0\r\ntorch-npu                    2.1.0.post10\r\n- Python 版本 (e.g., Python 3.7.5):\r\nPython 3.10.16\r\n- 操作系统版本:\r\n容器：Ubuntu 22.04.4 LTS\r\n\r\n三、测试步骤：\r\n\r\n```\r\nbash -x scripts/build.sh default\r\n\r\n出现 为开源代码仓\r\ngrep -nr \"codehub.huawei\" scripts/build.sh\r\n174:    git clone --branch $branch --depth 1 https://szv-open.codehub.huawei.com/OpenBaize/Ascend/ascend-op-common-lib.git\r\n264:    git clone -b v2.4.5 --depth=1 https://szv-open.codehub.huawei.com/innersource/Fuzz/secodefuzz.git\r\n```",
        "url": "https://gitee.com/ascend/ascend-transformer-boost/issues/IC5XO8",
        "clean_data": "问题标题指示CANN编译依赖未开源代码仓：ascend op common lib和secodefuzz如何处理 简化描述：CANN 8 1 RC1 alpha001版本编译时需要拉取华为内部未开源仓库ascend op common lib和secodefuzz，导致构建失败。需确定是否需要内部访问权限，或修改build sh替换为开源替代仓库。",
        "created_at": "2025-05-07T11:39:46+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-07T11:39:46+08:00"
    },
    {
        "id": 166,
        "source_id": "0263180173899246050",
        "title": "找不到libmedia_mini.so文件的解决方法",
        "body": "<div class=\"cke-article\"><p>（本错误是在进行MobileNetV2的香橙派端侧垃圾分类实验时发现，其它情况可参考本解决方法）</p>  <p>背景：香橙派Orange Pi Pro，CANN版本为8.0.0.beta1。</p>  <p>问题：在开发板内执行模型推理时报错，错误原因是找不到libmedia_mini.so的文件：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_10407.png\" src=\"cid:pic_0\" style=\"width: 624.0px;height: 353.0px;\"></span></p>  <p>问题分析：经过研究发现，前面安装的CANN中的lib64包下并没有该文件，可能是CANN的版本问题。 </p>  <p>解决方法：自己下载libmedia_mini.so文件，然后放在CANN包的路径中。</p>  <p>参考链接：https://developer.huawei.com/home/forum/ascend/thread-0204162114653426041-1-1.html</p>  <p>默认拷贝的路径为/usr/local/Ascend/ascend-toolkit/latest/aarch64-linux/lib64/</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0263180173899246050-1-1.html",
        "clean_data": "标题：开发板运行模型推理时报缺少libmedia mini so文件 描述：香橙派Pro使用CANN8 0 0 beta1版本执行模型推理时提示link error缺少libmedia mini so。经确认该文件不存在于ascend toolkit最新版lib64目录，需手动下载该 so文件上传至 usr local Ascend ascend toolkit latest aarch64 linux lib64 路径。参考解答详见论坛thread 0204162114653426041",
        "created_at": "2025-04-16T08:19:39+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-16T08:18:19+08:00"
    },
    {
        "id": 178,
        "source_id": "0266177061552103065",
        "title": "在编译时CMakeLists.txt中的路径出错，导致无法运行",
        "body": "<div class=\"cke-article\"><p><span class=\"easyimage easyimage-full\"><img alt=\"cke_105.jpeg\" src=\"cid:pic_0\" style=\"width: 1269.0px;height: 624.0px;\"></span></p>  <p>解决的方法是通过修改CMakePresets.json中的CANN安装路径后成功</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1193.png\" src=\"cid:pic_1\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0266177061552103065-1-1.html",
        "clean_data": "路径配置问题  compile 20240506 cmake path configure 编译报错源于CANN安装路径未正确配置，需在CMakePresets json而非CMakeLists txt中修改安装路径 图1显示配置示例",
        "created_at": "2025-03-11T07:45:52+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-11T07:45:52+08:00"
    },
    {
        "id": 624,
        "source_id": "20807310",
        "title": "编译错误，环境变量设置的是/usr/local/Ascend/ascend-toolkit/latest/runtime/lib64/stub，为什么用stub？",
        "body": "一、问题现象（附报错日志上下文）：\r\n案例: https://gitee.com/ascend/samples/tree/master/inference/modelInference/sampleResnetDVPP/cppACLLite\r\n\r\n工程编译时，为什么 环境变量设置的是/usr/local/Ascend/ascend-toolkit/latest/runtime/lib64/stub\r\n                         而不是 /usr/local/Ascend/ascend-toolkit/latest/aarch64-linux/lib64\r\n\r\n使用案例的环境变量 编译报错如下：\r\n\r\n![输入图片说明](https://foruda.gitee.com/images/1749536534915228557/64292a94_1215735.png \"屏幕截图\")",
        "url": "https://gitee.com/ascend/samples/issues/ICDZ0U",
        "clean_data": "编译错误：环境变量设置使用stub路径而非真实aarch64 linux库路径  问题核心：样本代码编译时将环境变量指定为 stub 目录  usr local Ascend ascend toolkit latest runtime lib64 stub ，而非实际底层SDK的ARM架构库路径  usr local Ascend ascend toolkit latest aarch64 linux lib64 ，导致出现图示编译错误  解决方案： 1  检查是否使用CANN SDK的正向开发环境 x86架构开发机 ，此时 stub 目录用于模拟ARM库符号 2  若在真实ARM开发环境 如Atlas设备 编译，需修改环境变量路径为aarch64 linux实际库位置 3  注意SDK路径因安装版本 架构存在差异，建议通过  opt atlas support tools toolchain 路径验证实际库路径 4  编译后须将生成的可执行文件部署至ARM侧运行，x86侧编译需继续使用 stub 目录",
        "created_at": "2025-06-10T14:23:09+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-11T18:19:20+08:00"
    },
    {
        "id": 2,
        "source_id": "19193110",
        "title": "【整体】自动融合开启阶段",
        "body": "### 该问题是怎么引起的？\n原图优化阶段的代码：\n```\nStatus GraphManager::PreRunOptimizeOriginalGraph(const GraphNodePtr &graph_node, const std::vector<GeTensor> &inputs,\n                                                 ge::ComputeGraphPtr &compute_graph, uint64_t session_id) {\n  ErrorManager::GetInstance().SetStage(error_message::kModelCompile, error_message::kPrepareOptimize);\n  GE_CHECK_NOTNULL(graph_node);\n  GE_CHECK_NOTNULL(compute_graph);\n\n  GE_ASSERT_SUCCESS(RunCustomPass(graph_node->GetGraph()), \"[Run][CustomPass] failed.\");\n  CompilerStages &stages = GetCompilerStages(graph_node->GetGraphId());\n  GM_RUN_AND_DUMP_PERF(\"InitPreparation\", stages.preparer.PrepareInit, graph_node,\n                       session_id, graph_rebuild_state_ctrl_.get(), &resource_context_mgr_);\n  // summary 处理放到normalize里\n  GM_RUN_AND_DUMP_PERF(\"HandleSummaryOp\", stages.optimizer.HandleSummaryOp, compute_graph);\n  GM_RUN_AND_DUMP_PERF(\"NormalizeGraph\", stages.preparer.NormalizeGraph, compute_graph, graph_node->GetOptions(),\n                       inputs);\n  GM_RUN_AND_DUMP_PERF(\"OptimizeGraphInit\", stages.optimizer.OptimizeGraphInit, compute_graph);\n  GM_RUN_AND_DUMP_PERF(\"OptimizeGraphPrepare\", stages.optimizer.OptimizeOriginalGraphForQuantize, compute_graph);\n\n  int64_t graph_stage = static_cast<int64_t>(GraphStage::GRAPH_STAGE_RESERVED);\n  (void)AttrUtils::GetInt(compute_graph, kGraphDumpStage, graph_stage);\n  if (graph_stage == static_cast<int64_t>(GraphStage::GRAPH_STAGE_FUZZ)) {\n    GELOGD(\"graph_stage:%d.\", static_cast<int32_t>(graph_stage));\n    return SUCCESS;\n  }\n\n  GM_RUN_AND_DUMP_PERF(\"Prepare\", stages.preparer.PrepareDynShape);\n  std::string graph_slice_mode;\n  if ((GetContext().GetOption(GRAPH_SLICE_MODE, graph_slice_mode) == GRAPH_SUCCESS) && (!graph_slice_mode.empty())) {\n    PassManager graph_pass;\n    GE_CHK_STATUS_RET(graph_pass.AddPass(\"PreRun::GraphSlicingPass\", new (std::nothrow) GraphSlicingPass));\n    GE_CHK_STATUS_RET(graph_pass.Run(compute_graph));\n  }\n\n  GE_CHK_STATUS_RET(ParallelOptionParser::Instance().ParseFromOption());\n  const auto &engine_parallel_option = ParallelOptionParser::Instance().GetEngineParallelOption();\n  GE_CHK_STATUS_RET_NOLOG(OptimizeByEngineParallel(graph_node, compute_graph, engine_parallel_option));\n  ErrorManager::GetInstance().SetStage(error_message::kModelCompile, error_message::kOriginOptimize);\n  GM_RUN_AND_DUMP_PERF(\"OptimizeOriginalGraph\", stages.optimizer.OptimizeOriginalGraph, compute_graph);\n\n  ErrorManager::GetInstance().SetStage(error_message::kModelCompile, error_message::kPrepareOptimize);\n  GM_RUN_AND_DUMP_PERF(\"PrepareRunningFormatRefiner\", stages.preparer.PrepareRunningFormatRefiner);\n  GM_RUN_AND_DUMP_PERF(\"RefineRunningFormat\", stages.optimizer.OptimizeOriginalGraphJudgeInsert, compute_graph);\n  GM_RUN_AND_DUMP_PERF(\"SubexpressionMigration\", SubexpressionMigration, compute_graph);\n  GE_RUN(GraphManager, stages.preparer.RecordAIPPInfo, compute_graph);\n  if (IsTailingOptimization()) {\n    GM_RUN_AND_DUMP_PERF(\"OptimizeSwitchOp\", stages.preparer.SwitchOpOptimize, compute_graph);\n  }\n  GE_CHK_STATUS_RET(stages.optimizer.IdentifyReference(compute_graph),\n                    \"[Identify][Reference] failed, graph:%s.\", compute_graph->GetName().c_str());\n  GM_RUN_AND_DUMP_PERF(\"Optimize1\", OptimizeStage1, compute_graph);\n  GM_RUN_AND_DUMP_PERF(\"OptimizeAfterStage1\", stages.optimizer.OptimizeAfterStage1, compute_graph);\n  GM_RUN_AND_DUMP_PERF(\"InferShape2\", GraphUtilsEx::InferShapeInNeed, compute_graph);\n  PassManager graph_pass;\n  GE_CHK_STATUS_RET(graph_pass.AddPass(\"PreRun::CtrlEdgeTransferPass\", new (std::nothrow) CtrlEdgeTransferPass));\n  GE_CHK_STATUS_RET(graph_pass.AddPass(\"PreRun::AutoFusePass\", new (std::nothrow) AutoFusePass));\n  GE_CHK_STATUS_RET(graph_pass.Run(compute_graph));\n  GEEVENT(\"PreRun:PreRunOptimizeOriginalGraph success.\");\n  return SUCCESS;\n}\n```\n\n\n一开始，将自动融合放在了InferShape2于CtrlEdgeTransferPass阶段后出现了三个问题：\n客户现场调测遇到三个问题：\n1. autofuse阶段的在符号化推导时，不支持transdata算子的infer报错。\n    产生transdata节点：transdata ge_proto_00000040_graph_1_OptimizeOriginalGraph_FeInsertTransNodeAfter\n\n2. pb原图没有layernorm算子，经历原图融合出现了LayerNormer算子\n    产生layerneo节点：layernorm ge_proto_00000029_graph_1_OptimizeOriginalGraph_FeGraphFusionAfter\n\n3. ReShape算子在原图优化中只有一个输入，另一个输入是属性 \n    在ge_proto_00000029_graph_1_OptimizeOriginalGraph_FeGraphFusionAfter阶段出现了一个非标的ReShape算子，只有一个输入，shape输入是按照属性方式打在ReShape上（非IR属性）\n    在ge_proto_00000046_graph_1_OptimizeStage1_2阶段又被融合回来了，变成了标准的ReShape\n\n### 重现步骤\n\n\n\n### 报错信息\n\n\n\n\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFDHY",
        "clean_data": "自动融合开启阶段：AutoFusePass引发三类异常。1  推导阶段transdata算子不支持infer；2  原图无layernorm算子但融合后产生LayerNormer节点；3  ReShape算子在优化阶段以属性而非IR方式绑定shape输入，后续阶段被还原为标准形式。",
        "created_at": "2025-01-03T10:13:44+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-22T11:09:44+08:00"
    },
    {
        "id": 766,
        "source_id": "20543665",
        "title": "在310b上调用hi_mpi_vi_set_chn_ldc_attr导致系统崩溃",
        "body": "一、问题现象（附报错日志上下文）：\r\n在310b上调用hi_mpi_vi_set_chn_ldc_attr导致系统崩溃\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  7.0\r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 22.04\r\n\r\n三、测试步骤：\r\n基于310b进行开发，调整摄像头传入图像的LDC属性，调用hi_mpi_vi_set_chn_ldc_attr系统会直接崩溃。\r\n\r\n\r\n四、日志信息:\r\n系统崩溃之前的日志\r\n```\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.091.594 [error_manager.cc:602]2639 ParseJsonFile:add error_code EZ0005 success\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.091.615 [error_manager.cc:602]2639 ParseJsonFile:add error_code EZ0006 success\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.091.637 [error_manager.cc:602]2639 ParseJsonFile:add error_code EZ0007 success\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.091.646 [error_manager.cc:610]2639 ParseJsonFile:Parse json file:/usr/local/Ascend/nnrt/8.0.RC1/aarch64-linux/lib64/../conf/error_manager/error_code.json success\r\n[INFO] PROFILING(2639,sample_hdmi):1970-01-01-01:05:30.093.156 [prof_atls_plugin.cpp:160] >>> (tid:2639) Module[48] register callback of ctrl handle.\r\n[INFO] ASCENDCL(2639,sample_hdmi):1970-01-01-01:05:30.093.178 [acl.cpp:268]2639 aclInit: call ge interface executor.Initialize\r\n[INFO] PROFILING(2639,sample_hdmi):1970-01-01-01:05:30.093.194 [prof_atls_plugin.cpp:160] >>> (tid:2639) Module[45] register callback of ctrl handle.\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.206 [ge_executor.cc:288]2639 Initialize:Init GeExecutor begin.\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.228 [plugin_manager.cc:475]2639 GetOpTilingForwardOrderPath:Enter GetOpTilingPath schedule\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.236 [plugin_manager.cc:89]2639 GetOppPath:Enter get opp path schedule\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.269 [plugin_manager.cc:98]2639 GetOppPath:Get opp path from env: /usr/local/Ascend/nnrt/latest/opp\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.287 [plugin_manager.cc:483]2639 GetOpTilingForwardOrderPath:Opp plugin path structure is new version!\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.295 [plugin_manager.cc:156]2639 GetPluginPathFromCustomOppPath:Start to get plugin path from ASCEND_CUSTOM_OPP_PATH schedule.\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.303 [plugin_manager.cc:160]2639 GetPluginPathFromCustomOppPath:env ASCEND_CUSTOM_OPP_PATH is not defined.\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.310 [plugin_manager.cc:397]2639 GetOppPluginPathNew:Enter get opp plugin path new schedule\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.317 [plugin_manager.cc:119]2639 GetOppPluginVendors:Enter get opp plugin config file schedule, config file is '/usr/local/Ascend/nnrt/latest/opp/vendors/config.ini'\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.340 [plugin_manager.cc:122]2639 GetOppPluginVendors:Can not open file '/usr/local/Ascend/nnrt/latest/opp/vendors/config.ini'!\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.348 [plugin_manager.cc:401]2639 GetOppPluginPathNew:Can not get opp plugin vendors!\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.388 [file_utils.cc:53]2639 RealPath:[Util][realpath] Get real_path for /usr/local/Ascend/nnrt/latest/opp//version.info failed, reason:No such file or directory\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.397 [plugin_manager.cc:883]2639 GetVersionFromPathWithName:Invalid input file path [/usr/local/Ascend/nnrt/latest/opp//version.info], make sure that the file path is correct.\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.416 [plugin_manager.cc:322]2639 GetOppAndCompilerVersion:Get opp_version:\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.423 [plugin_manager.cc:284]2639 IsVendorVersionValid:[NotVerification] Will not verify version as the opp version and compiler version are not set\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.482 [plugin_manager.cc:414]2639 GetOppPluginPathNew:plugin_path is '/usr/local/Ascend/nnrt/latest/opp/op_impl/custom/ai_core/tbe/:/usr/local/Ascend/nnrt/latest/opp/built-in/op_impl/ai_core/tbe/'\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.492 [plugin_manager.cc:139]2639 ReversePathString:Enter ReversePathString schedule\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.502 [plugin_manager.cc:151]2639 ReversePathString:path_str is '/usr/local/Ascend/nnrt/latest/opp/built-in/op_impl/ai_core/tbe/:/usr/local/Ascend/nnrt/latest/opp/op_impl/custom/ai_core/tbe/'\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.510 [plugin_manager.cc:836]2639 GetCurEnvPackageOsAndCpuType:Enter GetCurEnvPackageOsAndCpuType schedule\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.788 [plugin_manager.cc:838]2639 GetCurEnvPackageOsAndCpuType:Current lib path is:/usr/local/Ascend/nnrt/8.0.RC1/aarch64-linux/lib64/\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.797 [plugin_manager.cc:842]2639 GetCurEnvPackageOsAndCpuType:Run package path is:/usr/local/Ascend/nnrt/8.0.RC1/\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.809 [plugin_manager.cc:853]2639 GetCurEnvPackageOsAndCpuType:extract os and cpu info from /usr/local/Ascend/nnrt/8.0.RC1/opp/scene.info\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.875 [plugin_manager.cc:868]2639 GetCurEnvPackageOsAndCpuType:Get os:linux\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.892 [plugin_manager.cc:872]2639 GetCurEnvPackageOsAndCpuType:Get cpu:aarch64\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.929 [op_tiling_manager.cc:63]2639 LoadSo:[FindSo][Check] Get path with op_master [/usr/local/Ascend/nnrt/latest/opp/built-in/op_impl/ai_core/tbe/op_master/] failed\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.093.990 [op_tiling_manager.cc:72]2639 LoadSo:Failed to dlopen /usr/local/Ascend/nnrt/latest/opp/built-in/op_impl/ai_core/tbe/op_tiling/lib/linux/aarch64/liboptiling.so! errmsg:/usr/local/Ascend/nnrt/latest/opp/built-in/op_impl/ai_core/tbe/op_tiling/lib/linux/aarch64/liboptiling.so: cannot open shared object file: No such file or directory\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.014 [op_tiling_manager.cc:78]2639 LoadSo:Failed to dlopen /usr/local/Ascend/nnrt/latest/opp/built-in/op_impl/ai_core/tbe/op_tiling/liboptiling.so! errmsg:/usr/local/Ascend/nnrt/latest/opp/built-in/op_impl/ai_core/tbe/op_tiling/liboptiling.so: cannot open shared object file: No such file or directory\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.036 [op_tiling_manager.cc:63]2639 LoadSo:[FindSo][Check] Get path with op_master [/usr/local/Ascend/nnrt/latest/opp/op_impl/custom/ai_core/tbe/op_master/] failed\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.055 [op_tiling_manager.cc:72]2639 LoadSo:Failed to dlopen /usr/local/Ascend/nnrt/latest/opp/op_impl/custom/ai_core/tbe/op_tiling/lib/linux/aarch64/liboptiling.so! errmsg:/usr/local/Ascend/nnrt/latest/opp/op_impl/custom/ai_core/tbe/op_tiling/lib/linux/aarch64/liboptiling.so: cannot open shared object file: No such file or directory\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.072 [op_tiling_manager.cc:78]2639 LoadSo:Failed to dlopen /usr/local/Ascend/nnrt/latest/opp/op_impl/custom/ai_core/tbe/op_tiling/liboptiling.so! errmsg:/usr/local/Ascend/nnrt/latest/opp/op_impl/custom/ai_core/tbe/op_tiling/liboptiling.so: cannot open shared object file: No such file or directory\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.138 [plugin_manager.cc:498]2639 GetConstantFoldingOpsPath:Enter GetConstantFoldingOpsPath schedule\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.157 [plugin_manager.cc:89]2639 GetOppPath:Enter get opp path schedule\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.178 [plugin_manager.cc:98]2639 GetOppPath:Get opp path from env: /usr/local/Ascend/nnrt/latest/opp\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.245 [host_cpu_engine.cc:257]2639 ListSoFiles:Found 1 libs to load\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.094.271 [host_cpu_engine.cc:281]2639 LoadLib:To invoke dlopen on lib: /usr/local/Ascend/nnrt/8.0.RC1/opp/built-in/op_impl/host_cpu/libconstant_folding_ops.so\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.501 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ThreeNN] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.529 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Acos] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.538 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Acosh] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.545 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[AdaptiveAvgPool2dAssistMatrix] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.552 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[AdaptiveAvgPoolAssistMatrix] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.559 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MinAreaPolygons] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.566 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SilentCheck] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.578 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[AdaptiveMaxPool2d] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.593 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Add] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.605 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Addcdiv] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.619 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Addcmul] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.626 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Asin] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.637 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[AffineGrid] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.644 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Asinh] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.656 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Atan] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.662 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Atan2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.669 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Atanh] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.676 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Betainc] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.683 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Bucketize] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.689 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[CacheSwapTable] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.701 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[CalcBucketsLimitAndOffset] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.708 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[LogUniformCandidateSampler] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.715 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UniformCandidateSampler] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.731 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[CaseCondition] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.739 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Cast] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.745 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Ceil] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.758 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[CheckNumerics] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.771 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[CompareAndBitpack] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.778 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Combinations] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.790 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ComputeAccidentalHits] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.796 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ConcatV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.807 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Conj] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.826 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ConjugateTranspose] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.833 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Coordinates1DTo2D] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.845 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Cosh] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.858 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[CropAndResize] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.865 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Cross] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.872 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Cumsum] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.887 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Cummin] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.900 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Cummax] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.913 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[DynamicStitch] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.926 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EditDistance] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.939 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EluGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.946 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingLookup] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.959 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Equal] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.965 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ExpandDims] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.975 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Expand] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.095.982 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Exponential] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.110 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Fill] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.122 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Fills] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.137 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[FillDiagonal] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.153 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Floor] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.161 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[FloorDiv] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.168 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[FloorMod] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.181 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GatherElements] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.193 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GatherV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.206 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Geometric] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.219 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GetDynamicDims] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.233 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Greater] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.243 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GreaterEqual] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.256 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GridSampler2D] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.269 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GridSampler2DGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.276 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GridSampler3D] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.289 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GridSampler3DGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.296 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Histogram] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.315 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Identity] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.334 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[IMGWarpOffsets] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.342 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[IndexToAddr] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.349 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[InplaceIndexAdd] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.355 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[InplaceTopKDistance] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.368 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[InvertPermutation] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.375 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[InvGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.382 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[IsClose] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.389 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[IsInf] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.402 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[IsNan] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.409 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Less] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.442 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Log] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.451 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Log1p] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.470 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[LogMatrixDeterminant] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.477 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Assert] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.489 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[LogSoftmaxV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.496 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MaskedFill] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.503 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MaskedScatter] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.515 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MaskedSelect] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.522 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MaskedSelectGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.534 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MatrixDiagPartV3] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.541 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MatrixDiagV3] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.634 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Mul] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.642 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MultinomialAliasDraw] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.655 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MultinomialAliasSetup] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.666 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[AvgPoolV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.673 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[CTCLossV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.685 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[CTCLossV2Grad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.698 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MultinomialWithReplacement] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.705 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NonZero] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.719 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ScatterAddWithAxis] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.733 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[StatelessRandperm] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.753 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ViewCopy] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.759 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ScatterNdAdd] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.771 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Trace] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.784 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Neg] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.796 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NLLLoss] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.803 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NLLLossGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.816 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NMSWithMask] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.823 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NonMaxSuppressionV3] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.845 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[WarpAffine] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.852 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NonZeroWithValueShape] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.859 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NonZeroWithValueShapeV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.866 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NotEqual] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.873 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[OnesLike] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.880 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[PadD] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.096.887 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Pad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.150 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Pow] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.163 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[PadV3Grad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.178 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[PadV3] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.192 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Pinverse] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.205 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Poisson] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.218 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ProdEnvMatACalcRij] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.225 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[RandomStandardNormal] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.232 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[StatelessRandomUniformV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.245 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[RandomUniform] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.257 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[StatelessBernoulli] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.270 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[RealDiv] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.284 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Div] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.291 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Reshape] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.298 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Resize] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.311 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ResizeTrilinear] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.324 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ResizeBilinear] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.331 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ResizeBilinearGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.338 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[RoiPoolingWithArgMax] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.345 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ResizeBilinearV2Grad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.352 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ResizeGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.370 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ReverseSequence] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.384 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[RightShift] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.397 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[RNNTLoss] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.410 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Round] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.416 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Rsqrt] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.423 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ScatterElements] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.430 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ScatterNdMax] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.443 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ScatterNdMin] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.460 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SearchSorted] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.473 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Sigmoid] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.485 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Sign] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.492 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SliceWrite] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.499 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SoftmaxV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.505 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Sort] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.519 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SparseSegmentSum] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.534 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SparseSegmentMean] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.547 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SparseToDense] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.567 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SparseSegmentMeanGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.580 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SparseFillEmptyRows] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.593 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SpatialTransformer] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.605 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SplitV] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.617 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SplitD] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.623 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Square] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.635 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SquaredDifference] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.642 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[StridedSlice] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.653 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[StridedSliceV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.664 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[STFT] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.677 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Sub] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.689 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Tan] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.703 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TanhGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.715 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TensorEqual] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.722 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TensorScatterUpdate] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.728 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TopK] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.740 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TopKPQDistance] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.752 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TopKPQDistanceV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.764 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TopKV2D] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.776 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Tril] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.783 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Triu] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.790 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UniqueConsecutive] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.801 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UniqueWithCountsAndSorting] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.814 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UniqueWithCountsExt2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.827 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UpsampleNearest3d] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.840 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UpsampleNearest3dGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.853 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UpsampleTrilinear3d] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.860 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UpsampleTrilinear3dGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.866 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ZerosLike] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.873 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Zeta] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.885 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ActiveRotatedFilterGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.891 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Voxelization] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.898 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ActiveRotatedFilter] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.912 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Tile] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.956 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TileWithAxis] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.988 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ReduceMean] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.097.996 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ReduceSum] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.014 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ReduceAll] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.027 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[LinSpace] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.034 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[LinearSumAssignment] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.048 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SelectV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.106 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TransData] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.116 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[PSAMask] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.130 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[PSAMaskGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.137 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Sqrt] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.150 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[SigmoidGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.166 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Elu] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.178 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ClipByValueV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.220 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ApplyAdamV2] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.228 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[Assign] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.234 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ClipByValue] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.272 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingApplyAdam] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.297 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingApplyAdamW] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.326 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingApplyAdaGrad] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.353 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingApplyRmsprop] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.377 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingApplySgd] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.401 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingComputeVarExport] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.432 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingComputeVarImport] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.457 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingFeatureMappingExport] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.487 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingFeatureMappingFileSize] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.519 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingFeatureMappingImport] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.555 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingTableExport] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.579 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingTableFind] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.609 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingTableFindAndInit] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.641 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingTableImport] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.666 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[EmbeddingApplyFtrl] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.691 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[ExponentialDecayLR] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.705 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[GEMM] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.734 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[InitEmbeddingHashmap] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.757 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[InitPartitionMap] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.771 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[MatMul] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.778 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[NoOp] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.098.790 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TransDataRNN] register successfully.\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.098.985 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type GatherV2HostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.010 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type GatherV2DHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.021 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type GatherHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.109 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type ConcatHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.123 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type ConcatDHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.133 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type ConcatV2HostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.143 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type ConcatV2DHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.152 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type PackHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.336 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type CastHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.431 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type EqualHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.591 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SliceHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.604 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SliceDHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.688 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SplitHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.700 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SplitDHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.775 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type MulHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.866 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type DivHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.878 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type RealDivHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.960 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type StridedSliceHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.099.974 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type StridedSliceDHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.150 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type ReduceProdHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.166 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type ReduceProdDHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.248 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SubHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.317 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type AddHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.391 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type MapIndexHostKernel registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.404 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type CreateSession registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.415 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type DestroySession registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.424 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type ClearContainer registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.496 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SequenceAtCompute registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.507 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SequenceEmptyCompute registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.517 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SequenceLengthCompute registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.580 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SequenceConstructCompute registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.646 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SequenceInsertCompute registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.710 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type SequenceEraseCompute registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.776 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type StoreSplitTensorToSequence registered\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.100.839 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TableToResource] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.100.869 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UninitEmbeddingHashmap] register successfully.\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.100.905 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[UninitPartitionMap] register successfully.\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.100.982 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type FillHostKernel registered\r\n[DEBUG] AICPU(2639,sample_hdmi):1970-01-01-01:05:30.100.994 [cpu_kernel_register.cc:207][Register][tid:2639]Kernel[TruncatedNormal] register successfully.\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.101.075 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type WhereHostKernel registered\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.101.572 [host_cpu_engine.cc:300]2639 LoadLib:Lib: /usr/local/Ascend/nnrt/8.0.RC1/opp/built-in/op_impl/host_cpu/libconstant_folding_ops.so has been opened\r\n[INFO] GE(2639,sample_hdmi):1970-01-01-01:05:30.101.686 [plugin_manager.cc:729]2639 LoadWithFlags:Dlopen path: /usr/local/Ascend/nnrt/8.0.RC1/aarch64-linux/lib64/plugin/engines/runtime/libdvpp_rtkernel.so. flags is 4354\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.103.424 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type GenerateSqeAndLaunchTask registered\r\n[DEBUG] GE(2639,sample_hdmi):1970-01-01-01:05:30.103.466 [kernel_registry_impl.cc:128]2639 KernelRegisterV2:GERT kernel type CalcDvppWorkSpaceSize registered\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.103.767 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[AdjustBrightness] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.103.779 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[AdjustBrightnessV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.103.854 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[AdjustContrastWithMean] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.103.929 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[AdjustHue] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.103.998 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[AdjustSaturation] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.172 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[AdjustSaturationV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.247 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[GaussianBlur] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.323 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[YUVToRGB] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.398 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[Crop] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.474 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[CropAndResize] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.482 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[CropAndResizeV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.622 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[ImgCrop] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.697 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[ImgToTensor] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.770 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[DecodeJpeg] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.778 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[DecodeAndCropJpeg] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.854 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[NormalizeV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.104.941 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[PadV3D] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.014 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[Resize] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.023 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[ResizeV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.030 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[ResizeBicubic] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.036 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[ResizeBilinearV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.042 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[ResizeNearestNeighborV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.110 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[ReverseV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.177 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[RgbToGrayscale] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.251 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[Rotate] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.331 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[WarpAffineV2] register successfully\r\n[DEBUG] DVPP(2639,sample_hdmi):1970-01-01-01:05:30.105.399 [DvppKernelRegister.cpp:32][DVPP] [Register:32] [T2] Kernel[WarpPerspective] register successfully\r\n[WARNING] GE(2639,sample_hdmi):1970-01-01-01:05:30.105.617 [plugin_manager.cc:740]2639 LoadWithFlags:The shared library will not be checked. Please ensure that the source of the shared library is trusted.\r\n\r\n```",
        "url": "https://gitee.com/ascend/samples/issues/IC8BLD",
        "clean_data": "在Ascend 310B设备使用CANN 7 0调用hi mpi vi set chn ldc attr导致系统崩溃     调用Hi mpi vi set chn ldc attr接口调整LDC属性时触发系统崩溃，日志显示与GE ASCENDCL模块初始化相关路径缺失 如无法找到  usr local Ascend nnrt latest opp vendors config ini 及 liboptiling so 共享库 ，需确认配置路径完整性、依赖库安装及参数合法性。",
        "created_at": "2025-05-16T15:44:32+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-06T11:21:56+08:00"
    },
    {
        "id": 769,
        "source_id": "20627941",
        "title": " error: use of undeclared identifier 'tilingData'",
        "body": "一、问题现象（附报错日志上下文）：\r\n和之前很多issue(https://gitee.com/ascend/samples/issues/IBTG0Y)一样，遇到了同样的问题:\r\n![输入图片说明](https://foruda.gitee.com/images/1747991630471918991/1ae41175_8246595.png \"屏幕截图\")\r\n二、软件版本:\r\n-- CANN 版本: CANN  8.0.0  \r\n--Pytorch: 2.1\r\n--Python 版本 (e.g., Python 3.7.5): Python 3.10.8\r\n\r\n三、测试步骤：\r\n参考官方文档的步骤，运行./build.sh时出错\r\n\r\n\r\n四、日志信息:\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.346.528 [../../../opc_tool/op_compilation.py:337][__single_op_compile] Exception occured, An error occurred during compile phases of CompileStage.INFERCHANNEL, msg is /root/autodl-tmp/multi-arch-kernel-bench/ascend_op_projects/LeakyRelu/build_out/op_kernel/binary/ascend910b/src/leaky_relu.cpp:73:21: error: use of undeclared identifier 'tiling_data'\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.348.822 [../../../opc_tool/opc_common.py:223][_log_error] Traceback (most recent call last):\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.348.886 [../../../opc_tool/opc_common.py:223][_log_error]   File \"/usr/local/Ascend/ascend-toolkit/8.0.0/python/site-packages/tbe/common/utils/para_check.py\", line 543, in _in_wrapper\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.348.938 [../../../opc_tool/opc_common.py:223][_log_error]   File \"/usr/local/Ascend/ascend-toolkit/8.0.0/python/site-packages/tbe/tikcpp/compile_op.py\", line 3989, in get_code_channel_v220_by_first_tiling_key\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.348.986 [../../../opc_tool/opc_common.py:223][_log_error] Exception: An error occurred during compile phases of CompileStage.INFERCHANNEL, msg is /root/autodl-tmp/multi-arch-kernel-bench/ascend_op_projects/LeakyRelu/build_out/op_kernel/binary/ascend910b/src/leaky_relu.cpp:73:21: error: use of undeclared identifier 'tiling_data'\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.349.038 [../../../opc_tool/op_compilation.py:210][record_compile_error_info] Op[LeakyRelu] of index[0] compile failed, kernelName: LeakyRelu_fae42965a22a8e7dee2de1282546a576\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.349.464 [../../../opc_tool/opc_common.py:516][opc_log_full] [op_compilation.py:212][record_compile_error_info] reason is:[An error occurred during compile phases of CompileStage.INFERCHANNEL, msg is /root/autodl-tmp/multi-arch-kernel-bench/ascend_op_projects/LeakyRelu/build_out/op_kernel/binary/ascend910b/src/leaky_relu.cpp:73:21: error: use of undeclared identifier 'tiling_data'\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.349.524 [../../../opc_tool/opc_common.py:516][opc_log_full] /root/autodl-tmp/multi-arch-kernel-bench/ascend_op_projects/LeakyRelu/build_out/op_kernel/binary/ascend910b/src/leaky_relu.cpp:75:53: error: use of undeclared identifier 'tiling_data'\r\n[ERROR] TBE(15014,python3):2025-05-23-17:23:51.350.150 [../../../opc_tool/opc.py:721][main] Opc tool compile failed.\r\n[ERROR]: LeakyRelu do not registe tiling struct!!!\r\n[ERROR] Kernel compile failed, the run package will not be generated.",
        "url": "https://gitee.com/ascend/samples/issues/ICA4MD",
        "clean_data": "CANN 8 0编译LeakyRelu算子时提示错误：代码中引用了未声明的tiling data标识符，且算子未注册tiling结构。建议检查算子是否补全tiling结构注册代码，参照其他正常编译算子配置。",
        "created_at": "2025-05-23T17:28:29+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-09T16:16:48+08:00"
    },
    {
        "id": 770,
        "source_id": "20655822",
        "title": "无法进行硬件解码和编码",
        "body": "一、问题现象（附报错日志上下文）：\n编码：请问有python实现硬件编码的样例吗？\n解码：解码跑在了CPU侧，使用了https://gitee.com/ascend/ACLLite/tree/master/python库，参考样例：https://gitee.com/ascend/samples/tree/master/python/level2_simple_inference/2_object_detection/coco_detection_rtsp，之前跑通过，可以正常硬件解码，新部署的一台设备，解码跑在的CPU了，同样的代码。不确定是不是驱动和NNRT版本不适配。另外如果不使用多线程，单线程解码，则可以正常使用硬件解码，参考代码：\nimport numpy as np\nimport videocapture as video\nimport datetime\nfrom acllite_resource import AclLiteResource\nfrom acllite_model import AclLiteModel\nfrom acllite_imageproc import AclLiteImageProc\nfrom label import label\nfrom acllite_logger import log_error, log_info\n\n\nclass SampleResnetRtsp(object):\n    '''load the model, and do preprocess, infer, postprocess'''\n    def __init__(self, model_path, model_width, model_height):\n        # initial parameters\n        self.model_path = model_path\n        self.model_width = model_width\n        self.model_height = model_height\n        \n    def init_resource(self):\n        # initial acl resource, create image processor, create model\n        self._resource = AclLiteResource()\n        self._resource.init()\n    \n        self._dvpp = AclLiteImageProc(self._resource) \n        self._model = AclLiteModel(self.model_path)\n\n    def preprocess(self, image):\n        # process frames by AclLiteImageProc\n        self.resize_image = self._dvpp.crop_and_paste(image,1920,1080, self.model_width, self.model_height)\n        \n    def construct_image_info(self):\n        \"\"\"construct\"\"\"\n        image_info = np.array([self.model_width, self.model_height,\n                       self.model_width, self.model_height],\n                       dtype = np.float32)\n        return image_info\n    def infer(self):\n        image_info = self.construct_image_info()\n        # add input image to list and inference\n        self.output = self._model.execute([self.resize_image,image_info])\n    \n    def postprocess(self):\n        # decode the result and print top 1 \n        detect_results = self.output\n        box_num = int(detect_results[1][0, 0])\n        box_info = detect_results[0].flatten()\n                \n        scalex = 1920 / self.model_width\n        scaley = 1080 / self.model_height\n        if scalex > scaley:\n            scaley = scalex\n        detection_result_list = []\n        for n in range(int(box_num)):\n            ids = int(box_info[5 * int(box_num) + n])\n            score = box_info[4 * int(box_num) + n]\n            print(ids,score)\n    def release_resource(self):\n        # release resource includes acl resource, data set and unload model\n        del self._resource\n        del self._dvpp\n        del self._model\n        del self.resize_image\n\n\nif __name__ == '__main__':  \n    stream_path = \"xxxxzx\"\n    model_path = \"xxx.om\"\n    model_width = 640\n    model_height = 640\n\n    # create rtsp and init acl resource , load model\n    rtsp = SampleResnetRtsp(model_path, model_width, model_height)\n    ret = rtsp.init_resource()\n    cap = video.VideoCapture(stream_path)\n\n    while True:\n        ret, image = cap.read()\n        if ret:\n            log_error(\"vdec read from channel failed\")\n            break\n        if image is not None:\n            rtsp.preprocess(image)\n            rtsp.infer()\n            rtsp.postprocess()\n            print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'))\n        else:\n            log_info(\"read frame finish\")\n            break\n    rtsp.release_resource()\n\n二、软件版本:\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):   NNRT8.1.RC1\n--Python 版本 (e.g., Python 3.7.5):3.9.22\n--操作系统版本 (e.g., Ubuntu 18.04):ubuntu 22.04\n",
        "url": "https://gitee.com/ascend/samples/issues/ICAQ4U",
        "clean_data": "硬件解码转CPU执行且单线程有效：新部署设备使用ACLLite库加载模型时，原正常工作的硬件解码功能失效 现象与驱动 NNRT版本相关 ，且单线程解码可恢复硬件执行模式，请求提供Python硬件编码示例及排查指引。",
        "created_at": "2025-05-27T09:58:01+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-10T17:11:22+08:00"
    },
    {
        "id": 771,
        "source_id": "20665798",
        "title": "ModuleNotFoundError: No module named 'torch._six'",
        "body": "一、问题现象（附报错日志上下文）：\r\n(MindSpore) [ma-user AclNNInvocation]$bash run.sh -v Ascend910B4 -r npugetopt: unrecognized option '-r'\r\n/home/ma-user/Ascend/ascend-toolkit/latest\r\nrm: cannot remove './input/*.bin': No such file or directory\r\nrm: cannot remove './output/*.bin': No such file or directory\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/__init__.py\", line 32, in <module>\r\n    import torch_npu.npu\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/npu/__init__.py\", line 44, in <module>\r\n    from .utils import (is_initialized, _lazy_call, _lazy_init, init, set_dump,\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/npu/utils.py\", line 25, in <module>\r\n    import torch._six\r\nModuleNotFoundError: No module named 'torch._six'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/work/samples/operator/ascendc/4_best_practices/23_matmul_all_reduce_custom/AclNNInvocation/scripts/gen_data.py\", line 8, in <module>\r\n    import torch_npu\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/__init__.py\", line 34, in <module>\r\n    from torch_npu.utils.error_code import ErrCode, pta_error\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/utils/__init__.py\", line 23, in <module>\r\n    from .dataloader import add_dataloader_method\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/utils/dataloader.py\", line 28, in <module>\r\n    from torch._six import string_classes\r\nModuleNotFoundError: No module named 'torch._six'\r\nERROR: generate input data failed!\r\n(MindSpore) [ma-user AclNNInvocation]$\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  8.0.0.alpha003\r\n--Tensorflow/Pytorch/MindSpore 版本:  ‘torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl’\r\n--Python 版本 (e.g., Python 3.7.5): 3.9.10\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)): 无\r\n--操作系统版本 (e.g., Ubuntu 18.04): ModelArts\r\n\r\n三、测试步骤：\r\nclone simple 仓然后执行算子文件夹\r\n\r\n/home/ma-user/work/samples/operator/ascendc/4_best_practices/23_matmul_all_reduce_custom/AclNNInvocation\r\n\r\n中的 bash run.sh -v Ascend910B4 -r npu\r\n\r\n四、日志信息:\r\n\r\nThe environment has been set\r\nThe environment has been set\r\n __  __               _          _                      _         \r\n|  \\/  |             | |        | |     /\\             | |        \r\n| \\  / |   ___     __| |   ___  | |    /  \\     _ __   | |_   ___ \r\n| |\\/| |  / _ \\   / _  |  / _ \\ | |   / /\\ \\   |  __| | __ | / __|\r\n| |  | | | (_) | | (_| | |  __/ | |  / ____ \\  | |     | |_  \\__ \\\r\n|_|  |_|  \\___/   \\__ _|  \\___| |_| /_/    \\_\\ |_|      \\__| |___/\r\nUsing user ma-user\r\nEulerOS 2.0 (SP10), CANN-7.0.RC1 [V100R001C29],[V100R001C30],[V100R001C13],[V100R003C10],[V100R003C11]\r\nTips:\r\n1) Navigate to the target conda environment. For details, see /home/ma-user/README.\r\n2) Copy (Ctrl+C) and paste (Ctrl+V) on the jupyter terminal.\r\n3) Store your data in /home/ma-user/work, to which a persistent volume is mounted.\r\n(MindSpore) [ma-user work]$export no_proxy=127.0.0.1,localhost,172.16.*,iam.cn-southwest-2.huaweicloud.com,pip.modelarts.private.com\r\n(MindSpore) [ma-user work]$export NO_PROXY=127.0.0.1,localhost,172.16.*,iam.cn-southwest-2.huaweicloud.com,pip.modelarts.private.com\r\n(MindSpore) [ma-user work]$wget https://obs-9be7.obs.cn-east-2.myhuaweicloud.com/resource/s4%E6%96%87%E6%A1%A3/init_env.sh\r\n--2025-05-27 17:12:45--  https://obs-9be7.obs.cn-east-2.myhuaweicloud.com/resource/s4%E6%96%87%E6%A1%A3/init_env.sh\r\nResolving proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)... 192.168.0.33\r\nConnecting to proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)|192.168.0.33|:8083... connected.\r\nProxy request sent, awaiting response... 200 OK\r\nLength: 4617 (4.5K) [binary/octet-stream]\r\nSaving to: ‘init_env.sh’\r\n\r\ninit_env.sh                 100%[===========================================>]   4.51K  --.-KB/s    in 0s      \r\n\r\n2025-05-27 17:12:45 (117 MB/s) - ‘init_env.sh’ saved [4617/4617]\r\n\r\n(MindSpore) [ma-user work]$bash init_env.sh\r\nStart downloading toolkit package.\r\n--2025-05-27 17:12:55--  https://obs-9be7.obs.cn-east-2.myhuaweicloud.com/resource/cann_pkgs/Ascend-cann-toolkit_8.0.0.alpha003_linux-aarch64.run\r\nResolving proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)... 192.168.0.33\r\nConnecting to proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)|192.168.0.33|:8083... connected.\r\nProxy request sent, awaiting response... 200 OK\r\nLength: 2408159899 (2.2G) [binary/octet-stream]\r\nSaving to: ‘Ascend-cann-toolkit_8.0.0.alpha003_linux-aarch64.run’\r\n\r\nAscend-cann-toolkit_8.0.0.a 100%[===========================================>]   2.24G  41.5MB/s    in 46s     \r\n\r\n2025-05-27 17:13:41 (49.4 MB/s) - ‘Ascend-cann-toolkit_8.0.0.alpha003_linux-aarch64.run’ saved [2408159899/2408159899]\r\n\r\n CANN包部署完成                                           \r\nneed CMake compressed file exists.\r\n--2025-05-27 17:20:24--  https://obs-9be7.obs.cn-east-2.myhuaweicloud.com/AscendC/ResourceDependent/cmake-3.28.3-linux-aarch64.tar.gz\r\nResolving proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)... 192.168.0.33\r\nConnecting to proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)|192.168.0.33|:8083... connected.\r\nProxy request sent, awaiting response... 200 OK\r\nLength: 53885094 (51M) [application/gzip]\r\nSaving to: ‘cmake-3.28.3-linux-aarch64.tar.gz’\r\n\r\ncmake-3.28.3-linux-aarch64. 100%[===========================================>]  51.39M  35.9MB/s    in 1.4s    \r\n\r\n2025-05-27 17:20:26 (35.9 MB/s) - ‘cmake-3.28.3-linux-aarch64.tar.gz’ saved [53885094/53885094]\r\n\r\n(MindSpore) [ma-user work]$source ~/.bashrc\r\nThe environment has been set\r\n __  __               _          _                      _         \r\n|  \\/  |             | |        | |     /\\             | |        \r\n| \\  / |   ___     __| |   ___  | |    /  \\     _ __   | |_   ___ \r\n| |\\/| |  / _ \\   / _  |  / _ \\ | |   / /\\ \\   |  __| | __ | / __|\r\n| |  | | | (_) | | (_| | |  __/ | |  / ____ \\  | |     | |_  \\__ \\\r\n|_|  |_|  \\___/   \\__ _|  \\___| |_| /_/    \\_\\ |_|      \\__| |___/\r\nUsing user ma-user\r\nEulerOS 2.0 (SP10), CANN-7.0.RC1 [V100R001C29],[V100R001C30],[V100R001C13],[V100R003C10],[V100R003C11]\r\nTips:\r\n1) Navigate to the target conda environment. For details, see /home/ma-user/README.\r\n2) Copy (Ctrl+C) and paste (Ctrl+V) on the jupyter terminal.\r\n3) Store your data in /home/ma-user/work, to which a persistent volume is mounted.\r\n(MindSpore) [ma-user work]$cd /home/ma-user/work\r\n(MindSpore) [ma-user work]$git clone https://gitee.com/ascend/samples.git\r\nCloning into 'samples'...\r\nremote: Enumerating objects: 103489, done.\r\nremote: Counting objects: 100% (122/122), done.\r\nremote: Compressing objects: 100% (101/101), done.\r\nremote: Total 103489 (delta 39), reused 64 (delta 12), pack-reused 103367 (from 1)\r\nReceiving objects: 100% (103489/103489), 546.60 MiB | 23.44 MiB/s, done.\r\nResolving deltas: 100% (67622/67622), done.\r\nUpdating files: 100% (10975/10975), done.\r\n(MindSpore) [ma-user work]$cd samples/operator/ascendc/4_best_practices/\r\n0_flash_attention_score/             18_inter_core_fixpipe/               4_bank_conflict/\r\n10_reducesum/                        19_inter_core_balance_tail/          5_core_sync/\r\n11_cachemiss_matmul_object_combined/ 1_flash_attention_score_grad/        6_group_matmul/\r\n12_cachemiss_preload_dcci/           20_matmul_layout/                    7_vector_operater_tail_core/\r\n13_l2cache_hit_inter_core_tile/      21_all_gather_matmul_custom/         8_vector_operater_head_cost/\r\n14_reuse_ab_matrix/                  22_matmul_reduce_scatter_custom/     9_vector_operater_pipeline/\r\n15_mata_address_conflict/            23_matmul_all_reduce_custom/         README.md\r\n16_fixpipe/                          2_incre_flash_attention/             \r\n17_suitable_layout/                  3_prompt_flash_attention/            \r\n(MindSpore) [ma-user work]$cd samples/operator/ascendc/4_best_practices/23_matmul_all_reduce_custom/\r\n(MindSpore) [ma-user 23_matmul_all_reduce_custom]$ll\r\ntotal 28\r\ndrwxr-x--- 5 ma-user ma-group 4096 May 27 17:44 AclNNInvocation\r\n-rwxr-x--- 1 ma-user ma-group 1653 May 27 17:44 install.sh\r\ndrwxr-x--- 4 ma-user ma-group 4096 May 27 17:44 MatmulAllReduceCustom\r\n-rw-r----- 1 ma-user ma-group 2145 May 27 17:44 matmul_all_reduce_custom.json\r\n-rw-r----- 1 ma-user ma-group  681 May 27 17:44 matmul_all_reduce_demo_def.h\r\n-rw-r----- 1 ma-user ma-group 7793 May 27 17:44 README.md\r\n(MindSpore) [ma-user 23_matmul_all_reduce_custom]$bash install.sh \r\nERROR: SOC_VERSION should be in [Ascend910A Ascend910B Ascend310B1 Ascend310B2 Ascend310B3 Ascend310B4 Ascend310P1 Ascend310P3 Ascend910B1 Ascend910B2 Ascend910B3 Ascend910B4]\r\n(MindSpore) [ma-user 23_matmul_all_reduce_custom]$cd AclNNInvocation/\r\n(MindSpore) [ma-user AclNNInvocation]$ll\r\ntotal 20\r\ndrwxr-x--- 2 ma-user ma-group 4096 May 27 17:44 inc\r\n-rw-r----- 1 ma-user ma-group 3783 May 27 17:44 README.md\r\n-rw-r----- 1 ma-user ma-group 2401 May 27 17:44 run.sh\r\ndrwxr-x--- 2 ma-user ma-group 4096 May 27 17:44 scripts\r\ndrwxr-x--- 2 ma-user ma-group 4096 May 27 17:44 src\r\n(MindSpore) [ma-user AclNNInvocation]$bash run.sh -v Ascend910B4 -r npu\r\ngetopt: unrecognized option '-r'\r\n/home/ma-user/Ascend/ascend-toolkit/latest\r\nrm: cannot remove './input/*.bin': No such file or directory\r\nrm: cannot remove './output/*.bin': No such file or directory\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/work/samples/operator/ascendc/4_best_practices/23_matmul_all_reduce_custom/AclNNInvocation/scripts/gen_data.py\", line 7, in <module>\r\n    import torch\r\nModuleNotFoundError: No module named 'torch'\r\nERROR: generate input data failed!\r\n(MindSpore) [ma-user AclNNInvocation]$wget https://gitee.com/ascend/pytorch/releases/download/v6.0.rc1-pytorch1.11.0/torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl\r\n--2025-05-27 17:48:50--  https://gitee.com/ascend/pytorch/releases/download/v6.0.rc1-pytorch1.11.0/torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl\r\nResolving proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)... 192.168.0.33\r\nConnecting to proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)|192.168.0.33|:8083... connected.\r\nProxy request sent, awaiting response... 302 Found\r\nLocation: https://gitee.com/ascend/pytorch/attach_files/1741339/download/torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl [following]\r\n--2025-05-27 17:48:50--  https://gitee.com/ascend/pytorch/attach_files/1741339/download/torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl\r\nReusing existing connection to gitee.com:443.\r\nProxy request sent, awaiting response... 302 Found\r\nLocation: https://foruda.gitee.com/attach_file/1713446665299008122/torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl?token=b22c0f9ba2ed70c26fbb9fca7fc2ff9b&ts=1748339331&attname=torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl [following]\r\n--2025-05-27 17:48:51--  https://foruda.gitee.com/attach_file/1713446665299008122/torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl?token=b22c0f9ba2ed70c26fbb9fca7fc2ff9b&ts=1748339331&attname=torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl\r\nConnecting to proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)|192.168.0.33|:8083... connected.\r\nProxy request sent, awaiting response... 200 OK\r\nLength: 7140395 (6.8M) [application/zip]\r\nSaving to: ‘torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl’\r\n\r\ntorch_npu-1.11.0.post11-cp3 100%[===========================================>]   6.81M   568KB/s    in 13s     \r\n\r\n2025-05-27 17:49:04 (537 KB/s) - ‘torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl’ saved [7140395/7140395]\r\n\r\n(MindSpore) [ma-user AclNNInvocation]$pip3 install torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl\r\nLooking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\r\nERROR: torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl is not a supported wheel on this platform.\r\nWARNING: You are using pip version 21.0.1; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\r\n(MindSpore) [ma-user AclNNInvocation]$pip3 install torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl --user\r\nLooking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\r\nERROR: torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl is not a supported wheel on this platform.\r\nWARNING: You are using pip version 21.0.1; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\r\n(MindSpore) [ma-user AclNNInvocation]$ll\r\ntotal 6996\r\ndrwxr-x--- 2 ma-user ma-group    4096 May 27 17:44 inc\r\n-rw-r----- 1 ma-user ma-group    3783 May 27 17:44 README.md\r\n-rw-r----- 1 ma-user ma-group    2401 May 27 17:44 run.sh\r\ndrwxr-x--- 2 ma-user ma-group    4096 May 27 17:44 scripts\r\ndrwxr-x--- 2 ma-user ma-group    4096 May 27 17:44 src\r\n-rw-r----- 1 ma-user ma-group 7140395 May 27 17:49 torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl\r\n(MindSpore) [ma-user AclNNInvocation]$pip3 install torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl --user\r\nLooking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\r\nERROR: torch_npu-1.11.0.post11-cp38-cp38-linux_aarch64.whl is not a supported wheel on this platform.\r\nWARNING: You are using pip version 21.0.1; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\r\n(MindSpore) [ma-user AclNNInvocation]$wget https://gitee.com/ascend/pytorch/releases/download/v6.0.rc1-pytorch1.11.0/torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl\r\n--2025-05-27 17:50:36--  https://gitee.com/ascend/pytorch/releases/download/v6.0.rc1-pytorch1.11.0/torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl\r\nResolving proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)... 192.168.0.33\r\nConnecting to proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)|192.168.0.33|:8083... connected.\r\nProxy request sent, awaiting response... 302 Found\r\nLocation: https://gitee.com/ascend/pytorch/attach_files/1741342/download/torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl [following]\r\n--2025-05-27 17:50:36--  https://gitee.com/ascend/pytorch/attach_files/1741342/download/torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl\r\nReusing existing connection to gitee.com:443.\r\nProxy request sent, awaiting response... 302 Found\r\nLocation: https://foruda.gitee.com/attach_file/1713446700553891500/torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl?token=6cce4651a22f744f93c7023fde331504&ts=1748339436&attname=torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl [following]\r\n--2025-05-27 17:50:36--  https://foruda.gitee.com/attach_file/1713446700553891500/torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl?token=6cce4651a22f744f93c7023fde331504&ts=1748339436&attname=torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl\r\nConnecting to proxy-notebook.modelarts.com (proxy-notebook.modelarts.com)|192.168.0.33|:8083... connected.\r\nProxy request sent, awaiting response... 200 OK\r\nLength: 7149577 (6.8M) [application/zip]\r\nSaving to: ‘torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl’\r\n\r\ntorch_npu-1.11.0.post11-cp3 100%[===========================================>]   6.82M   566KB/s    in 13s     \r\n\r\n2025-05-27 17:50:50 (539 KB/s) - ‘torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl’ saved [7149577/7149577]\r\n\r\n(MindSpore) [ma-user AclNNInvocation]$pip3 install torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl --userLooking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\r\nProcessing ./torch_npu-1.11.0.post11-cp39-cp39-linux_aarch64.whl\r\nInstalling collected packages: torch-npu\r\nSuccessfully installed torch-npu-1.11.0.post11\r\nWARNING: You are using pip version 21.0.1; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\r\n(MindSpore) [ma-user AclNNInvocation]$python3 -c \"import torch;import torch_npu;print(torch_npu.npu.is_available())\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'torch'\r\n(MindSpore) [ma-user AclNNInvocation]$python3 -c \"import torch;import torch_npu;print(torch_npu.npu.is_available())\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'torch'\r\n(MindSpore) [ma-user AclNNInvocation]$https://download.pytorch.org/whl/cpu/torch-2.2.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\r\nbash: https://download.pytorch.org/whl/cpu/torch-2.2.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl: No such file or directory\r\n(MindSpore) [ma-user AclNNInvocation]$pip install torch\r\nLooking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\r\nCollecting torch\r\n  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/torch/2.7.0/torch-2.7.0-cp39-cp39-manylinux_2_28_aarch64.whl (99.2 MB)\r\n     |████████████████████████████████| 99.2 MB 17.9 MB/s \r\nRequirement already satisfied: jinja2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (3.1.2)\r\nRequirement already satisfied: fsspec in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (2023.12.2)\r\nCollecting typing-extensions>=4.10.0\r\n  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/typing-extensions/4.13.2/typing_extensions-4.13.2-py3-none-any.whl (45 kB)\r\n     |████████████████████████████████| 45 kB 51.3 MB/s \r\nRequirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (3.13.1)\r\nCollecting sympy>=1.13.3\r\n  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/sympy/1.14.0/sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n     |████████████████████████████████| 6.3 MB 41.8 MB/s \r\nRequirement already satisfied: networkx in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (3.2.1)\r\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\r\nInstalling collected packages: typing-extensions, sympy, torch\r\n  Attempting uninstall: typing-extensions\r\n    Found existing installation: typing-extensions 4.9.0\r\n    Uninstalling typing-extensions-4.9.0:\r\n      Successfully uninstalled typing-extensions-4.9.0\r\n  Attempting uninstall: sympy\r\n    Found existing installation: sympy 1.4\r\n    Uninstalling sympy-1.4:\r\n      Successfully uninstalled sympy-1.4\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nmodelarts 1.4.28 requires lxml==5.1.0, but you have lxml 4.9.3 which is incompatible.\r\nmodelarts 1.4.28 requires matplotlib==3.5.2, but you have matplotlib 3.5.1 which is incompatible.\r\nmodelarts 1.4.28 requires prettytable<=3.7.0, but you have prettytable 3.9.0 which is incompatible.\r\nmodelarts 1.4.28 requires requests==2.31.0, but you have requests 2.27.1 which is incompatible.\r\nmodelarts 1.4.28 requires typing-extensions==4.7.1, but you have typing-extensions 4.13.2 which is incompatible.\r\nmodelarts 1.4.28 requires urllib3==1.26.18, but you have urllib3 1.26.7 which is incompatible.\r\nSuccessfully installed sympy-1.14.0 torch-2.7.0 typing-extensions-4.13.2\r\nWARNING: You are using pip version 21.0.1; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\r\n(MindSpore) [ma-user AclNNInvocation]$python3 -c \"import torch;import torch_npu;print(torch_npu.npu.is_available())\"\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/__init__.py\", line 32, in <module>\r\n    import torch_npu.npu\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/npu/__init__.py\", line 44, in <module>\r\n    from .utils import (is_initialized, _lazy_call, _lazy_init, init, set_dump,\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/npu/utils.py\", line 25, in <module>\r\n    import torch._six\r\nModuleNotFoundError: No module named 'torch._six'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/__init__.py\", line 34, in <module>\r\n    from torch_npu.utils.error_code import ErrCode, pta_error\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/utils/__init__.py\", line 23, in <module>\r\n    from .dataloader import add_dataloader_method\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/utils/dataloader.py\", line 28, in <module>\r\n    from torch._six import string_classes\r\nModuleNotFoundError: No module named 'torch._six'\r\n(MindSpore) [ma-user AclNNInvocation]$pip install torch._sixLooking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\r\nERROR: Could not find a version that satisfies the requirement torch._six\r\nERROR: No matching distribution found for torch._six\r\nWARNING: You are using pip version 21.0.1; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\r\n(MindSpore) [ma-user AclNNInvocation]$bash run.sh -v Ascend910B4 -r npugetopt: unrecognized option '-r'\r\n/home/ma-user/Ascend/ascend-toolkit/latest\r\nrm: cannot remove './input/*.bin': No such file or directory\r\nrm: cannot remove './output/*.bin': No such file or directory\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/__init__.py\", line 32, in <module>\r\n    import torch_npu.npu\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/npu/__init__.py\", line 44, in <module>\r\n    from .utils import (is_initialized, _lazy_call, _lazy_init, init, set_dump,\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/npu/utils.py\", line 25, in <module>\r\n    import torch._six\r\nModuleNotFoundError: No module named 'torch._six'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/work/samples/operator/ascendc/4_best_practices/23_matmul_all_reduce_custom/AclNNInvocation/scripts/gen_data.py\", line 8, in <module>\r\n    import torch_npu\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/__init__.py\", line 34, in <module>\r\n    from torch_npu.utils.error_code import ErrCode, pta_error\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/utils/__init__.py\", line 23, in <module>\r\n    from .dataloader import add_dataloader_method\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/utils/dataloader.py\", line 28, in <module>\r\n    from torch._six import string_classes\r\nModuleNotFoundError: No module named 'torch._six'\r\nERROR: generate input data failed!\r\n(MindSpore) [ma-user AclNNInvocation]$pip3 install torch==2.2.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\r\nLooking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\r\nLooking in links: https://download.pytorch.org/whl/torch_stable.html\r\nERROR: Could not find a version that satisfies the requirement torch==2.2.0+cpu\r\nERROR: No matching distribution found for torch==2.2.0+cpu\r\nWARNING: You are using pip version 21.0.1; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\r\n(MindSpore) [ma-user AclNNInvocation]$pip install --upgrade torch torchvision torchaudio\r\nLooking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\r\nRequirement already satisfied: torch in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (2.7.0)\r\nCollecting torchvision\r\n  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/torchvision/0.22.0/torchvision-0.22.0-cp39-cp39-manylinux_2_28_aarch64.whl (2.5 MB)\r\n     |████████████████████████████████| 2.5 MB 49.4 MB/s \r\nCollecting torchaudio\r\n  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/torchaudio/2.7.0/torchaudio-2.7.0-cp39-cp39-manylinux_2_28_aarch64.whl (1.7 MB)\r\n     |████████████████████████████████| 1.7 MB 53.0 MB/s \r\nRequirement already satisfied: typing-extensions>=4.10.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (4.13.2)\r\nRequirement already satisfied: networkx in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (3.2.1)\r\nRequirement already satisfied: sympy>=1.13.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (1.14.0)\r\nRequirement already satisfied: jinja2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (3.1.2)\r\nRequirement already satisfied: fsspec in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (2023.12.2)\r\nRequirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torch) (3.13.1)\r\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torchvision) (10.0.1)\r\nRequirement already satisfied: numpy in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from torchvision) (1.22.0)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\r\nInstalling collected packages: torchvision, torchaudio\r\nSuccessfully installed torchaudio-2.7.0 torchvision-0.22.0\r\nWARNING: You are using pip version 21.0.1; however, version 25.1.1 is available.\r\nYou should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\r\n(MindSpore) [ma-user AclNNInvocation]$bash run.sh -v Ascend910B4 -r npugetopt: unrecognized option '-r'\r\n/home/ma-user/Ascend/ascend-toolkit/latest\r\nrm: cannot remove './input/*.bin': No such file or directory\r\nrm: cannot remove './output/*.bin': No such file or directory\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/__init__.py\", line 32, in <module>\r\n    import torch_npu.npu\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/npu/__init__.py\", line 44, in <module>\r\n    from .utils import (is_initialized, _lazy_call, _lazy_init, init, set_dump,\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/npu/utils.py\", line 25, in <module>\r\n    import torch._six\r\nModuleNotFoundError: No module named 'torch._six'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ma-user/work/samples/operator/ascendc/4_best_practices/23_matmul_all_reduce_custom/AclNNInvocation/scripts/gen_data.py\", line 8, in <module>\r\n    import torch_npu\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/__init__.py\", line 34, in <module>\r\n    from torch_npu.utils.error_code import ErrCode, pta_error\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/utils/__init__.py\", line 23, in <module>\r\n    from .dataloader import add_dataloader_method\r\n  File \"/home/ma-user/.local/lib/python3.9/site-packages/torch_npu/utils/dataloader.py\", line 28, in <module>\r\n    from torch._six import string_classes\r\nModuleNotFoundError: No module named 'torch._six'\r\nERROR: generate input data failed!\r\n\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n",
        "url": "https://gitee.com/ascend/samples/issues/ICAXTY",
        "clean_data": "ModuleNotFoundError  No module named  torch  six      安装Ascend CANN 8 0 0 alpha003与torch npu 1 11 0 post11时出现依赖错误。原因： torch npu 依赖的 torch  six 模块缺失，提示旧版PyTorch 1 11 0 与安装的主版PyTorch 2 7 0 版本不兼容。需确保同时安装适配版本的PyTorch、torch npu，并验证Python环境 CP39 与Ascend工具链的兼容性。",
        "created_at": "2025-05-27T18:02:29+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-06T11:47:03+08:00"
    },
    {
        "id": 35,
        "source_id": "20078156",
        "title": "[Question|问题咨询]: 如果想要优化核间、vector的策略，可以调整哪些部分的参数呢",
        "body": "### 问题描述\r\n\r\n如果想要优化核间、vector的策略，可以调整哪些部分的参数呢\r\n\r\n### 所属算子\r\n\r\nFFN\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops-adv/issues/IBYCEK",
        "clean_data": "优化FFN算子的核间并行度和Vector策略可通过调整以下参数：核间距 tile size 、向量分段 vector len block size 、伪指令点数、数据对齐方式、矩阵分块策略等关键参数。这些参数直接影响算子在多核架构下的执行效率。",
        "created_at": "2025-04-02T17:19:06+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-02T17:45:28+08:00"
    },
    {
        "id": 113,
        "source_id": "20732772",
        "title": "CVE-2025-30167",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-30167](https://nvd.nist.gov/vuln/detail/CVE-2025-30167)\n漏洞归属组件：jupyter\n漏洞归属的版本：1.0.0\nCVSS V3分值：\n&emsp;BaseScore: 7.3 High\n&emsp;Vector: CVSS:3.1/AV:L/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H\n\n漏洞简述：\nJupyter Core is a package for the core common functionality of Jupyter projects. When using Jupyter Core prior to version 5.8.0 on Windows, the shared `%PROGRAMDATA%` directory is searched for configuration files (`SYSTEM_CONFIG_PATH` and `SYSTEM_JUPYTER_PATH`), which may allow users to create configuration files affecting other users. Only shared Windows systems with multiple users and unprotected `%PROGRAMDATA%` are affected. Users should upgrade to Jupyter Core version 5.8.0 or later to receive a patch. Some other mitigations are available. As administrator, modify the permissions on the `%PROGRAMDATA%` directory so it is not writable by unauthorized users; or as administrator, create the `%PROGRAMDATA%\\jupyter` directory with appropriately restrictive permissions; or as user or administrator, set the `%PROGRAMDATA%` environment variable to a directory with appropriately restrictive permissions (e.g. controlled by administrators _or_ the current user).\n\n漏洞公开时间：2025-06-04 01:15:21\n漏洞创建时间：2025-06-04 09:55:10\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-30167\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICCDIC",
        "clean_data": "CVE 2025 30167  Jupyter Core权限漏洞导致多用户环境风险，升级至5 8 0 或限制 PROGRAMDATA 目录权限可修复。影响版本 5 8 0，CVSS 7 3 High AV L AC L PR L UI R 。核心问题：Windows系统共享 PROGRAMDATA 路径时，未授权用户可通过创建配置文件影响他人。缓解方案：修改 PROGRAMDATA  jupyter目录权限为不可写 不可读；或设置环境变量指向受控权限目录。",
        "created_at": "2025-06-04T09:55:10+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": [
            "[]"
        ],
        "source_closed": false,
        "updated_at": "2025-06-10T11:25:07+08:00"
    },
    {
        "id": 625,
        "source_id": "20808962",
        "title": "triton.language.math缺少isfinited属性",
        "body": "报错内容：AttributeError: module 'triton.language.math' has no attribute 'isfinited'\r\n",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICE0AQ",
        "clean_data": "triton language math模块缺失isfinited属性导致AttributeError",
        "created_at": "2025-06-10T15:24:44+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-10T15:24:44+08:00"
    },
    {
        "id": 34,
        "source_id": "20059898",
        "title": "Transpose算子",
        "body": "Transpose算子",
        "url": "https://gitee.com/ascend/canndev/issues/IBXYBE",
        "clean_data": "Transpose算子 请补充具体问题描述 如使用指导 性能优化 模型转换异常等",
        "created_at": "2025-04-01T15:27:56+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-01T15:31:04+08:00"
    },
    {
        "id": 570,
        "source_id": "20780854",
        "title": "CVE-2021-41945",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-41945](https://nvd.nist.gov/vuln/detail/CVE-2021-41945)\n漏洞归属组件：httpx\n漏洞归属的版本：0.19.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nEncode OSS httpx &lt; 0.23.0 is affected by improper input validation in `httpx.URL`, `httpx.Client` and some functions using `httpx.URL.copy_with`.\n\n漏洞公开时间：2022-04-28 22:15:00\n漏洞创建时间：2025-06-08 00:20:38\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-41945\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDELY",
        "clean_data": "CVE 2021 41945：httpx   0 23 0 的  httpx URL 、 httpx Client  和部分使用  httpx URL copy with  的函数存在输入验证问题，建议升级至 0 23 0 或更高版本。",
        "created_at": "2025-06-08T00:20:38+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:20:38+08:00"
    },
    {
        "id": 81,
        "source_id": "20568260",
        "title": "Atlas 200I a2 dk 执行.h264格式视屏解码时报错",
        "body": "一、问题现象（附报错日志上下文）：\r\nAtlas 200I a2 dk 执行.h264格式视屏解码时报错\r\n执行samples样例：[yolov3_mask_detection_video]时报错(https://gitee.com/ascend/samples/tree/master/python/level2_simple_inference/2_object_detection/YOLOV3_mask_detection_video)\r\n![报错](https://foruda.gitee.com/images/1747643621891916228/daf66873_13683452.png \"屏幕截图\")\r\n\r\n\r\n二、软件版本:\r\n-- CANN 版本 (CANN 7.0.rc1):  \r\n--Pytorch 版本:1.13.0\r\n--Python 版本 (e.g., Python 3.9.2):\r\n--操作系统版本 (e.g., Ubuntu 22.04.5 LTS):\r\n\r\n三、测试步骤：\r\n按照：https://gitee.com/ascend/samples/tree/master/python/level2_simple_inference/2_object_detection/YOLOV3_mask_detection_video。\r\n进行执行的。求助！！！！！！！！！！！！！！！！！！！！！！！\r\n\r\n\r\n四、日志信息:\r\n(base) root@davinci-mini:~/samples/python/level2_simple_inference/2_object_detection/YOLOV3_m                ask_detection_video/scripts# bash samples_run.sh\r\n[INFO] The sample starts to run\r\nCurrent environment valid ip list:\r\n        127.0.0.1\r\n        192.168.137.102\r\n        192.168.137.53\r\n        192.168.0.2\r\nPlease choose one to show the presenter in browser:192.168.137.102\r\n[INFO]  init resource stage:\r\n[INFO]  Init resource success\r\n[INFO]  Init model resource start...\r\n[INFO]  AclLiteModel create model output dataset:\r\n[INFO]  malloc output 0, size 21120\r\n[INFO]  malloc output 1, size 84480\r\n[INFO]  malloc output 2, size 337920\r\n[INFO]  Create model output dataset success\r\n[INFO]  Init model resource success\r\n[INFO]  presenter server ip 192.168.137.102, port 7006, channel name video, type 1\r\n[INFO] The program runs successfully, Please visit http://192.168.137.102:7007 for display se                rver!\r\nEnter any command to stop the application:[INFO]        Received open channel respone\r\n[INFO]  Open status is 3 now\r\n[INFO]  presenter agent change connect_status to 3\r\n[INFO]  Get ../data/mask.h264 infomation: width 1920, height 1080, profile 100, codec h264, e                ntype 3\r\n[INFO]  Ready to decode ../data/mask.h264...\r\n[INFO]  Start decode ../data/mask.h264 frames\r\n[INFO]  Pyav decode finish\r\n[INFO]  No decode frame in queue anymore\r\nread None image, break\r\nRelease yolov3 resource finished\r\n[INFO]  acl resource release all resource\r\n[INFO]  dvpp resource release success\r\n[INFO]  AclLiteModel release source success\r\n[INFO]  acl resource release stream\r\n[INFO]  acl resource release context\r\n[INFO]  Reset acl device 0\r\n[INFO]  Release acl resource success\r\n[INFO]  Presenter channel close...\r\n[INFO]  Receive presenter agent exit notification, queue size 0\r\n[ERROR] Heard beat thread exit\r\n",
        "url": "https://gitee.com/ascend/samples/issues/IC8UKK",
        "clean_data": "标题关联精简描述：     Atlas 200I a2 DK运行YOLOv3口罩检测视频示例时，解码 h264文件报错并退出心跳线程。涉及硬件可能不支持当前h264文件的编码参数 如profile 100、分辨率1920x1080 ，或Pyav解码器与CANN 7 0 rc1版本的兼容性问题。建议检查视频格式兼容性、确认硬件支持参数、验证Pyav依赖，或升级CANN版本至正式版以排查。",
        "created_at": "2025-05-19T16:47:29+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-21T14:27:08+08:00"
    },
    {
        "id": 177,
        "source_id": "0243177061603902064",
        "title": "在运行bash.sh时出现失败问题",
        "body": "<div class=\"cke-article\"><p><span class=\"easyimage easyimage-full\"><img alt=\"cke_141.jpeg\" src=\"cid:pic_0\"></span></p>  <p>出现了权限目录生成失败的问题，原因是由于在生成该脚本时目录出现问题，在权限给予后不会再进行报错</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0243177061603902064-1-1.html",
        "clean_data": "运行bash sh脚本失败，因生成目录时权限配置异常。授予权限后可消除报错。需在目录生成阶段确保权限正确或手动重赋权。",
        "created_at": "2025-03-11T07:46:44+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-11T07:46:44+08:00"
    },
    {
        "id": 114,
        "source_id": "20733906",
        "title": "torchvision.ops.nms 报错",
        "body": "一、问题现象（附报错日志上下文）：\n[ERROR] RUNTIME(46536,python3):2025-06-04-02:06:46.815.082 [davinic_kernel_task.cc:1144]46536 PrintErrorInfoForDavinciTask:[FINAL][FINAL]Aicore kernel execute failed, device_id=0, stream_id=18, report_stream_id=18, task_id=1994, flip_num=0, fault kernel_name=RepeatInterleave_7a09f5b7af4126487a7f726a9aac7548_high_performance__kernel0, fault kernel info ext=RepeatInterleave_7a09f5b7af4126487a7f726a9aac7548_high_performance__kernel0, program id=61, hash=685125912937150811.\n[ERROR] RUNTIME(46536,python3):2025-06-04-02:06:46.815.129 [davinic_kernel_task.cc:1083]46536 GetArgsInfo:[FINAL][FINAL][AIC_INFO] args(0 to 20) after execute:0x12c07fdffc00, 0x12c07fdfe600, 0x12c07fdffe00, 0x12c1005f2828, 0x12c0c0011000, 0x1, 0xc, 0x1, 0x1, 0x1, 0x1, 0x1, 0x1, 0x1, 0x1, 0x1, 0x1, 0x8, 0, 0,  \n[ERROR] RUNTIME(46536,python3):2025-06-04-02:06:46.815.140 [davinic_kernel_task.cc:1083]46536 GetArgsInfo:[FINAL][FINAL][AIC_INFO] args(20 to 21) after execute:0\n### 最终错误原因\n核心问题： RepeatInterleave 算子在NPU上执行时发生了 向量核心异常（vector core exception）\n\n### 📋 详细错误信息\n1. 错误算子： RepeatInterleave_7a09f5b7af4126487a7f726a9aac7548_high_performance__kernel0\n2. 错误类型：\n   \n   - 错误代码： 0x800000\n   - 错误描述： The DDR address of the MTE instruction is out of range （MTE指令的DDR地址超出范围）\n3. 具体错误位置：\n   \n   - 设备ID：0\n   - 流ID：18\n   - 任务ID：1994\n   - 核心ID：9\n4. 关键错误信息：\n```\n[ERROR] RUNTIME: The DDR address of the MTE instruction is out of range.\n[ERROR] RUNTIME: Aicore kernel execute failed, fault \nkernel_name=RepeatInterleave_7a09f5b7af4126487a7f726a9aac7548_high_performance__\nkernel0\n[ERROR] RUNTIME: Stream Synchronize failed, retCode=0x31, [vector core \nexception]\n```\n### 🔍 问题根本原因\n这是一个 内存访问越界错误 ：\n\n- RepeatInterleave 算子在执行过程中，MTE（Memory Transfer Engine）指令尝试访问的DDR内存地址超出了允许的范围\n- 这导致了向量核心异常，进而引发整个计算流的失败\n \n\n二、软件版本:\nCANN 版本： 24.1.rc2\n\n深度学习框架版本：\n\n- PyTorch: 2.5.1\n- torch-npu: 2.5.1\n- torchvision: 0.20.1\n- torchvision-npu: 0.21.0+gite24f93f\nPython版本： Python 3.10.12\n\n操作系统版本： Ubuntu 22.04.4 LTS (Jammy Jellyfish) 1 2\n\n驱动版本： 24.1.rc2\n\n- ascendhal_version: 7.35.23\n- aicpu_version: 1.0\n- Innerversion: V100R001C18SPC001B233\n- package_version: 24.1.rc2\n\n三、测试步骤：\n单个算子ops.nms 测试没有问题，显示 npu 比 cpu 速度快很多，然后替换 https://github.com/facebookresearch/detectron2/blob/main/detectron2/layers/nms.py 这个里面的 nms 算子 ，只添加 import torchvision_npu 这个代码，出现了上面的报错 \n\n\n四、日志信息:\n\n\n",
        "url": "https://gitee.com/ascend/vision/issues/ICCEDU",
        "clean_data": "torchvision ops nms在NPU上执行异常：RepeatInterleave算子DDR地址越界     替换detectron2中nms算子为torchvision npu后，RepeatInterleave内核因MTE指令访问DDR地址超出范围报错 0x800000 ，导致向量核心异常。独立测试nms算子无问题，确认问题与算子替换或CANN 24 1 rc2版本兼容性相关。需检查torchvision npu版本与CANN的适配性，或调整算子调用参数避免内存异常。",
        "created_at": "2025-06-04T10:33:32+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-11T10:58:09+08:00"
    },
    {
        "id": 115,
        "source_id": "20735056",
        "title": "onnx转om报错，tiling offset out of range, index: 32",
        "body": "一、问题现象（附报错日志上下文）：\r\n\r\nVITS模型onnx模型转om时报错：\r\n\r\n1）动态shape转换时：\r\n命令：\r\natc --framework=5 \\\r\n--soc_version=Ascend310P3 \\\r\n--model vits-chinese.onnx \\\r\n--output vits-chinese \\\r\n--input_shape=\"x:1,-1;x_length:1\" \\\r\n--dynamic_dims=\"20;40\" \\\r\n--input_format=ND\r\n\r\n报错：\r\nATC run failed, Please check the detail log, Try 'atc --help' for more information\r\nE10042: [PID: 39589] 2025-06-03-17:41:10.827.922 GenerateOfflineModel execute failed.\r\n        TraceBack (most recent call last):\r\n        Multi-batch not support middle dynamic shape. CurrentShape: [-2]. Please check nodes in graph which cause dynamic shape.[FUNC:UpdateOutputFromSubgraphsForMultiDims][FILE:infershape_pass.cc][LINE:363]\r\n        Node ascend_mbatch_shape_case update output 0 tensor desc failed. ret: 1343225857[FUNC:UpdateParentNodeContainsSubgraphs][FILE:infer_base_pass.cc][LINE:345]\r\n        process pass InferShapePass on node:ascend_mbatch_shape_case failed, ret:4294967295[FUNC:RunPassesOnNode][FILE:base_pass.cc][LINE:563]\r\n        build graph failed, graph id:0, ret:1343242270[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1618]\r\n        GenerateOfflineModel execute failed.\r\n\r\n2）固定shape转换时：\r\n可以得到om模型，但无法用netron打开，且模型大小变大（107M->177M）\r\n\r\n命令：\r\natc --framework=5 \\\r\n--soc_version=Ascend310P3 \\\r\n--model vits-chinese.onnx \\\r\n--output vits-chinese \\\r\n--input_shape=\"x:1,20;x_length:1\"\r\n\r\n日志：\r\nATC start working now, please wait for a moment.\r\n.Warning: tiling offset out of range, index: 32\r\n..Warning: set_tiling_params does not take effect because get_op_mode is dynamic\r\n.Warning: set_tiling_params does not take effect because get_op_mode is dynamic\r\n.........................................\r\nATC run success, welcome to the next use.\r\nW11001: [PID: 68409] 2025-06-03-21:56:04.806.946 Op [/enc_p/encoder/attn_layers.0/Pow] does not hit the high-priority operator information library, which might result in compromised performance.\r\nW11001: [PID: 68409] 2025-06-03-21:56:04.822.515 Op [/enc_p/encoder/attn_layers.1/Pow] does not hit the high-priority operator information library, which might result in compromised performance.\r\nW11001: [PID: 68409] 2025-06-03-21:56:04.835.599 Op [/enc_p/encoder/attn_layers.2/Pow] does not hit the high-priority operator information library, which might result in compromised performance.\r\nW11001: [PID: 68409] 2025-06-03-21:56:04.848.592 Op [/enc_p/encoder/attn_layers.3/Pow] does not hit the high-priority operator information library, which might result in compromised performance.\r\nW11001: [PID: 68409] 2025-06-03-21:56:04.861.530 Op [/enc_p/encoder/attn_layers.4/Pow] does not hit the high-priority operator information library, which might result in compromised performance.\r\nW11001: [PID: 68409] 2025-06-03-21:56:04.874.441 Op [/enc_p/encoder/attn_layers.5/Pow] does not hit the high-priority operator information library, which might result in compromised performance.\r\n\r\n使用netron打开时：\r\n![输入图片说明](https://foruda.gitee.com/images/1749006175918947168/20472693_15902054.png \"屏幕截图\")\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  8.0.RC3.20\r\n--Tensorflow/Pytorch/MindSpore 版本: Pytorch 2.1.0\r\n--Python 版本 (e.g., Python 3.7.5): Python 3.9.10\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04): Linux HUAWEIMCU 5.10.0-182.0.0.95.h2692.eulerosv2r13.aarch64\r\n",
        "url": "https://gitee.com/ascend/samples/issues/ICCF9S",
        "clean_data": "标题：onnx转om报错，tiling offset out of range  index  32  问题描述： 1  VITS模型动态shape转换失败，报错 Multi batch not support middle dynamic shape ； 2  固定shape转换虽成功但存在三类异常：a  tiling offset越界 index32 警告；b  缺失高优先级算子命中警告 6个Pow节点 ；c  模型体积异常增大38  107M  177M 且Netron无法解析； 3  输入参数：Ascend310P3芯片，PyTorch2 1 0框架，CANN8 0 RC3 20  解决方案简述： 需检查动态shape配置是否包含中间维度动态性，固定shape转换时确认Pow节点是否影响性能，通过atc日志定位未解析算子并提交复现环境信息",
        "created_at": "2025-06-04T11:13:15+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-11T09:36:30+08:00"
    },
    {
        "id": 552,
        "source_id": "20777601",
        "title": "DVPP + AIPP前处理和OpenCV前处理不一致，导致om模型推理结果异常",
        "body": "一、问题现象（附报错日志上下文）：\n参考inference/modelInference/sampleYOLOV7案例，使用DVPP + AIPP前处理 和 OPENCV前处理结果不一致。\n前处理：\n    读取jpg图片， resize为1，3，224，224， 归一化 /255\n\n1、openCV前处理代码:\n~~~\ncv::Mat img = cv::imread(fileName);\nResult SampleHelmetCls::ProcessInput(cv::Mat &img)\n{\n    cv::Mat resized_img;\n    cv::resize(img, resized_img, cv::Size(MODEL_WIDTH, MODEL_HEIGHT), 0, 0, cv::INTER_LINEAR);\n\n    // HWC -> CHW;  BGR -> RGB\n    int32_t i = 0;\n\tfor (int32_t row = 0; row < MODEL_HEIGHT; ++row) {\n\t\t//逐行对象素值和图像通道进行处理\n\t\t//resized_img.step=widthx3 就是每一行有width个3通道的值\n\t\t//第row行\n\t\tuchar* uc_pixel = resized_img.data + row * resized_img.step;\n\t\tfor (int32_t col = 0; col < MODEL_WIDTH; ++col)\n\t\t{\n\t\t\t//第col列\n\t\t\t//提取第第row行第col列数据进行处理\n\t\t\t//像素值处理\n\t\t\tprocess_imgdata[i] = (float)uc_pixel[2] / 255.0;\n\t\t\t//通道变换\n\t\t\tprocess_imgdata[i + MODEL_HEIGHT * MODEL_WIDTH] = (float)uc_pixel[1] / 255.0;\n\t\t\tprocess_imgdata[i + 2 * MODEL_HEIGHT * MODEL_WIDTH] = (float)uc_pixel[0] / 255.0;\n\t\t\tuc_pixel += 3;//表示进行下一列\n\t\t\t++i;//表示在3个通道中的第i个位置，rgb三个通道的值是分开的，如r123456g123456b123456\n\t\t}\n\t}\n\n    preprocessResult_.chw_data = process_imgdata;\n\n    return SUCCESS;\n}\n~~~\n\n2、DVPP + AIPP前处理代码:\n~~~\nResult SampleHelmetCls::ProcessInputAscend(string testImgPath){\n    // read image from file\n    ImageData image;\n    AclLiteError ret = ReadJpeg(image, testImgPath);\n\n    // copy image from host to dvpp\n    ImageData imageDevice;\n    ret = CopyImageToDevice(imageDevice, image, runMode_, MEMORY_DVPP);\n\n    // image decoded from JPEG format to YUV\n    ImageData yuvImage;\n    ret = imageProcess_.JpegD(yuvImage, imageDevice);\n\n    // zoom image to modelWidth_ * modelHeight_\n    ret = imageProcess_.Resize(resizedImage_, yuvImage, modelWidth_, modelHeight_);\n    return SUCCESS;\n}\n~~~\naipp.cfg:\n~~~\naipp_op {\n    aipp_mode: static\n    input_format : YUV420SP_U8\n    src_image_size_w : 224\n    src_image_size_h : 224\n\n    csc_switch : true\n    rbuv_swap_switch : true\n    matrix_r0c0 : 256\n    matrix_r0c1 : 0\n    matrix_r0c2 : 359\n    matrix_r1c0 : 256\n    matrix_r1c1 : -88\n    matrix_r1c2 : -183\n    matrix_r2c0 : 256\n    matrix_r2c1 : 454\n    matrix_r2c2 : 0\n    input_bias_0 : 0\n    input_bias_1 : 128\n    input_bias_2 : 128\n\n    mean_chn_0: 0\n    mean_chn_1: 0\n    mean_chn_2: 0\n    var_reci_chn_0: 0.0039215686274509803921568627451\n    var_reci_chn_1: 0.0039215686274509803921568627451\n    var_reci_chn_2: 0.0039215686274509803921568627451\n}\n~~~\n\n测试结果：\nopencv推理结果\n    [INFO]  image name: ../data/test1.jpg\n    预测类别:0.918457  0.044861  0.036591\n    戴安全帽\n\nDVPP+AIPP推理结果：\n    [INFO]  image name: ../data/test1.jpg\n    预测类别:0.930176  0.050262  0.019760\n    戴安全帽\n\n预测类别为om模型的输出3个float32，两边不一致\n\n\n二、软件版本:\n-- CANN 版本 (8.2RC1):\n-- atlas 200I A2  \n\n\n\n",
        "url": "https://gitee.com/ascend/samples/issues/ICDC3L",
        "clean_data": "DVPP AIPP与OpenCV前处理流程导致YOLOV7模型推理结果不一致问题： OpenCV处理流程执行 RGB通道转换 255归一化 CHW格式输出 ，DVPP AIPP处理流程采用 aipp cfg配置矩阵CSC变换 通道偏置为128 255归一化 。两种预处理方法在颜色空间转换 YUV420SP vs BGR 、归一化实现方式 1 255 vs 0 003921568    、图像缩放算法 Interpolation方法未明确 等方面的处理差异导致最终模型输入存在数据分布偏移，表现为3个float32输出概率相近但值不一致 0 918 0 930 0 036 0 019 。建议检查CANN 8 2RC1版本下AIPP矩阵配置、DVPP解码流程与OpenCV预处理的数据对齐策略是否匹配。",
        "created_at": "2025-06-07T15:18:33+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T09:41:06+08:00"
    },
    {
        "id": 554,
        "source_id": "20780311",
        "title": "CVE-2024-52304",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-52304](https://nvd.nist.gov/vuln/detail/CVE-2024-52304)\n漏洞归属组件：aiohttp\n漏洞归属的版本：3.7.4\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\naiohttp is an asynchronous HTTP client/server framework for asyncio and Python. Prior to version 3.10.11, the Python parser parses newlines in chunk extensions incorrectly which can lead to request smuggling vulnerabilities under certain conditions. If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or `AIOHTTP_NO_EXTENSIONS` is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections. Version 3.10.11 fixes the issue.\n\n漏洞公开时间：2024-11-19 05:15:06\n漏洞创建时间：2025-06-07 22:10:30\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-52304\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDE6V",
        "clean_data": "CVE 2024 52304：aiohttp 3 7 4在纯Python安装或启用AIOHTTP NO EXTENSIONS时因解析分块扩展换行符错误，可能引发请求走私漏洞导致代理防护失效。建议升级至3 10 11修复该问题。",
        "created_at": "2025-06-07T22:10:30+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:10:30+08:00"
    },
    {
        "id": 629,
        "source_id": "0248185010805447115",
        "title": "ATC不支持ONNX14及以上吗",
        "body": "<div class=\"cke-article\">atc --model=inference.onnx --framework=5 --output=inference --soc_version=Ascend310P3 --input_shape &quot;x:1,3, 488, 488&quot;  <p>ATC start working now, please wait for a moment. </p>  <p>... </p>  <p>ATC run failed, Please check the detail log, Try 'atc --help' for more information </p>  <p>E19010: [PID: 12619] 2025-06-11-15:14:03.860.303 No parser is registered for Op [Loop.0, optype [ai.onnx::14::Loop]]. </p>  <p>        Solution: Check the version of the installation package and reinstall the package. For details, see the operator specifications. </p>  <p>        TraceBack (most recent call last): </p>  <p>        Model parse to graph failed, graph name:inference.[FUNC:ModelParseToGraph][FILE:onnx_parser.cc][LINE:936] </p>  <p>        ATC model parse ret fail.[FUNC:ParseGraph][FILE:omg.cc][LINE:776] </p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248185010805447115-1-1.html",
        "clean_data": "ATC不支持ONNX v14及更高版本的Loop操作符，转换inference onnx模型时提示E19010错误：No parser registered for  ai onnx  14  Loop ，日志显示onnx parser cc 936处ModelParseToGraph解析失败。",
        "created_at": "2025-06-11T07:53:25+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-12T02:57:30+08:00"
    },
    {
        "id": 555,
        "source_id": "20780314",
        "title": "CVE-2024-53899",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-53899](https://nvd.nist.gov/vuln/detail/CVE-2024-53899)\n漏洞归属组件：virtualenv\n漏洞归属的版本：15.1.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nvirtualenv before 20.26.6 allows command injection through the activation scripts for a virtual environment. Magic template strings are not quoted correctly when replacing. NOTE: this is not the same as CVE-2024-9287.\n\n漏洞公开时间：2024-11-25 00:15:06\n漏洞创建时间：2025-06-07 22:10:34\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-53899\n",
        "url": "https://gitee.com/ascend/modelzoo-TensorFlow-bak/issues/ICDE6Y",
        "clean_data": "CVE 2024 53899  virtualenv 15 1 0及更早版本存在命令注入漏洞，源于虚拟环境激活脚本中魔改模板字符串替换未正确使用引号，区别于CVE 2024 9287。2024年11月25日披露。",
        "created_at": "2025-06-07T22:10:34+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:10:34+08:00"
    },
    {
        "id": 556,
        "source_id": "20780315",
        "title": "CVE-2025-48432",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-48432](https://nvd.nist.gov/vuln/detail/CVE-2025-48432)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nAn issue was discovered in Django 5.2 before 5.2.2, 5.1 before 5.1.10, and 4.2 before 4.2.22. Internal HTTP response logging does not escape request.path, which allows remote attackers to potentially manipulate log output via crafted URLs. This may lead to log injection or forgery when logs are viewed in terminals or processed by external systems.\n\n漏洞公开时间：2025-06-05 11:15:25\n漏洞创建时间：2025-06-07 22:10:36\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-48432\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDE6Z",
        "clean_data": "CVE 2025 48432  Django 5 2  before 5 2 2 、5 1  before 5 1 10  和 4 2  before 4 2 22  中内部 HTTP 响应日志未转义 request path 参数，可能通过构造恶意 URL 导致日志注入或伪造 终端查看或外部系统处理时存在风险 。",
        "created_at": "2025-06-07T22:10:36+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:10:37+08:00"
    },
    {
        "id": 36,
        "source_id": "20115560",
        "title": "torchair入图进行训练时，expand扩维后模型出现精度问题， 推理时无精度问题",
        "body": "一、需求场景&价值\r\ntorchair入图进行模型训练时出现精度问题， 但该场景下正常可提升性能，分析的可能是出现的一个bug。  图模式训练入图时bug较多，只是遇到了其中一个。\r\n二、需求建议实现的规格\r\n\r\n三、竞品比较（选填）",
        "url": "https://gitee.com/ascend/torchair/issues/IBZ59K",
        "clean_data": "问题标题： Train阶段使用expand操作引发精度异常，Infer阶段正常       问题描述  ： 采用TorchAIR将模型入图训练时，执行expand算子扩维后模型精度异常，但推理阶段未受损。经分析，该精度损失可能由图模式转换过程中的潜在错误导致，当前需排查训练扩维处理逻辑与推理是否一致，并验证图模式下算子实现。",
        "created_at": "2025-04-07T18:07:21+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-07T18:07:22+08:00"
    },
    {
        "id": 638,
        "source_id": "0248184554080978079",
        "title": "warpperspective功能问题",
        "body": "<div class=\"cke-article\">cann8.0rc3,atlas 300v pro,请问：cann算子warpperspective与opencv中的cv::warpPerspective函数处理结果是否是相同的，进行算子转成om，看结果是不对的</div>",
        "url": "https://www.hiascend.com/forum/thread-0248184554080978079-1-1.html",
        "clean_data": "CANN 8 0rc3版本的warpperspective算子与OpenCV的cv  warpPerspective函数处理结果不一致，涉及算子转换OM后功能异常问题。",
        "created_at": "2025-06-06T01:01:21+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-12T02:30:55+08:00"
    },
    {
        "id": 557,
        "source_id": "20780316",
        "title": "CVE-2025-30360",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-30360](https://nvd.nist.gov/vuln/detail/CVE-2025-30360)\n漏洞归属组件：webpack-dev-server\n漏洞归属的版本：4.15.2\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nwebpack-dev-server allows users to use webpack with a development server that provides live reloading. Prior to version 5.2.1, webpack-dev-server users_x27; source code may be stolen when you access a malicious web site with non-Chromium based browser. The `Origin` header is checked to prevent Cross-site WebSocket hijacking from happening, which was reported by CVE-2018-14732. But webpack-dev-server always allows IP address `Origin` headers. This allows websites that are served on IP addresses to connect WebSocket. An attacker can obtain source code via a method similar to that used to exploit CVE-2018-14732. Version 5.2.1 contains a patch for the issue.\n\n漏洞公开时间：2025-06-04 02:15:25\n漏洞创建时间：2025-06-07 22:10:38\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-30360\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDE70",
        "clean_data": "CVE 2025 30360：webpack dev server 4 15 2版本存在WebSocket源地址校验缺陷，允许非Chromium浏览器通过IP地址Origin头连接WebSocket接口窃取用户源代码。建议升级至5 2 1版本修复，具体详见 NIST漏洞详情  https   nvd nist gov vuln detail CVE 2025 30360 。",
        "created_at": "2025-06-07T22:10:38+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:10:39+08:00"
    },
    {
        "id": 558,
        "source_id": "20780317",
        "title": "CVE-2025-30359",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-30359](https://nvd.nist.gov/vuln/detail/CVE-2025-30359)\n漏洞归属组件：webpack-dev-server\n漏洞归属的版本：4.15.2\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nwebpack-dev-server allows users to use webpack with a development server that provides live reloading. Prior to version 5.2.1, webpack-dev-server users_x27; source code may be stolen when they access a malicious web site. Because the request for classic script by a script tag is not subject to same origin policy, an attacker can inject a malicious script in their site and run the script. Note that the attacker has to know the port and the output entrypoint script path. Combined with prototype pollution, the attacker can get a reference to the webpack runtime variables. By using `Function::toString` against the values in `__webpack_modules__`, the attacker can get the source code. Version 5.2.1 contains a patch for the issue.\n\n漏洞公开时间：2025-06-04 02:15:25\n漏洞创建时间：2025-06-07 22:10:40\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-30359\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDE71",
        "clean_data": "问题描述     使用   webpack dev server   4 15 2 及以下版本时，存在源代码泄露风险 CVE 2025 30359 。攻击者可通过诱导用户访问恶意网站，利用未受同源策略限制的经典脚本请求，结合原型污染和  Function  toString  技术，窃取    webpack modules    中的源代码。  修复方案：升级至 5 2 1 或更高版本  ，需确保端口和输出入口路径安全以避免攻击。详情参考  NVD 官方链接  https   nvd nist gov vuln detail CVE 2025 30359 。",
        "created_at": "2025-06-07T22:10:40+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:10:40+08:00"
    },
    {
        "id": 559,
        "source_id": "20780446",
        "title": "CVE-2025-27152",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-27152](https://nvd.nist.gov/vuln/detail/CVE-2025-27152)\n漏洞归属组件：axios\n漏洞归属的版本：1.7.9\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\naxios is a promise based HTTP client for the browser and node.js. The issue occurs when passing absolute URLs rather than protocol-relative URLs to axios. Even if ⁠baseURL is set, axios sends the request to the specified absolute URL, potentially causing SSRF and credential leakage. This issue impacts both server-side and client-side usage of axios. This issue is fixed in 1.8.2.\n\n漏洞公开时间：2025-03-08 00:15:38\n漏洞创建时间：2025-06-07 22:40:36\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-27152\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEAM",
        "clean_data": "CVE 2025 27152：axios 1 7 9版本在发送带有绝对URL的请求时，未校验baseURL配置有效性，导致请求可能指向任意地址，存在SSRF安全漏洞和凭证泄露风险。建议升级至1 8 2及以上版本修复。",
        "created_at": "2025-06-07T22:40:36+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:40:37+08:00"
    },
    {
        "id": 560,
        "source_id": "20780450",
        "title": "CVE-2024-57965",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-57965](https://nvd.nist.gov/vuln/detail/CVE-2024-57965)\n漏洞归属组件：axios\n漏洞归属的版本：1.5.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn axios before 1.7.8, lib/helpers/isURLSameOrigin.js does not use a URL object when determining an origin, and has a potentially unwanted setAttribute(_x27;href_x27;,href) call. NOTE: some parties feel that the code change only addresses a warning message from a SAST tool and does not fix a vulnerability.\n\n漏洞公开时间：2025-01-29 17:15:08\n漏洞创建时间：2025-06-07 22:40:41\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-57965\n",
        "url": "https://gitee.com/ascend/Asight/issues/ICDEAQ",
        "clean_data": "CVE 2024 57965  axios 1 5 1版本中lib helpers isURLSameOrigin js模块未采用URL对象进行源验证，且包含潜在风险的setAttribute  href   href 调用。部分安全专家质疑该修复仅针对SAST工具警告而非真实漏洞。建议升级至1 7 8 含 以上版本，详情参见 NIST漏洞库  https   nvd nist gov vuln detail CVE 2024 57965 。",
        "created_at": "2025-06-07T22:40:42+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:40:42+08:00"
    },
    {
        "id": 126,
        "source_id": "02115184267564566030",
        "title": "AMCT量化yolo后，推理速度变化过小",
        "body": "<div class=\"cke-article\">ultralytics官方的yolo11s的.onnx模型，大小在36.3mb，用amct_onnx自动量化到int8后，输出的deploy模型大小9.4mb，map损失&lt;1%。对它们分别用atc编译为离线模型.om后，前者大小19.5mb，后者11.5mb。看体积是没问题的，但是两个模型的推理速度变化较小，仅从0.046s→0.043s，这是为什么？下附我使用的atc命令<br> <br> atc \\  <p>  --model &quot;yolo11s_quant_deploy_model.onnx&quot; \\ </p>  <p>  --framework 5 \\ </p>  <p>  --input_shape &quot;images:1,3,640,640&quot; \\ </p>  <p>  --output yolo11s_quant_deploy_model \\ </p>  <p>  --soc_version &quot;Ascend310B4&quot;</p> <br> <br> 设备：Orangepi Aipro 8T算力<br> SOC：Ascend310B4</div>",
        "url": "https://www.hiascend.com/forum/thread-02115184267564566030-1-1.html",
        "clean_data": "ATC量化后模型推理速度提升不明显的原因可能包括： 1  Ascend310B4硬件对INT8加速效果受限 2  输入数据未按NHWC格式编排导致量化优势未触发 3  ATC未启用量化优化参数 检查  input type等配置  4  原始 onnx模型已采用计算优化方案 5  预处理 后处理耗时占比高 6  低精度计算在该模型的关键路径 如NMS 无效 7  小模型规模整体耗时未达阈值 建议：使用lda查看模型执行路径，检查是否涉及不支持低精度的算子；对比完整推理管线耗时；验证输入数据的shuffle和reshape是否经过量化校准。",
        "created_at": "2025-06-02T17:26:08+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": null
    },
    {
        "id": 561,
        "source_id": "20780452",
        "title": "CVE-2024-57965",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-57965](https://nvd.nist.gov/vuln/detail/CVE-2024-57965)\n漏洞归属组件：axios\n漏洞归属的版本：1.7.9\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn axios before 1.7.8, lib/helpers/isURLSameOrigin.js does not use a URL object when determining an origin, and has a potentially unwanted setAttribute(_x27;href_x27;,href) call. NOTE: some parties feel that the code change only addresses a warning message from a SAST tool and does not fix a vulnerability.\n\n漏洞公开时间：2025-01-29 17:15:08\n漏洞创建时间：2025-06-07 22:40:44\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-57965\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEAS",
        "clean_data": "CVE 2024 57965  axios 1 7 8及以下版本isURLSameOrigin模块未正确使用URL对象并存在setAttribute  href   href 潜在安全调用，建议升级至1 7 8以上版本。详情  CVE 2024 57965  https   nvd nist gov vuln detail CVE 2024 57965",
        "created_at": "2025-06-07T22:40:45+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:40:45+08:00"
    },
    {
        "id": 562,
        "source_id": "20780453",
        "title": "CVE-2025-23207",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-23207](https://nvd.nist.gov/vuln/detail/CVE-2025-23207)\n漏洞归属组件：katex\n漏洞归属的版本：0.16.21\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nKaTeX is a fast, easy-to-use JavaScript library for TeX math rendering on the web. KaTeX users who render untrusted mathematical expressions with `renderToString` could encounter malicious input using `\\htmlData` that runs arbitrary JavaScript, or generate invalid HTML. Users are advised to upgrade to KaTeX v0.16.21 to remove this vulnerability. Users unable to upgrade should avoid use of or turn off the `trust` option, or set it to forbid `\\htmlData` commands, forbid inputs containing the substring `\"\\\\htmlData\"` and sanitize HTML output from KaTeX.\n\n漏洞公开时间：2025-01-18 06:15:29\n漏洞创建时间：2025-06-07 22:40:47\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-23207\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEAT",
        "clean_data": "CVE 2025 23207     KaTeX 0 16 21使用 renderToString 处理不受信任表达式时，存在利用  htmlData 执行JS或生成无效HTML的风险。解决方案：升级至0 16 21；若无法升级，则禁用 trust 选项，禁止使用  htmlData 命令，过滤包含    htmlData  的输入，并对输出HTML进行消毒处理。",
        "created_at": "2025-06-07T22:40:47+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T22:40:48+08:00"
    },
    {
        "id": 107,
        "source_id": "20731115",
        "title": "冗余代码",
        "body": "一、需求场景&价值\r\n\r\n二、需求建议实现的规格\r\n\r\n三、竞品比较（选填）",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICCC8B",
        "clean_data": "冗余代码",
        "created_at": "2025-06-04T08:17:14+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T08:17:19+08:00"
    },
    {
        "id": 120,
        "source_id": "0205184388177962046",
        "title": "acl循环推理时，第一次推理成功，后续推理报错",
        "body": "<div class=\"cke-article\"><p>1.使用如下代码进行推理时，第一次推理成功，后续推理报错。</p>  <p>代码和plog日志：</p>  <p>链接: https://pan.baidu.com/s/1EsA3Tegg5vGWxoaUfh58gg 提取码: ggad</p>  <p>2.执行结果日志</p> ----acl.mdl.exec-----------  <p>0</p>  <p>推理time 0.22550582885742188</p>  <p>----acl.mdl.exec-----------</p>  <p>500002</p>  <p>推理time 1.802175760269165</p>  <p>----acl.mdl.exec-----------</p>  <p>500002</p>  <p>推理time 1.781337022781372</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0205184388177962046-1-1.html",
        "clean_data": "ACL循环推理失败：首次推理正常，后续调用报错500002。用户已上传代码及plog日志，需分析异常原因。",
        "created_at": "2025-06-04T02:56:18+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T06:39:34+08:00"
    },
    {
        "id": 123,
        "source_id": "0248184385267706059",
        "title": "onnxruntime_cann run_iobinding",
        "body": "<div class=\"cke-article\">请问怎么用c/c++实现CANNProvider的io_binding模式</div>",
        "url": "https://www.hiascend.com/forum/thread-0248184385267706059-1-1.html",
        "clean_data": "标题：CANNProvider调用run iobinding方法 答案：在ONNX Runtime C  接口中实现CANNProvider的IO绑定功能，需完成以下步骤：1 调用aclInit初始化CANN环境 2 将config options传入ProviderOptions 3 使用Ort  IoBinding类绑定内存：  建议使用ACL虚拟内存直接绑定，避免跨设备拷贝。代码示例确保包含正确的设备分配标识，运行后检查句柄返回状态。",
        "created_at": "2025-06-04T02:07:48+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-06T01:14:40+08:00"
    },
    {
        "id": 563,
        "source_id": "20780705",
        "title": "CVE-2021-23368",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-23368](https://nvd.nist.gov/vuln/detail/CVE-2021-23368)\n漏洞归属组件：postcss\n漏洞归属的版本：8.4.31\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe package postcss from 7.0.0 and before 8.2.10 are vulnerable to Regular Expression Denial of Service (ReDoS) during source map parsing.\n\n漏洞公开时间：2021-04-12 22:15:00\n漏洞创建时间：2025-06-07 23:50:51\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-23368\n",
        "url": "https://gitee.com/ascend/Asight/issues/ICDEHT",
        "clean_data": "CVE 2021 23368  postcss组件8 4 31版本源码解析模块存在ReDoS漏洞，影响7 0 0至8 2 10版本，攻击者可通过构造恶意源码映射触发正则表达式拒绝服务攻击。  注：原文 漏洞归属的版本：8 4 31 与 影响版本：7 0 0至8 2 10 存在版本跨度矛盾，已按公开时间2021年的时效性保留历史影响范围表述。",
        "created_at": "2025-06-07T23:50:51+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T23:50:51+08:00"
    },
    {
        "id": 564,
        "source_id": "20780708",
        "title": "CVE-2021-23368",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-23368](https://nvd.nist.gov/vuln/detail/CVE-2021-23368)\n漏洞归属组件：postcss\n漏洞归属的版本：8.4.49\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe package postcss from 7.0.0 and before 8.2.10 are vulnerable to Regular Expression Denial of Service (ReDoS) during source map parsing.\n\n漏洞公开时间：2021-04-12 22:15:00\n漏洞创建时间：2025-06-07 23:50:54\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-23368\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEHW",
        "clean_data": "CVE 2021 23368：postcss 7 0 0至8 2 10版本解析源音映射时存在ReDoS漏洞，可能导致性能问题。2021年4月12日公开。详情见：https   nvd nist gov vuln detail CVE 2021 23368",
        "created_at": "2025-06-07T23:50:54+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T23:50:55+08:00"
    },
    {
        "id": 565,
        "source_id": "20780846",
        "title": "CVE-2021-44420",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-44420](https://nvd.nist.gov/vuln/detail/CVE-2021-44420)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn Django 2.2 before 2.2.25, 3.1 before 3.1.14, and 3.2 before 3.2.10, HTTP requests for URLs with trailing newlines could bypass upstream access control based on URL paths.\n\n漏洞公开时间：2021-12-08 08:15:00\n漏洞创建时间：2025-06-08 00:20:16\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-44420\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDELQ",
        "clean_data": "CVE 2021 44420：Django 3 2 7存在路径尾随换行导致URL访问控制绕过漏洞，建议升级至3 2 10及以上版本。漏洞详情参考 NIST公开信息  https   nvd nist gov vuln detail CVE 2021 44420 。",
        "created_at": "2025-06-08T00:20:16+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:20:16+08:00"
    },
    {
        "id": 139,
        "source_id": "0236176463454994013",
        "title": "单线程多输入多输出 ，多stream串联模型报错",
        "body": "<div class=\"cke-article\"><p>#include &quot;fylm.h&quot;</p>  <p></p>  <p></p>  <p>static const cv::Scalar CV_COLOR_BLUE(255, 0, 0);</p>  <p>static const cv::Scalar CV_COLOR_GREEN(0, 255, 0);</p>  <p>static const cv::Scalar CV_COLOR_RED(0, 0, 255);</p>  <p>static const cv::Scalar CV_COLOR_BLACK(0, 0, 0);</p>  <p>static const cv::Scalar CV_COLOR_WHITE(255, 255, 255);</p>  <p></p>  <p></p>  <p>FylmAscend::FylmAscend(const FusionConfigs &amp;config) : fylmModelId(0), mmnModelId(1), ascendCfg(config)</p>  <p>{</p>  <p>    uint32_t deviceNum;</p>  <p>    CHECK_ACL(aclrtGetDeviceCount(&amp;deviceNum));</p>  <p>    init();</p>  <p>}</p>  <p></p>  <p></p>  <p>FylmAscend::~FylmAscend()</p>  <p>{</p>  <p>    this-&gt;destroyResource();</p>  <p>}</p>  <p></p>  <p></p>  <p>void FylmAscend::init()</p>  <p>{</p>  <p>    initResource();</p>  <p>    CHECK_ACL(aclmdlLoadFromFile(ascendCfg.fylmPath.c_str(), &amp;fylmModelId));</p>  <p>    CHECK_ACL(aclmdlLoadFromFile(ascendCfg.mmnPath.c_str(), &amp;mmnModelId));</p>  <p>    CHECK_ACL(!this-&gt;createDesc());</p>  <p>    if (!this-&gt;createDesc())</p>  <p>    {</p>  <p>        return;</p>  <p>    }</p>  <p>    if (!this-&gt;createModelInput(fylmInputDataSet, fylmModelDesc) ||</p>  <p>        !this-&gt;createModelOutput(fylmOutputDataSet, fylmModelDesc) ||</p>  <p>        !this-&gt;createModelInput(mmnInputDataSet, mmnModelDesc) ||</p>  <p>        !this-&gt;createModelOutput(mmnOutputDataSet, mmnModelDesc))</p>  <p>    {</p>  <p>        std::cerr &lt;&lt; &quot;Failed to create model input/output datasets&quot; &lt;&lt; std::endl;</p>  <p>        destroyResource();</p>  <p>        return;</p>  <p>    }</p>  <p>}</p>  <p></p>  <p></p>  <p>bool FylmAscend::initResource()</p>  <p>{</p>  <p>    CHECK_ACL(aclInit(nullptr));</p>  <p>    CHECK_ACL(this-&gt;ascendCfg.deviceId);</p>  <p>    CHECK_ACL(aclrtCreateContext(&amp;context, 0));</p>  <p>    // 创建两个stream和事件</p>  <p>    CHECK_ACL(aclrtCreateStream(&amp;fylmStream));</p>  <p>    CHECK_ACL(aclrtCreateStream(&amp;mmnStream));</p>  <p>    CHECK_ACL(aclrtCreateEvent(&amp;extractEvent));</p>  <p>    return true;</p>  <p>}</p>  <p></p>  <p></p>  <p>bool FylmAscend::createDesc()</p>  <p>{</p>  <p>    this-&gt;fylmModelDesc = aclmdlCreateDesc();</p>  <p>    this-&gt;mmnModelDesc = aclmdlCreateDesc();</p>  <p></p>  <p></p>  <p>    if (this-&gt;fylmModelDesc == nullptr || this-&gt;mmnModelDesc == nullptr)</p>  <p>    {</p>  <p>        std::cout &lt;&lt; &quot;create model description failed&quot; &lt;&lt; std::endl;</p>  <p>        return false;</p>  <p>    }</p>  <p></p>  <p></p>  <p>    CHECK_ACL(aclmdlGetDesc(this-&gt;fylmModelDesc, this-&gt;fylmModelId));</p>  <p>    CHECK_ACL(aclmdlGetDesc(this-&gt;mmnModelDesc, this-&gt;mmnModelId));</p>  <p></p>  <p></p>  <p>    // std::cout &lt;&lt; &quot;fylm inputNum: &quot; &lt;&lt; aclmdlGetNumInputs(this-&gt;fylmModelDesc) &lt;&lt; std::endl;</p>  <p>    // std::cout &lt;&lt; &quot;fylm outputNum: &quot; &lt;&lt; aclmdlGetNumOutputs(this-&gt;fylmModelDesc) &lt;&lt; std::endl;</p>  <p>    // std::cout &lt;&lt; &quot;mmn inputNum: &quot; &lt;&lt; aclmdlGetNumInputs(this-&gt;mmnModelDesc) &lt;&lt; std::endl;</p>  <p>    // std::cout &lt;&lt; &quot;mmn outputNum: &quot; &lt;&lt; aclmdlGetNumOutputs(this-&gt;mmnModelDesc) &lt;&lt; std::endl;</p>  <p>    return true;</p>  <p>}</p>  <p></p>  <p></p>  <p>bool FylmAscend::createModelInput(aclmdlDataset *&amp;inputDataSet, aclmdlDesc *&amp;modelDesc)</p>  <p>{</p>  <p>    inputDataSet = aclmdlCreateDataset();</p>  <p>    if (!inputDataSet)</p>  <p>    {</p>  <p>        std::cerr &lt;&lt; &quot;Failed to create input dataset&quot; &lt;&lt; std::endl;</p>  <p>        return false;</p>  <p>    }</p>  <p></p>  <p></p>  <p>    size_t inputNum = aclmdlGetNumInputs(modelDesc);</p>  <p>    for (size_t i = 0; i &lt; inputNum; ++i)</p>  <p>    {</p>  <p>        size_t bufferSize = aclmdlGetInputSizeByIndex(modelDesc, i);</p>  <p>        void *inputBuffer = nullptr;</p>  <p>        aclError ret = aclrtMalloc(&amp;inputBuffer, bufferSize, ACL_MEM_MALLOC_HUGE_FIRST);</p>  <p>        if (ret != ACL_SUCCESS)</p>  <p>        {</p>  <p>            std::cerr &lt;&lt; &quot;aclrtMalloc failed for input &quot; &lt;&lt; i &lt;&lt; std::endl;</p>  <p>            destoryDataSet(inputDataSet);</p>  <p>            return false;</p>  <p>        }</p>  <p></p>  <p></p>  <p>        aclDataBuffer *dataBuffer = aclCreateDataBuffer(inputBuffer, bufferSize);</p>  <p>        if (!dataBuffer)</p>  <p>        {</p>  <p>            aclrtFree(inputBuffer);</p>  <p>            destoryDataSet(inputDataSet);</p>  <p>            std::cerr &lt;&lt; &quot;aclCreateDataBuffer failed for input &quot; &lt;&lt; i &lt;&lt; std::endl;</p>  <p>            return false;</p>  <p>        }</p>  <p></p>  <p></p>  <p>        ret = aclmdlAddDatasetBuffer(inputDataSet, dataBuffer);</p>  <p>        if (ret != ACL_SUCCESS)</p>  <p>        {</p>  <p>            aclrtFree(inputBuffer);</p>  <p>            aclDestroyDataBuffer(dataBuffer);</p>  <p>            destoryDataSet(inputDataSet);</p>  <p>            std::cerr &lt;&lt; &quot;aclmdlAddDatasetBuffer failed for input &quot; &lt;&lt; i &lt;&lt; std::endl;</p>  <p>            return false;</p>  <p>        }</p>  <p>    }</p>  <p>    return true;</p>  <p>}</p>  <p></p>  <p></p>  <p>bool FylmAscend::createModelOutput(aclmdlDataset *&amp;outputDataSet, aclmdlDesc *&amp;modelDesc)</p>  <p>{</p>  <p>    outputDataSet = aclmdlCreateDataset();</p>  <p>    if (!outputDataSet)</p>  <p>    {</p>  <p>        std::cerr &lt;&lt; &quot;Failed to create output dataset&quot; &lt;&lt; std::endl;</p>  <p>        return false;</p>  <p>    }</p>  <p></p>  <p></p>  <p>    size_t outputNum = aclmdlGetNumOutputs(modelDesc);</p>  <p>    for (size_t i = 0; i &lt; outputNum; ++i)</p>  <p>    {</p>  <p>        size_t bufferSize = aclmdlGetOutputSizeByIndex(modelDesc, i);</p>  <p>        void *outputBuffer = nullptr;</p>  <p>        aclError ret = aclrtMalloc(&amp;outputBuffer, bufferSize, ACL_MEM_MALLOC_HUGE_FIRST);</p>  <p>        if (ret != ACL_SUCCESS)</p>  <p>        {</p>  <p>            std::cerr &lt;&lt; &quot;aclrtMalloc failed for output &quot; &lt;&lt; i &lt;&lt; std::endl;</p>  <p>            destoryDataSet(outputDataSet);</p>  <p>            return false;</p>  <p>        }</p>  <p></p>  <p></p>  <p>        aclDataBuffer *dataBuffer = aclCreateDataBuffer(outputBuffer, bufferSize);</p>  <p>        if (!dataBuffer)</p>  <p>        {</p>  <p>            aclrtFree(outputBuffer);</p>  <p>            destoryDataSet(outputDataSet);</p>  <p>            std::cerr &lt;&lt; &quot;aclCreateDataBuffer failed for output &quot; &lt;&lt; i &lt;&lt; std::endl;</p>  <p>            return false;</p>  <p>        }</p>  <p></p>  <p></p>  <p>        ret = aclmdlAddDatasetBuffer(outputDataSet, dataBuffer);</p>  <p>        if (ret != ACL_SUCCESS)</p>  <p>        {</p>  <p>            aclrtFree(outputBuffer);</p>  <p>            aclDestroyDataBuffer(dataBuffer);</p>  <p>            destoryDataSet(outputDataSet);</p>  <p>            std::cerr &lt;&lt; &quot;aclmdlAddDatasetBuffer failed for output &quot; &lt;&lt; i &lt;&lt; std::endl;</p>  <p>            return false;</p>  <p>        }</p>  <p>    }</p>  <p>    return true;</p>  <p>}</p>  <p></p>  <p></p>  <p>void FylmAscend::destoryDataSet(aclmdlDataset *&amp;dataset)</p>  <p>{</p>  <p>    if (dataset != nullptr)</p>  <p>    {</p>  <p>        for (size_t i = 0; i &lt; aclmdlGetDatasetNumBuffers(dataset); ++i)</p>  <p>        {</p>  <p>            aclDataBuffer *dataBuffer = aclmdlGetDatasetBuffer(dataset, i);</p>  <p>            void *data = aclGetDataBufferAddr(dataBuffer);</p>  <p>            aclrtFree(data);</p>  <p>            aclDestroyDataBuffer(dataBuffer);</p>  <p>        }</p>  <p>        aclmdlDestroyDataset(dataset);</p>  <p>        dataset = nullptr;</p>  <p>    }</p>  <p>}</p>  <p></p>  <p></p>  <p>void FylmAscend::destroyResource()</p>  <p>{</p>  <p>    // 释放数据</p>  <p>    destoryDataSet(fylmInputDataSet);</p>  <p>    destoryDataSet(fylmOutputDataSet);</p>  <p>    destoryDataSet(mmnInputDataSet);</p>  <p>    destoryDataSet(mmnOutputDataSet);</p>  <p></p>  <p></p>  <p>    // 释放模型相关资源</p>  <p>    if (fylmModelDesc != nullptr)</p>  <p>    {</p>  <p>        aclmdlDestroyDesc(fylmModelDesc);</p>  <p>        fylmModelDesc = nullptr;</p>  <p>    }</p>  <p>    if (fylmModelId != 0)</p>  <p>    {</p>  <p>        aclmdlUnload(fylmModelId);</p>  <p>        fylmModelId = 0;</p>  <p>    }</p>  <p></p>  <p></p>  <p>    if (mmnModelDesc != nullptr)</p>  <p>    {</p>  <p>        aclmdlDestroyDesc(mmnModelDesc);</p>  <p>        mmnModelDesc = nullptr;</p>  <p>    }</p>  <p></p>  <p></p>  <p>    if (mmnModelId != 0)</p>  <p>    {</p>  <p>        aclmdlUnload(mmnModelId);</p>  <p>        mmnModelId = 0;</p>  <p>    }</p>  <p></p>  <p></p>  <p>    if (extractEvent)</p>  <p>        aclrtDestroyEvent(extractEvent);</p>  <p>    if (fylmStream)</p>  <p>        aclrtDestroyStream(fylmStream);</p>  <p>    if (mmnStream)</p>  <p>        aclrtDestroyStream(mmnStream);</p>  <p>    // 销毁上下文</p>  <p>    if (context != nullptr)</p>  <p>    {</p>  <p>        aclrtDestroyContext(context);</p>  <p>        context = nullptr;</p>  <p>    }</p>  <p>    // 重置设备</p>  <p>    aclrtResetDevice(ascendCfg.deviceId);</p>  <p>    aclFinalize();</p>  <p>}</p>  <p></p>  <p></p>  <p>cv::Mat FylmAscend::preProcess(cv::Mat &amp;src, int interpolation)</p>  <p>{</p>  <p>    // 首先对如果是3色图转换颜色</p>  <p>    cv::Mat grayImg;</p>  <p>    // 1. resize with the minimal ratio of W and H</p>  <p>    if (src.channels() != 1)</p>  <p>    {</p>  <p>        cv::cvtColor(src, grayImg, cv::COLOR_BGR2GRAY);</p>  <p>    }</p>  <p>    else</p>  <p>    {</p>  <p>        grayImg = src.clone();</p>  <p>    }</p>  <p>    const int &amp;inputW = ascendCfg.inputSize.width;</p>  <p>    const int &amp;inputH = ascendCfg.inputSize.height;</p>  <p>    float r = std::min(inputW / (grayImg.cols * 1.0), inputH / (grayImg.rows * 1.0));</p>  <p>    int unpadW = r * grayImg.cols;</p>  <p>    int unpadH = r * grayImg.rows;</p>  <p>    cv::Mat re(unpadH, unpadW, CV_8UC1);</p>  <p>    cv::resize(grayImg, re, re.size(), 0, 0, interpolation);</p>  <p>    cv::Mat padImg(inputH, inputW, CV_8UC1, cv::Scalar(0));</p>  <p>    re.copyTo(padImg(cv::Rect(0, 0, re.cols, re.rows)));</p>  <p>    padImg.convertTo(padImg, CV_32F, 1.0 / 255.0);</p>  <p>    return padImg;</p>  <p>}</p>  <p></p>  <p></p>  <p>void FylmAscend::registrain(cv::Mat &amp;img1, cv::Mat img2, std::vector&lt;float&gt; &amp;matrix)</p>  <p>{</p>  <p>    std::cout &lt;&lt; &quot;registrain ..............&quot; &lt;&lt; std::endl;</p>  <p>    cv::Mat prImg1 = preProcess(img1, cv::INTER_NEAREST);</p>  <p>    cv::Mat prImg2 = preProcess(img2, cv::INTER_NEAREST);</p>  <p>    std::cout &lt;&lt; &quot;registrain: preProcess Done!&quot; &lt;&lt; std::endl;</p>  <p></p>  <p></p>  <p>    std::vector&lt;void *&gt; imgData1;</p>  <p>    imgData1.push_back(prImg1.data);</p>  <p>    std::vector&lt;void *&gt; imgData2;</p>  <p>    imgData2.push_back(prImg2.data);</p>  <p>    // 执行两次特征提取</p>  <p>    extract(imgData1, 1, 0);</p>  <p>    extract(imgData2, 1, 1);</p>  <p>    // TODO: 运行第二个模型，执行mmn</p>  <p>    // 模拟数据</p>  <p>    std::vector&lt;float *&gt; featureData;</p>  <p>    float *fakeData = new float[1024 * 128];</p>  <p></p>  <p></p>  <p>    for (int i = 0; i &lt; 4; i++)</p>  <p>    {</p>  <p>        featureData.push_back(fakeData);</p>  <p>    }</p>  <p>    mmn(featureData, 4);</p>  <p>    CHECK_ACL(aclrtSynchronizeStream(mmnStream));</p>  <p>    std::cout &lt;&lt; &quot;mmn done!&quot; &lt;&lt; std::endl;</p>  <p>    // TODO: 对最终的结果进行后处理</p>  <p>    delete[] fakeData;</p>  <p>    std::cout &lt;&lt; &quot;registrain: extract Done!&quot; &lt;&lt; std::endl;</p>  <p>}</p>  <p></p>  <p></p>  <p>void FylmAscend::extract(std::vector&lt;void *&gt; imgData, size_t input_size, int imgIdx)</p>  <p>{</p>  <p>    std::cout &lt;&lt; &quot;extract ..............&quot; &lt;&lt; std::endl;</p>  <p>    // 填充数据</p>  <p>    for (size_t i = 0; i &lt; input_size; i++)</p>  <p>    {</p>  <p>        // 获取输入buffer</p>  <p>        aclDataBuffer *inputBuffer = aclmdlGetDatasetBuffer(fylmInputDataSet, i);</p>  <p>        void *devData = aclGetDataBufferAddr(inputBuffer);</p>  <p>        size_t dataSize = aclGetDataBufferSize(inputBuffer);</p>  <p>        // 拷贝数据到设备（假设输入数据已经在设备侧）</p>  <p>        CHECK_ACL(aclrtMemcpyAsync(devData, dataSize, imgData[i], dataSize,</p>  <p>                                   ACL_MEMCPY_HOST_TO_DEVICE, fylmStream));</p>  <p>    }</p>  <p></p>  <p></p>  <p>    CHECK_ACL(aclmdlExecuteAsync(this-&gt;fylmModelId, this-&gt;fylmInputDataSet, this-&gt;fylmOutputDataSet, this-&gt;fylmStream));</p>  <p>    // CHECK_ACL(aclrtSynchronizeStream(fylmStream));</p>  <p>    std::cout &lt;&lt; &quot;extract: aclmdExecute Done!&quot; &lt;&lt; std::endl;</p>  <p>    // 后处理</p>  <p>    for (size_t i = 0; i &lt; aclmdlGetDatasetNumBuffers(fylmOutputDataSet); ++i)</p>  <p>    {</p>  <p>        aclDataBuffer *dataBuffer = aclmdlGetDatasetBuffer(fylmOutputDataSet, i);</p>  <p>        void *data = aclGetDataBufferAddr(dataBuffer);</p>  <p>        size_t size = aclGetDataBufferSize(dataBuffer);</p>  <p></p>  <p></p>  <p>        // 将数据从设备拷贝到主机</p>  <p>        void *hostData = malloc(size);</p>  <p>        aclrtMemcpyAsync(hostData, size, data, size, ACL_MEMCPY_DEVICE_TO_HOST, fylmStream);</p>  <p>        // TODO: 特征变换</p>  <p>        CHECK_ACL(aclrtSynchronizeStream(fylmStream));</p>  <p>        free(hostData);</p>  <p>    }</p>  <p>    std::cout &lt;&lt; &quot;extract: postProcess Done!&quot; &lt;&lt; std::endl;</p>  <p></p>  <p></p>  <p>    // 记录事件</p>  <p>    if (imgIdx == 1)</p>  <p>    { // 等待两张图都处理完</p>  <p>        CHECK_ACL(aclrtRecordEvent(extractEvent, fylmStream));</p>  <p>    }</p>  <p>}</p>  <p></p>  <p></p>  <p>void FylmAscend::mmn(std::vector&lt;float *&gt; extractData, size_t input_size)</p>  <p>{</p>  <p>    std::cout &lt;&lt; &quot;mmn: begin to mmn&quot; &lt;&lt; std::endl;</p>  <p>    CHECK_ACL(aclrtStreamWaitEvent(mmnStream, extractEvent));</p>  <p>    // 填充数据</p>  <p>    for (size_t i = 0; i &lt; input_size; i++)</p>  <p>    {</p>  <p>        // 获取输入buffer</p>  <p>        aclDataBuffer *inputBuffer = aclmdlGetDatasetBuffer(mmnInputDataSet, i);</p>  <p>        void *devData = aclGetDataBufferAddr(inputBuffer);</p>  <p>        size_t dataSize = aclGetDataBufferSize(inputBuffer);</p>  <p>        // 拷贝数据到设备（假设输入数据已经在设备侧）</p>  <p>        aclrtMemcpyAsync(devData, dataSize, extractData[i], dataSize, ACL_MEMCPY_DEVICE_TO_DEVICE, mmnStream);</p>  <p>    }</p>  <p></p>  <p></p>  <p>    CHECK_ACL(aclmdlExecuteAsync(mmnModelId, mmnInputDataSet, mmnOutputDataSet, mmnStream));</p>  <p>    // CHECK_ACL(aclrtSynchronizeStream(mmnStream));</p>  <p>    std::cout &lt;&lt; &quot;mmn: excute done!&quot; &lt;&lt; std::endl;</p>  <p></p>  <p></p>  <p>    for (size_t i = 0; i &lt; aclmdlGetDatasetNumBuffers(mmnOutputDataSet); ++i)</p>  <p>    {</p>  <p>        aclDataBuffer *dataBuffer = aclmdlGetDatasetBuffer(mmnOutputDataSet, i);</p>  <p>        void *data = aclGetDataBufferAddr(dataBuffer);</p>  <p>        size_t size = aclGetDataBufferSize(dataBuffer);</p>  <p></p>  <p></p>  <p>        // 将数据从设备拷贝到主机</p>  <p>        void *hostData = malloc(size);</p>  <p>        aclrtMemcpyAsync(hostData, size, data, size, ACL_MEMCPY_DEVICE_TO_HOST, mmnStream);</p>  <p>        // TODO: 特征变换</p>  <p>        CHECK_ACL(aclrtSynchronizeStream(mmnStream));</p>  <p>        free(hostData);</p>  <p>    }</p>  <p>    std::cout &lt;&lt; &quot;mmn: post done!&quot; &lt;&lt; std::endl;</p>  <p></p>  <p></p>  <p>    // 同步等待最终结果</p>  <p>    // CHECK_ACL(aclrtSynchronizeStream(mmnStream));</p>  <p>}</p>  <p></p>  <p>**************************************************************************</p>  <p>结果一直报错，运行单模型都是ok的，运行多stream就一直报错，显示*** stack smashing detected ***: &lt;unknown&gt; terminated </p>  <p>Aborted，请问有相关的example或者帮忙看看问题吗</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0236176463454994013-1-1.html",
        "clean_data": "标题：单线程多stream串联模型执行堆栈破坏  问题描述：在单线程环境下同时执行两个异步stream FyLm MMN模型 、关联事件等待，执行时触发     stack smashing detected     错误；各模块单独运行及同步执行均正常，异步串联时报内存异常，关键代码涉及多stream并发、异步内存拷贝和事件依赖管理。",
        "created_at": "2025-03-04T09:37:35+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-04T09:37:35+08:00"
    },
    {
        "id": 650,
        "source_id": "02115185009986244107",
        "title": "算子执行失败，暂时没有定位到具体问题",
        "body": "<div class=\"cke-article\"><p>算子执行失败<br> 之前注释掉kernel侧的de_disp.cpp中的process行后，ACL测试工程可以正常执行算子。但是取消注释后，又出现507015问题。</p>  <p>说明问题出现在自定义算子内部<br> 暂时没有找到具体出现在哪里，在kernel侧的de_disp.cpp中尝试增加printf语句，但是没有找到这些语句在哪里输出，所以不知道算子具体问题出在哪里。</p>  <p>针对算子中需要传入的参数，我们采用了写死的方式来先验证算子内部的计算逻辑<br> kernel侧的de_disp.cpp文件和算子执行./execute_disp_op &gt; log.txt命令后的txt文件都在附件中，ACL工程中的main.cpp和op_runner.cpp文件也在附件中</p>  <p>在下面的GitHub链接中也放了这些代码文件</p>  <p>https://github.com/wywywywy1/disp</p></div>",
        "url": "https://www.hiascend.com/forum/thread-02115185009986244107-1-1.html",
        "clean_data": "自定义算子执行引发507015错误   用户取消注释 de disp cpp中process代码段后，ACL测试工程报507015错误。通过注释掉该段代码可规避问题，但内核侧代码执行路径存在异常： 1  printf调试信息未在控制台或log txt中输出 2  参数采用硬编码验证计算逻辑 3  关键代码依赖已上传：de disp cpp、main cpp、op runner cpp GitHub  disp仓库  需定位内核执行阶段异常并确认日志输出配置。",
        "created_at": "2025-06-11T07:39:46+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T09:28:12+08:00"
    },
    {
        "id": 652,
        "source_id": "0226184684669941075",
        "title": "参考样例对脚本进行修改，推理结果完全一样",
        "body": "<div class=\"cke-article\"><p>我在快速入门的resnet50图片分类样例基础上进行修改，推理结果全部一样，但是结果与我在windows下使用python进行推理结果完全不一样，能不能帮我指出我的修改有哪些问题，谢谢！！！<br> 修改后的python脚本在附件。</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0226184684669941075-1-1.html",
        "clean_data": "基于resnet50图片分类样例的Python脚本修改后推理结果与Windows环境不一致， attachments提供修改版本，需核查输入预处理 模型参数加载 硬件环境适配问题。",
        "created_at": "2025-06-07T13:17:50+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T01:47:22+08:00"
    },
    {
        "id": 173,
        "source_id": "0297177756742392029",
        "title": "对算子的编译、调用流程不是很清楚",
        "body": "<div class=\"cke-article\">现在功能都跑通了，但是对算子的编译、调用流程不是很清楚，比如算子的源码编译、二进制编译都在什么路径下，在各个调用方式下都是怎么编译、链接的</div>",
        "url": "https://www.hiascend.com/forum/thread-0297177756742392029-1-1.html",
        "clean_data": "算子编译与调用流程说明 算子开发需明确源码编译路径 ascend cann device acllib src operator 和二进制输出路径  usr local Ascend ascend toolkit latest acllib lib64 。调用方式差异：AscendCL通过动态链接库实现算子绑定，ATC工具链需配置op目录；基于模板开发时需注意cmake时op路径映射。",
        "created_at": "2025-03-19T08:52:22+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-19T08:52:22+08:00"
    },
    {
        "id": 8,
        "source_id": "19199998",
        "title": " 自动融合节点名不友好",
        "body": "一、需求场景&价值\r\n当前融合后在profiling上看是fused_graph_x，不好和原图对应\r\n\r\n二、需求建议实现的规格\r\n\r\n三、竞品比较（选填）",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFITA",
        "clean_data": "自动融合节点在profiling中显示为fused graph x，与原图对应困难，如何优化节点命名以便开发者快速定位原图元素？",
        "created_at": "2025-01-03T16:40:55+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-03T16:40:56+08:00"
    },
    {
        "id": 172,
        "source_id": "0201179457415507162",
        "title": "基于Ascend C的MC²通算融合算子性能优化最佳实践",
        "body": "<div class=\"cke-article\"><p><span><span><span><span><span>近年来</span></span><span><span>，</span></span><span><span>随着GPT-3、LLaMA、DeepSeek等模型的参数</span></span><span><span>规模</span></span><span><span>突破千亿甚至万亿级别，AI大模型已成为驱动人工智能技术革新的核心引擎。然而，模型规模的指数级增长使得单设备训练在计算能力、存储容量和能效等方面面临根本性瓶颈。</span></span><span><span>以</span></span><span><span>1750亿参数的GPT-3模型</span></span><span><span>为例，其训练</span></span><span><span>至少需要数百GB</span></span><span><span>的</span></span><span><span>内存资源，这使得分布式并行推理/训练从可选方案转变为必选技术路径。</span></span></span></span></span></p>  <p><span><span><span><span><span>在分布式推理/训练框架中，</span></span><span><span>如何平衡</span></span><span><span>计算效率与通信开销成为关键挑战。传统的单维度并行策略（如数据并行）已无法满足需求，</span></span><span><span>而</span></span><span><span>混合并行（Hybrid Parallelism）通过同时切分计算图（模型并行）、数据批次（数据并行）以及流水线阶段（流水线并行），成为当前主流解决方案。其中，Cube计算和集合通信算子的协同切分</span></span><span><span>与</span></span><span><span>并行策略，是决定系统吞吐量的关键因素。昇腾CANN</span></span><span><span>通过</span></span><span><span>将需要切分并行的计算和通信算子</span></span><span><span>进行</span></span><span><span>融合（又称：通算融合），</span></span><span><span>实现了</span></span><span><span>计算和通信</span></span><span><span>的</span></span><span><span>流水</span></span><span><span>，</span></span><span><span>从而</span></span><span><span>并行提升性能</span></span><span><span>。</span></span><span><span>融合后的算子简称为MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>通算融合算子（</span></span><span><span><span style=\"color: rgb(29,29,26);\">Matrix Computation &amp; Communication</span></span></span><span><span>）。</span></span></span></span></span></p>  <p><span><span><span><span><span>根据不同的应用场景，昇腾CANN的算子加速库内置了多种MC²通算融合类算子，典型算子包括AllGatherMatMul、MatMulReduceScatter、MatMulAllReduce等</span></span><span><span>。</span></span><span><span>这些算子将AllReduce、ReduceScatter、AllGather等通信过程</span></span><span><span>与</span></span><span><span>MatMul计算</span></span><span><span>进行</span></span><span><span>融合，使SP、TP等并行场景下的通信和矩阵计算</span></span><span><span>实现</span></span><span><span>流水并行，</span></span><span><span>从而</span></span><span><span>加速大模型</span></span><span><span>的</span></span><span><span>执行。</span></span></span></span></span></p>  <p><span><span><span><span><span>此外</span></span><span><span>，基于Ascend C算子编程语言，开发者</span></span><span><span>可以</span></span><span><span>进一步对MC²算子</span></span><span><span>实施</span></span><span><span>性能优化，以</span></span><span><span>满足</span></span><span><span>更加严苛的需求场景。</span></span></span></span></span></p>  <p><span><span><span><span><span>本文将</span></span><span><span>从</span></span><span><span>开发者角度</span></span><span><span>出发</span></span><span><span>，系统阐述面向大模型推理/训练场景的MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>算子性能优化方法，重点解决以下问题：</span></span></span></span></span></p>  <ol>  <li><span><span>如何进行通算融合性能评估：根据输入张量的Shape、融合前单独计算和通信的耗时情况等因素，分析通算融合后的预期性能收益</span></span><span><span>及</span></span><span><span>可能存在的瓶颈点。</span></span></li>  <li><span><span>如何制定数据切分策略：通过理论</span></span><span><span>分析</span></span><span><span>和</span></span><span><span>实际</span></span><span><span>示例</span></span><span><span>，</span></span><span><span>说明如何将输入张量</span></span><span><span>进行</span></span><span><span>切分，形成多条数据流水并行，以达到最优性能目标。</span></span></li> </ol>  <p><span><span><span><span><span>优化后的完整样例</span></span><span><span>可</span></span><span><span>参考</span></span><a href=\"cid:link_1\" rel=\"nofollow\" target=\"_blank\" title=\"\"><span><span style=\"color: rgb(128,0,128);\">MatmulAllReduce样例</span></span></a><span><span>、</span></span><a href=\"cid:link_0\" rel=\"nofollow\" target=\"_blank\" title=\"\"><span><span style=\"color: rgb(0,0,255);\">MatmulReduceScatter样例</span></span></a><span><span>、</span></span><a href=\"cid:link_2\" rel=\"nofollow\" target=\"_blank\" title=\"\"><span><span style=\"color: rgb(0,0,255);\">AllGatherMatmul样例</span></span></a><span><span>。</span></span></span></span></span></p>  <h2>MC²算子性能瓶颈点分析</h2>  <p><span><span><span><span><span>MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>通算融合算子的性能收益主要来自于通信、计算的并行执行，即将输入数据切分为多个子块，子块的计算和通信任务形成两条流水线，通过两条流水线上任务的并行执行，实现流水掩盖，从而提升算子性能。如下图所示，MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>算子先做Matmul计算、后通信的场景，输入矩阵沿M轴被切分为两块，第二块数据的Matmul计算和第一块数据的通信可以并行执行，从而达到计算和通信时间相互掩盖的目的。本节的所有图示中MM代表Matmul计算，hcom代表通信任务。</span></span></span></span></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"1.PNG\" src=\"cid:pic_0\"></span></p>  <p><span><span><span><span><span>MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>算子性能收益公式为：</span></span></span></span></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"1-1.png\" src=\"cid:pic_1\"></span></p>  <p><span><span><span><span><span>融合后MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>算子的执行耗时，受以下因素制约，从而影响算子性能收益。</span></span></span></span></span></p>  <ul>  <li><span><span>因素一：计算和通信的执行时间差异</span></span>   <p><span><span>若计算和通信任务的执行时间相差不大，则融合后，MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>算子的计算和通信并行执行，能得到较好的流水掩盖，性能收益较大。</span></span></p>   <p><span><span>若计算和通信任务的执行时间差异较大，则融合后，MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>算子内计算和通信并行执行，能够掩盖的时间较少，算子整体执行耗时与未切分串行时的算子执行耗时接近，此时无法获得较大性能收益。</span></span></p>   <p><span><span><span class=\"easyimage easyimage-full\"><img alt=\"2.png\" src=\"cid:pic_2\"></span></span></span></p>  </li>  <li><span><span>因素二：数据切分导致的计算或通信的执行时间膨胀</span></span>  <p><span><span>当对输入数据进行切分后，原本的整块数据被切分成若干小数据块，对若干小数据块分别做Matmul计算或者执行通信任务，此时相比切分前，计算或者通信任务的执行时间可能发生膨胀（即执行时间变长）。该膨胀产生的原因包括：切分后的数据块过小导致计算或通信的效率降低、切分的数据块过多导致增加额外的调度开销、并行执行后计算和通信对L2Cache或device存储内存的访问冲突等。以Matmul计算为例，简单说明数据切分后执行时间可能发生的膨胀情况。</span></span></p>   <ul>   <li><span><span>未发生膨胀：</span></span>    <p><span><span><span><span><span>数据切分前，Matmul执行时间为200us，将Matmul的输入均匀切分为两块，假设切分后，每块数据的Matmul执行时间都是100us，通过计算的并行执行，下图实际性能收益为100us。</span></span></span></span></span></p>    <p><span><span><span><span><span><span class=\"easyimage easyimage-full\"><img alt=\"3.png\" src=\"cid:pic_3\"></span></span></span></span></span></span></p>   </li>   <li>   <p><span><span><span><span><span>发生一般程度的膨胀：</span></span></span></span></span></p>    <p><span><span>数据切分前，Matmul执行时间为200us，将Matmul的输入均匀切分为两块，假设切分后，每块数据的Matmul执行时间都是150us，通过计算的并行执行，下图实际性能收益为50us。</span></span></p>    <p><span><span><span class=\"easyimage easyimage-full\"><img alt=\"4.png\" src=\"cid:pic_4\"></span></span></span></p>   </li>   <li><span><span>发生严重程度的膨胀：</span></span>   <p><span><span><span><span><span>数据切分前，Matmul执行时间为200us，将Matmul的输入均匀切分为两块，假设切分后，每块数据的Matmul执行时间都是200us，通过计算的并行执行，下图实际性能收益为劣化50us。</span></span></span></span></span></p>    <p><span><span><span><span><span><span class=\"easyimage easyimage-full\"><img alt=\"5.png\" src=\"cid:pic_5\"></span></span></span></span></span></span></p>   </li>  </ul>  </li> </ul>  <p><span><span><span><span><span>综合上述分析，计算和通信执行时间较均衡的场景，有更好的流水掩盖和性能收益；同时，性能收益也受到数据切分导致的执行时间膨胀的影响。下文将介绍如何制定数据切分策略，以达到最佳流水掩盖效果。</span></span></span></span></span></p>  <h2>设计优化方案</h2>  <p><span><span><span><span><span>以Atlas A2 训练系列产品/Atlas 800I A2 推理产品，输入数据格式为ND、数据类型为half的MatmulAllreduce算子为例 ，该算子中计算执行在前，通信任务执行在后。假定Matmul计算中左矩阵的形状为[M, K]，右矩阵的形状为[K, N]，算子中的通信对象为Matmul的输出矩阵，则通信任务的输入shape为[M, N]。因为K轴只在Matmul计算中存在，当K轴较大时，计算量大，计算执行时间大于通信执行时间，此时计算为算子的瓶颈（bound）；反之，当K轴较小时，计算量小，计算执行时间小于通信执行时间，此时通信为算子的瓶颈。在制定数据切分策略前，对原始矩阵分别执行计算和通信任务，根据两个任务的执行时间判定bound场景。</span></span></span></span></span></p>  <p><span><span><span><span><span>该算子的数据切分策略应满足如下要求：</span></span></span></span></span></p>  <ul>  <li><span><span>只切分M轴。因为通信任务调用的Hccl API要求分块数据内存连续，若按N轴切分，则每行数据都被切断，导致通信数据的内存不连续，不满足通信要求；若按M轴切分，则每行数据都是内存连续的，满足通信要求。</span></span></li>  <li><span><span>若A表示长块、B表示短块，只能切出A或B连续排布的形式，例如AAAB、BAAA等情况。</span></span></li> </ul>  <p><span><span><span><span><span>如上文所述，数据切分的目标是达成尽可能多的流水掩盖。根据计算与通信任务的执行时间差异，实际场景可以分解为如下两个具体场景，两个场景有各自细分的切分目标。</span></span></span></span></span></p>  <ul>  <li><strong><span><span><span><strong>计算bound</strong></span></span></span></strong><span><span>：</span></span>   <p><span><span>对于同一个切分后的数据块，计算执行耗时大于通信执行耗时，</span></span><span><span><span style=\"font-weight: normal;\">此时，计算连续，且通信的尾块要短，如下图所示</span></span></span><strong><span><span>。</span></span></strong></p>   <p></p>   <p><strong><span><span><span class=\"easyimage easyimage-full\"><img alt=\"6.png\" src=\"cid:pic_6\"></span></span></span></strong></p>   <p></p>  </li>  <li><strong><span><span><span><strong>通信bound</strong></span></span></span></strong><span><span>：</span></span>  <p><span><span><span><span><span>对于同一个切分后的数据块，通信执行耗时</span></span><span><span><span style=\"font-weight: normal;\">大于计算执行耗时，此时，通信连续，且计算的头快要短</span></span></span><span><span>，如下图所示。</span></span></span></span></span></p>   <p></p>   <p><span><span><span><span><span><span class=\"easyimage easyimage-full\"><img alt=\"7.png\" src=\"cid:pic_7\"></span></span></span></span></span></span></p>   <p></p>  </li> </ul>  <p><span><span><span><span><span>在进行最终的数据切分前，需要做的前置工作有：判定bound场景、分别对Matmul计算和AllReduce通信的数据量与执行时间关系做公式拟合。具体步骤如下。</span></span></span></span></span></p>  <ol>  <li><span><span>将输入数据分别单独执行Matmul计算和AllReduce通信任务，利用msProf工具分别采集执行时间，判定时间较长的任务为对应的bound场景。例如通信执行时间大于计算执行时间，则为</span></span><span><span><span style=\"font-weight: normal;\">通信bound</span></span></span><span><span><span style=\"font-weight: normal;\">场景</span></span></span><span><span>。</span></span></li>  <li><span><span>将输入数据按M轴切分，分别切成M轴为256、512、768、1024、2048的若干数据块，这里可以根据实际情况调整切块大小。</span></span></li>  <li><span><span><span><span><span>将步骤2得到的数据块分别做AllReduce通信，利用msProf工具采集执行时间，得到每个数据块的执行时间t</span></span><span><span><span style=\"vertical-align: sub;\">1</span></span></span><span><span>, t</span></span><span><span><span style=\"vertical-align: sub;\">2</span></span></span><span><span>, ..., t</span></span><span><span><span style=\"vertical-align: sub;\">n</span></span></span><span><span>。然后，作图分析数据量与对应的执行时间的关系，拟合得到公式t = CostComm(m)，其中m表示数据块的M轴长度，t表示数据块的通信执行时间，CostComm表示拟合得到的m和t的映射关系。该映射关系一般为线性，若不满足线性关系，可以采用分段拟合的方式。示例如下：</span></span></span></span></span>  <p><span><span><span><span><span><span class=\"easyimage easyimage-full\"><img alt=\"8.png\" src=\"cid:pic_8\"></span></span></span></span></span></span></p>   <p><span class=\"easyimage easyimage-full\"><img alt=\"9.png\" src=\"cid:pic_9\"></span></p>   <p></p>   <p><span><span>数据量x = m * N * sizeof(dataType)，单位是Bytes。该拟合公式表示为：</span></span></p>   <ul>   <li><span><span>x小于8MB：t = -0.9698202 * x * x + 27.0622573 * x + 14.769，单位是us。</span></span></li>   <li><span><span>x大于等于8MB：t = 13.58491263 * x + 61.508333，单位是us。</span></span></li>  </ul>  </li>  <li><span><span><span><span><span>将步骤2切分得到的各数据块做Matmul计算，按与步骤3相同的方式采集各数据块的计算执行时间t，并拟合得到M轴长度和计算执行时间关系的公式t = CostMM(m)，CostMM示拟合得到的m和t的映射关系。</span></span></span></span></span></li> </ol>  <p><span><span><span><strong><span><span>切分算法步骤：</span></span></strong></span></span></span></p>  <ol>  <li><span><span><span><span><span>根据输入矩阵的shape：M、K、N，按照经验值设置合适的M轴方向切分的短块长度。如下表达式中，a、b、c表示根据经验值给出的短块长度的备选，将K、N带入如下三个表达式后，取a、b、c的最小值m0为选定的短块长度。</span></span></span></span></span>   <p><span><span><span><span><span>- </span></span></span></span></span>a * K * N &gt;= 4 * 1024 * 1024 * 1024，a取不等式的最小值</p>   <p><span><span>- b * K * N / 1024 + b * N &gt;= 6 * 1024 * 1024，b取不等式的最小值</span></span></p>   <p><span><span>- </span></span><span><span>c &gt;= 3 * 128，c取不等式的最小值</span></span></p>   <p><span><span>- </span></span><span><span>m0 = min(a, b, c)</span></span></p>  </li>  <li>根据短块长度m0和拟合公式，分别得到计算执行时间t0 = CostMM(m0) * 1.15，通信执行时间t1 = CostComm(m0) * 1.15。  <p>​​​​​​​​​​​​​​注意：通信和计算并行执行时，可能出现抢占内存带宽的情况，导致执行时间增加，一般按经验在拟合公式中乘以1.15的系数，用户可以根据实测情况调整该系数。</p>  </li>  <li><span><span>根据短块的长度，按</span></span><span><span>计算</span></span><span><span><span style=\"font-weight: normal;\">bound</span></span></span><span><span><span style=\"font-weight: normal;\">或</span></span></span><span><span><span style=\"font-weight: normal;\">通信bound</span></span></span><span><span>配平通算，得到长块的长度，长块长度尽量对齐128个元素，以保证计算亲和。本案例为</span></span><span><span><span style=\"font-weight: normal;\">通信bound</span></span></span><span><span><span style=\"font-weight: normal;\">场景</span></span></span><span><span>，这里的配平，即将短块的通信时间和长块的计算时间匹配相等：将t1作为长块的计算执行时间，带入t1 = CostMM(m1)公式，计算得到m1，即为长块的长度。</span></span></li>  <li><span><span><span><span><span>根据短块长度m0、长块长度m1、原始M轴长度M，得出长块的切块个数count = (M - m0) / m1。该式一般不能整除，此时需要做如下处理：</span></span></span></span></span>  <p><span><span>- 将结果的小数部分舍弃，保留整数部分作为切块个数。</span></span></p>   <p><span><span>- ​​​​​​​</span></span><span><span>由于舍弃了小数部分，M轴长度有剩余，因此需要调整长块长度m1 = (M - m0) / count。</span></span></p>   <p><span><span>- 为保持计算亲和，将长块长度m1调整至128对齐，即向下取128倍数的整数，更新长块长度m1。</span></span></p>   <p><span><span>- 由于调整m1后，M轴长度有剩余，因此调整短块长度m0 = M - (m1 * count)。</span></span></p>   <p><span><span>- 最终得到短块长度m0，长块长度m1，长块个数count。</span></span></p>  </li> </ol>  <h2>验证优化方案性能收益</h2>  <ul>  <li><span><span><span><span><span>制定切分策略并验证性能收益</span></span></span></span></span>   <p><span><span>本MatmulAllreduce案例中，给定的输入矩阵Shape为M=4096，K=3072，N=8192，数据类型为half，分核数为8，通过融合前msProf工具采集，得到该输入的Matmul计算执行时间为803us，AllReduce通信的执行时间为1071us，总耗时1874us，属于通信bound场景。按照上述的切分算法，本案例的具体切分情况如下：</span></span></p>  </li>  <li style=\"margin-left: 40.0px;\"><span><span>根据经验值选定短块（bound场景中短块为头块，即切分后的第一个数据块）M方向长度m0为384，则通信数据量x为：384 * 8192 * 2 / 1024 / 1024 = 6MB。按通信拟合公式估算通信的执行时间为143us。考虑可能会发生内存带宽冲突，因此再乘以1.15的系数，得出通信执行时间164us。</span></span></li>  <li style=\"margin-left: 40.0px;\"><span><span>计算长块M方向长度。根据短块通信时间，配平长块的计算执行时间同样为164us，按计算拟合公式估算出该长度m1为768。</span></span></li>  <li style=\"margin-left: 40.0px;\"><span><span>根据M=4096、m0=384、m1=768，计算长块个数：(4096 - 384) / 768 = 4.83，向下取整为4。</span></span></li>  <li style=\"margin-left: 40.0px;\"><span><span>根据短块长度m0=384，长块个数4，调整长块m1长度：(4096 - 384) / 4 = 928，向下按128对齐，调整m1为896。</span></span></li>  <li style=\"margin-left: 40.0px;\"><span><span>根据长块长度m1=896，长块个数4，调整短块m0长度：4096 - 896 * 4 = 512。</span></span></li>  <li style=\"margin-left: 40.0px;\"><span><span><span><span><span>最终得到将原始输入矩阵切分为5个数据块，长度分别为：{512，896，896，896，896}。</span></span></span></span></span></li> </ul>  <p style=\"margin-left: 40.0px;\"><span><span>如下代码所示，在算子的Tiling代码中设置制定好的切分策略。按该切分策略测试，融合后该算子的执行时间为1262us，则融合算子的性能收益为(1874 - 1262) / 1874 = 32.7%。</span></span></p>  <pre><br><code class=\"language-cpp\">MatmulAllReduceCustomTilingData *tiling = context-&gt;GetTilingData&lt;MatmulAllReduceCustomTilingData&gt;(); <br>tiling-&gt;param.rankDim = 8; <br>tiling-&gt;param.tileM = 512; // 短块大小 <br>tiling-&gt;param.tileNum = 1; // 短块个数 <br>tiling-&gt;param.tailM = 896; // 长块大小 <br>tiling-&gt;param.tailNum = 4; // 长块个数 <br>tiling-&gt;param.rankM = 4096; <br>tiling-&gt;param.rankN = 8192; <br>tiling-&gt;param.rankK = 4096; <br>tiling-&gt;param.isTransposeA = 0; <br>tiling-&gt;param.isTransposeB = 0; <br>tiling-&gt;param.cToFloatLen = 0; <br>tiling-&gt;param.nd2NzWorkLen = true; <br>tiling-&gt;param.dataType = static_cast&lt;uint8_t&gt;(HCCL_DATA_TYPE_MAP.at(aType));</code></pre>  <ul>  <li><span><span>针对切分膨胀做调整</span></span>​​​​​​​</li> </ul>  <p style=\"margin-left: 40.0px;\"><span><span>​​​​上文提到，切分数据会引起计算或通信执行时间的膨胀，使实测结果与理论值有偏差。比如切块数量较多时，执行时间的膨胀对性能影响较大，可能导致性能收益变小或者出现性能劣化，因此最终需要根据上述理论切分策略，结合实测，对切分策略做调整。</span></span></p>  <h2>总结</h2>  <p><span><span><span><span><span>MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>算子通过数据切分后计算和通信的并行执行，获得性能收益，但受数据切分后执行时间膨胀的影响。对MC</span></span><span><span><span style=\"vertical-align: super;\">2</span></span></span><span><span>算子进行性能调优的主要方式是制定数据切分策略，开发人员需要根据理论推导找到理想切分策略，然后根据实测结果调整，最终找到最优切分策略。</span></span></span></span></span></p>  <h2>更多学习资源</h2>  <p><span><span><span><span><span>了解更多Ascend C算子性能优化手段和实践案例，请访问：</span></span><a href=\"cid:link_3\" rel=\"nofollow\" target=\"_blank\" title=\"\"><span><span style=\"color: rgb(0,0,255);\">cid:link_3</span></span></a></span></span></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0201179457415507162-1-1.html",
        "clean_data": "标题：基于Ascend C的MC 通算融合算子性能优化最佳实践       内容提炼：     MC 通算融合算子 计算 通信 通过数据切分实现计算与通信的流水并行，提升大模型训练 推理性能。性能优化核心步骤：    1    判定限速因子 Bound           单独执行Matmul计算与通信 AllReduce ReduceScatter AllGather ，用msProf采集时间：            通信bound   通信耗时   计算 ：重点匹配通信时间            计算bound   计算耗时   通信 ：重点匹配计算时间    2    切分策略设计            仅切分M轴   通信需内存连续，N轴切分会断行           短块 m0 与长块 m1 匹配公式  ：          通信时间  t1   CostComm m0    1 15  预留15 内存冲突余量           计算时间  t2   CostMM m1    1 15 ，通过方程  t1   t2  确定长块大小          计算切块个数与长度对齐  ：           count    M   m0     m1           调整长块长度为128倍数 计算亲和     3    验证与调优          输入示例：MatmulAllReduce 4096x3072x8192  half         理论分块：  512 896 896 896 896   M轴         实际性能收益：从1874us 串行 降至1262us 32 7 提升         最终需结合实测微调切分策略以消除切分膨胀问题      适用场景  ：Ascend C编程、Atlas A2训练产品、ND格式、half精度、混合并行 SP TP 。     关键源码参数  ： tileM  短块 、 tailM  长块 、 tailNum  长块个数 ，需与硬件配置 如Hccl API要求 适配。      学习资源  ：通过案例实践 如MatmulAllReduce 掌握公式推导与代码配置 cid link 3 。",
        "created_at": "2025-04-08T01:33:36+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-08T01:16:56+08:00"
    },
    {
        "id": 15,
        "source_id": "19209105",
        "title": "【API】GE IR 转 AscIR时，缺失LessEq等api，需要补齐",
        "body": "一、问题现象（附报错日志上下文）：\nxxxx\n\n二、软件版本:\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \n--Tensorflow/Pytorch/MindSpore 版本:\n--Python 版本 (e.g., Python 3.7.5):\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\n--操作系统版本 (e.g., Ubuntu 18.04):\n\n三、测试步骤：\nxxxx\n\n\n四、日志信息:\nxxxx\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\n\n日志提供方式:\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\n\n获取方法请参考wiki：\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFPU9",
        "clean_data": "API GE IR转AscIR时LessEq等API缺失如何补全？",
        "created_at": "2025-01-05T10:55:37+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-05T11:10:13+08:00"
    },
    {
        "id": 163,
        "source_id": "0237182526863257107",
        "title": "XJTUSE-基于昇腾开发板的实践：从ResNet50图像分类，初始、清晰化到SSD目标检测",
        "body": "<div class=\"cke-article\"><h2 style=\"text-align: justify;\"><span style=\"display: none;\"> </span><span style=\"font-size: 16.0px;\"><span style=\"text-align: justify;\">随着人工智能技术的快速发展，AI模型在各个领域的应用越来越广泛。华为昇腾系列处理器以其强大的AI计算能力，为开发者提供了高效的推理平台。本文将介绍在昇腾开发板上实现ResNet50图像分类和SSD目标检测的技术实践。</span></span></h2>  <p style=\"text-align: justify;\"><span><span><strong><span><span><span><strong>ResNet50图像分类实践</strong></span></span></span></strong></span></span></p>  <p style=\"text-align: justify;\"><span><span><strong><span><span><span><strong>模型转换与准备</strong></span></span></span></strong></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>在昇腾开发板上运行AI模型前，首先需要将原始模型转换为昇腾处理器支持的离线模型(OM模型)。从提供的资料中可以看到，我们使用了ATC(Ascend Tensor Compiler)工具将MindSpore框架的ResNet50模型转换为OM格式：</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>atc --</span></span><span><span>framework=1--model=./resnet50.air --input_format=NCHW --output=resnet50 --log=error --soc_version=Ascend310B4</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>这个命令中几个关键参数值得注意：</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>--framework=1 表示原始模型</span></span><span><span>。</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>--soc_version=Ascend310B4 指定了</span></span><span><span>昇腾AI</span></span><span><span>处理器型号</span></span><span><span>,此处为</span></span><span><span>Ascend310B4</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>--input_format=NCHW 定义了输入Tensor的内存排列方式。</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>模型转换是昇腾开发流程中的关键一步，确保AI模型能够充分利用昇腾处理器的硬件加速能力。</span></span></span></span></p>  <p style=\"text-align: justify;\"></p>  <p style=\"text-align: justify;\"><span><span><strong><span><span><span><strong>推理流程与性能</strong></span></span></span></strong></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>从实践日志中可以看到推理流程：</span></span></span></span></p>  <p style=\"text-align: justify;\"><span class=\"easyimage easyimage-full\"><img alt=\"cke_9160.jpeg\" src=\"cid:pic_0\"></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>这表明模型成功地对不同图片进行了分类识别，将物体归类到正确的类别（猫、船、飞机等）。</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span> <strong><span><span><span><strong>初始、清晰化</strong></span></span></span></strong></span></span></p>  <p style=\"text-align: justify;\"><span class=\"easyimage easyimage-full\"><img alt=\"cke_13634.jpeg\" src=\"cid:pic_1\"></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>从日志中我们还注意到模型</span></span><span><span>清晰化</span></span><span><span>的关键步骤：</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>Init resource success</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>Init model resource start...</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>[AclliteModel] create model output dataset:</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>malloc output 0, size 3145728</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>Create model output dataset success</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>Init model resource success</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>pic:data1.png</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>pic_size:512x512</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>time:133ms</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>这段日志显示了模型资源的</span></span><span><span>初始、清晰化</span></span><span><span>过程，包括输出内存的分配（3,145,728字节）和512x512尺寸图片的处理时间（133ms）。合理的资源</span></span><span><span>初始</span></span><span><span>化是确保模型高效运行的基础。</span></span></span></span></p>  <p style=\"text-align: justify;\"></p>  <p style=\"text-align: justify;\"><span><span><strong><span><span><span><strong>SSD目标检测实践</strong></span></span></span></strong></span></span></p>  <p style=\"text-align: justify;\"><span><span><strong><span><span><span><strong>模型原理与特点</strong></span></span></span></strong></span></span></p>  <p style=\"text-align: justify;\"></p>  <p style=\"text-align: justify;\"><span><span><span><span>SSD(Single Shot MultiBox Detector)是一种高效的单阶段目标检测算法，其核心特点包括：</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>1. 多尺度检测：SSD使用了6种不同尺度的特征图（38×38到1×1），浅层特征检测小物体，深层特征检测大物体，实现了对不同尺寸目标的全面检测。</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>2. 卷积检测：与YOLO的全连接层不同，SSD直接使用3×3卷积核从特征图中提取检测结果，保持了空间信息。</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>3. 预设Anchor：SSD采用预设边界框（default bounding boxes）作为参考，网络只需预测相对于这些anchor的偏移量，简化了学习难度。</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>从提供的框架图可以看出，SSD通过&quot;Class prediction&quot;、&quot;Anchor box&quot;和&quot;Multiscale feature maps&quot;三个核心组件实现了高效检测。</span></span></span></span></p>  <p style=\"text-align: justify;\"></p>  <p style=\"text-align: justify;\"><span><span><strong><span><span><span><strong>环境准备与优化建议</strong></span></span></span></strong></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>实践过程中需要注意的环境准备：</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>1. 确保安装正确版本的MindSpore、pycocotools和OpenCV</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>2. 离线推理时可能遇到内存问题，需要参考FAQ</span></span><span><span>文档</span></span><span><span>进行优化</span></span><span><span>（</span></span><span><span>优化如下：</span></span><span><span>）</span></span></span></span></p>  <p style=\"text-align: justify;\"><span class=\"easyimage easyimage-full\"><img alt=\"cke_27387.jpeg\" src=\"cid:pic_2\"></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>3. 根据实际硬件配置调整batch size和输入尺寸</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>对于性能优化，可以考虑：</span></span></span></span></p>  <p style=\"text-align: justify;text-indent: 10.5pt;\"><span><span><span><span>1、</span></span><span><span>使用混合精度推理</span></span></span></span></p>  <p style=\"text-align: justify;text-indent: 10.5pt;\"><span><span><span><span>2、</span></span><span><span>优化预处理流水线</span></span></span></span></p>  <p style=\"text-align: justify;text-indent: 10.5pt;\"><span><span><span><span>3、</span></span><span><span>合理设置线程数和内存分配</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span> <strong><span><span><span><strong>昇腾开发实践总结</strong></span></span></span></strong></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>通过ResNet50和SSD两个典型案例，我们完整体验了在昇腾开发板上的AI模型实践流程：</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>1. 模型转换：使用ATC工具将框架模型转换为昇腾专用格式</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>2. 资源初始化：合理分配计算资源和内存</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>3. 推理优化：平衡预处理、推理和后处理的时间开销</span></span></span></span></p>  <p style=\"text-align: justify;\"><span><span><span><span>昇腾处理器展现了出色的推理性能，ResNet50的单图推理时间在500ms以内，SSD也能保持实时性要求。多尺度检测和预设Anchor等技术创新，使得SSD在精度和速度上取得了良好平衡。</span></span></span></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0237182526863257107-1-1.html",
        "clean_data": "在昇腾310B4开发板上完成ResNet50与SSD的完整AI部署流程。ResNet50通过ATC工具 Ascend Tensor Compiler 将MindSpore模型转换为OM格式，并完成133ms内512x512图像的分类推理，需注意配置框架版本与输入格式。SSD目标检测实现对不同尺寸物体的多尺度检测，包含预设Anchor和卷积预测两个核心技术特点。开发环境需匹配MindSpore pycocotools OpenCV版本，离线推理须按FAQ优化内存分配，建议通过调整batch size、混合精度推理、预处理流水线及线程内存配置提升性能。实践验证了昇腾平台同时满足ResNet50图像分类和SSD目标检测的精度与实时性需求。",
        "created_at": "2025-05-13T13:54:23+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-14T08:30:08+08:00"
    },
    {
        "id": 90,
        "source_id": "20649391",
        "title": "建立MLIR的测试系统",
        "body": "当前只有端到端的 triton 用例测试，没有更细粒度的 MLIR 测试系统，参见社区实现\r\n\r\n- https://github.com/triton-lang/triton/tree/main/test\r\n- https://github.com/microsoft/triton-shared/tree/main/test\r\n\r\n建立 MLIR 测试系统后，要集成进 CI 里。",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICAL67",
        "clean_data": "当前缺少MLIR单元测试系统，仅有Triton端到端测试案例。请参考实现：https   github com triton lang triton tree main test 与 https   github com microsoft triton shared tree main test，构建细粒度测试框架，并集成至CI。",
        "created_at": "2025-05-26T16:21:13+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T16:21:13+08:00"
    },
    {
        "id": 63,
        "source_id": "20522720",
        "title": "在kernel中加入 AscendC::printf(\"test\\n\");后，执行时会报错",
        "body": "一、问题现象（附报错日志上下文）：\n在kernel中加入 AscendC::printf(\"test\\n\");后，执行时会报错\n![输入图片说明](https://foruda.gitee.com/images/1747301230964920895/317cdcf5_11274154.png \"屏幕截图\")\n二、软件版本:\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \nversion: 1.0\nruntime_running_version=[7.7.T20.0.B210:8.1.RC1]\ncompiler_running_version=[7.7.T20.0.B210:8.1.RC1]\nhccl_running_version=[7.7.T20.0.B210:8.1.RC1]\nopp_running_version=[7.7.T20.0.B210:8.1.RC1]\ntoolkit_running_version=[7.7.T20.0.B210:8.1.RC1]\naoe_running_version=[7.7.T20.0.B210:8.1.RC1]\nncs_running_version=[7.7.T20.0.B210:8.1.RC1]\nopp_kernel_running_version=[7.7.T20.0.B210:8.1.RC1]\nruntime_upgrade_version=[7.7.T20.0.B210:8.1.RC1]\ncompiler_upgrade_version=[7.7.T20.0.B210:8.1.RC1]\nhccl_upgrade_version=[7.7.T20.0.B210:8.1.RC1]\nopp_upgrade_version=[7.7.T20.0.B210:8.1.RC1]\ntoolkit_upgrade_version=[7.7.T20.0.B210:8.1.RC1]\naoe_upgrade_version=[7.7.T20.0.B210:8.1.RC1]\nncs_upgrade_version=[7.7.T20.0.B210:8.1.RC1]\nopp_kernel_upgrade_version=[7.7.T20.0.B210:8.1.RC1]\nruntime_installed_version=[7.7.T20.0.B210:8.1.RC1]\ncompiler_installed_version=[7.7.T20.0.B210:8.1.RC1]\nhccl_installed_version=[7.7.T20.0.B210:8.1.RC1]\nopp_installed_version=[7.7.T20.0.B210:8.1.RC1]\ntoolkit_installed_version=[7.7.T20.0.B210:8.1.RC1]\naoe_installed_version=[7.7.T20.0.B210:8.1.RC1]\nncs_installed_version=[7.7.T20.0.B210:8.1.RC1]\nopp_kernel_installed_version=[7.7.T20.0.B210:8.1.RC1]\n--Tensorflow/Pytorch/MindSpore 版本:\n--Python 版本 (e.g., Python 3.7.5):\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\n--操作系统版本 (e.g., Ubuntu 18.04):\n\n三、测试步骤：\n在任意kernel的核函数中加入AscendC::printf(\"test\\n\");后都会报错\n![输入图片说明](https://foruda.gitee.com/images/1747280475696665216/9160c1e5_11274154.png \"屏幕截图\")\n\n四、日志信息:\nplog部分日志\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.256.624 [stars_engine.cc:1551]557413 ProcLogicCqReport:Task run failed, device_id=0, stream_id=2, task_id=1, sqe_type=0(ffts), errType=0x1(task exception), sqSwStatus=0\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.290.970 [device_error_proc.cc:1434]557413 ProcessStarsCoreErrorInfo:report error module_type=5, module_name=EZ9999\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.290.980 [device_error_proc.cc:1434]557413 ProcessStarsCoreErrorInfo:The error from device(chipId:0, dieId:0), serial number is 1612, there is an fftsplus aivector error exception, core id is 37, error code = 0, dump info: pc start: 0x12c0c00b2dd0, current: 0x12c0c00b39a0, vec error info: 0xe700003cde, mte error info: 0x8306000054, ifu error info: 0x2fffffb500000, ccu error info: 0x2ef0c5276700005d, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c100340080.\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.291.101 [device_error_proc.cc:1446]557413 ProcessStarsCoreErrorInfo:report error module_type=5, module_name=EZ9999\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.291.106 [device_error_proc.cc:1446]557413 ProcessStarsCoreErrorInfo:The extend info: errcode:(0, 0x4000, 0) errorStr: CCU instruction address check error. fixp_error0 info: 0x6000054, fixp_error1 info: 0x83, fsmId:0, tslot:2, thread:0, ctxid:0, blk:0, sublk:0, subErrType:4.\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.291.156 [davinci_kernel_task.cc:1400]557413 SetStarsResultForDavinciTask:AICORE Kernel task happen error, retCode=0x26.\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.291.808 [davinci_kernel_task.cc:1337]557413 PreCheckTaskErr:report error module_type=5, module_name=EZ9999\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.291.814 [davinci_kernel_task.cc:1337]557413 PreCheckTaskErr:Kernel task happen error, retCode=0x26, [aicore exception].\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.297.753 [davinci_kernel_task.cc:1248]557413 PrintErrorInfoForDavinciTask:Aicore kernel execute failed, device_id=0, stream_id=2, report_stream_id=2, task_id=1, flip_num=0, fault kernel_name=_Z7MLABf16mPhS_S_S_S_S_S_S_S_S_S_S_S_S_, fault kernel info ext=_Z7MLABf16mPhS_S_S_S_S_S_S_S_S_S_S_S_S_, program id=1, hash=9266734828636082699.\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.297.815 [davinci_kernel_task.cc:1186]557413 GetArgsInfo:[AIC_INFO] args(0 to 15) after execute:0xdfffd7271000, 0x12c0c0013000, 0x12c0c0024000, 0x12c041200000, 0x12c0c0027000, 0x12c0c0068000, 0x12c0c0071000, 0x12c0c0072000, 0x12c041600000, 0x12c042400000, 0x12c042c00000, 0x12c043a00000, 0x12c0c0084000, 0x12c0c00a5000, 0x12c0c0083000,  \n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.297.821 [davinci_kernel_task.cc:1189]557413 GetArgsInfo:tilingKey = 0, print 1 Times totalLen=(15*8)Bytes, argsSize=120, blockDim=24\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.297.830 [davinci_kernel_task.cc:1252]557413 PrintErrorInfoForDavinciTask:[AIC_INFO] after execute:args print end\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.297.854 [davinci_kernel_task.cc:1152]557413 GetMixCtxInfo:The DavinciTask Mix context-buf[0]=0x00000006.\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.297.858 [davinci_kernel_task.cc:1152]557413 GetMixCtxInfo:The DavinciTask Mix context-buf[1]=0000000000.\n[ERROR] RUNTIME(557413,19_mla):2025-05-14-13:19:08.297.862 [davinci_kernel_task.cc:1152]557413 GetMixCtxInfo:The DavinciTask Mix context-buf[2]=0000000000.\n\n日志提供方式:\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\n\n获取方法请参考wiki：\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/catlass/issues/IC7VFK",
        "clean_data": "问题标题：在kernel中加入AscendC  printf  test n   后执行报错      关键信息：     在CANN 1 0环境下，于内核核函数中插入AscendC  printf调用后触发AICORE执行异常 错误码0x26 。     日志特征：       CCU指令地址检查错误  errorStr  CCU instruction address check error       报错信息关联到 davinci kernel task cc 中 SetStarsResultForDavinciTask  AICORE Kernel task happen error       可能原因：     AscendC  printf在当前CANN版本中未支持内核空间调用，直接使用会导致硬件异常。      建议处理：     1  检查官方文档确认printf在ACCP内核中的使用限制或替代方法 如通过Host端调试 ；   2  升级至更高版本CANN以验证是否修复兼容性问题；   3  避免在内核核函数中直接插入printf，改用其他输出接口或日志方式。",
        "created_at": "2025-05-14T21:28:40+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T11:39:54+08:00"
    },
    {
        "id": 175,
        "source_id": "02114177739207451013",
        "title": "【tbe】一个基于tik使能double buffer的小例子",
        "body": "<div class=\"cke-article\"><p><strong>背景</strong>：在tik文档中简单描述了 thread_num=2 可以使能 double buffer, 但没有完整的例子，试验过程中踩坑无数。包括目前AI也不能生成一个正确的版本，因此分享下试验成功的小例子</p>  <p><strong>完整的例子</strong>：</p>  <blockquote> <p>from tbe import tik</p>  <p>from tbe.common.platform import set_current_compile_soc_info</p>  <p></p>  <p>def ping_pong_operation():</p>  <p>    set_current_compile_soc_info(&quot;Ascend310P3&quot;)</p>  <p></p>  <p></p>  <p>    # Create a TIK instance</p>  <p>    tik_instance = tik.Tik()</p>  <p></p>  <p></p>  <p>    # Define global memory tensors for input and output data</p>  <p>    input_data = tik_instance.Tensor(&quot;float16&quot;, (4096,), name=&quot;input_data&quot;, scope=tik.scope_gm)</p>  <p>    output_data = tik_instance.Tensor(&quot;float16&quot;, (4096,), name=&quot;output_data&quot;, scope=tik.scope_gm)</p>  <p></p>  <p></p>  <p>    # Define two buffers in the unified buffer (UB)</p>  <p>    buffer_size = 128  # Size of each buffer, 128 * sizeof (float16) = 256 Bytes</p>  <p>    src_buffer = tik_instance.Tensor(&quot;float16&quot;, (buffer_size,), name=&quot;src_buffer&quot;, scope=tik.scope_ubuf)</p>  <p>    dst_buffer = tik_instance.Tensor(&quot;float16&quot;, (buffer_size,), name=&quot;dst_buffer&quot;, scope=tik.scope_ubuf)</p>  <p></p>  <p></p>  <p>    # Use thread_num=2 to parallelize the ping-pong operations</p>  <p>    loop_times = 32</p>  <p>    # Ping-pong operation logic</p>  <p>    with tik_instance.for_range(0, loop_times, thread_num=2) as i:</p>  <p>        tik_instance.data_move(src_buffer, input_data[i * buffer_size], 0, 1, buffer_size &gt;&gt; 5, 0, 0)</p>  <p>        tik_instance.vec_add(128, dst_buffer, src_buffer, src_buffer, buffer_size // 128, 8, 8, 8)</p>  <p>        tik_instance.data_move(output_data[i * buffer_size], dst_buffer, 0, 1, buffer_size &gt;&gt; 5, 0, 0)</p>  <p></p>  <p></p>  <p>    tik_instance.BuildCCE(kernel_name=&quot;tik_vec_add_128_float16&quot;, inputs=[input_data], outputs=[output_data])</p>  <p>    return tik_instance</p>  <p></p>  <p></p>  <p>if __name__ == &quot;__main__&quot;:</p>  <p>    # Call the ping_pong_operation function to generate the TIK code</p>  <p>    tik_instance = ping_pong_operation()</p>  <p>    print(&quot;TIK code generated successfully!&quot;)</p> </blockquote>  <p><strong>注意</strong>：</p>  <blockquote> <p>a) 使用tik_instance.for_range(0, loop_times, thread_num=2)自动的完成buffer的切分，因此不需要再手动的使用 with tik_instance.if_scope((i % 2) == 0): 分别编写ping和pong部分的逻辑</p>  <p>b）计算逻辑tik_instance.vec_add的源和目的操作数不能使用同一块内存，否则导致迭代间的依赖，从而导致pingpang失效</p> </blockquote>  <p><strong>对应的中间文件cce逻辑</strong>：EVENT_ID 使用1个，不需要确保ping和pong部分独立使用不同的EVENT_ID</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"image.png\" src=\"cid:pic_0\"></span></p>  <p>对应的仿真图：MET2/MET3是紧挨着加载</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"image.png\" src=\"cid:pic_1\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-02114177739207451013-1-1.html",
        "clean_data": "TBE Tik Double Buffer使能示例  1  背景需求：Tik文档未提供完整双缓存代码示例 2  关键实现：通过设置thread num 2的for range自动完成buffer切分 3  代码要点：      编译配置：set current compile soc info  Ascend310P3        内存定义：256字节UB缓存 128 float16       双缓操作：for range实现在ubuff中交替读写 4  注意事项：    a  不需要手动编写if scope分支    b  vec add操作需使用不同内存地址 避免迭代依赖  5  结果验证：已生成CCE中间文件，EVENT ID自动管理；提供MET2 MET3加载时序仿真图",
        "created_at": "2025-03-19T04:00:07+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-19T07:21:25+08:00"
    },
    {
        "id": 43,
        "source_id": "20328837",
        "title": "ContructGeShapeFromRtShape函数名存在拼写错误，\"Contruct\"应为\"Construct\"（需要全局替换修复）",
        "body": "ContructGeShapeFromRtShape函数名存在拼写错误，\"Contruct\"应为\"Construct\"（需要全局替换修复）\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IC3PTX",
        "clean_data": "ContructGeShapeFromRtShape函数名需全局修正为ConstructGeShapeFromRtShape",
        "created_at": "2025-04-24T17:15:24+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-24T17:15:24+08:00"
    },
    {
        "id": 158,
        "source_id": "02115184387829832044",
        "title": "Synchronize stream failed, error code is 507046,",
        "body": "<div class=\"cke-article\"><p>在做cast+matmul的算子融合，在编译之前，总是报错Synchronize stream failed</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1348.png\" src=\"cid:pic_0\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-02115184387829832044-1-1.html",
        "clean_data": "适用于cast matmul算子融合场景的 Synchronize stream failed  507046  错误排查：在未进入编译阶段即触发的显存同步错误，通常由资源分配冲突或stream操作序列异常导致。该问题与算子融合实现中显存管理机制相关，建议检查显存分配顺序并确认stream对象生命周期管理符合文档规范，必要时可通过社区issue工具提交完整环境参数与操作日志进一步诊断。",
        "created_at": "2025-06-04T02:50:30+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T01:30:15+08:00"
    },
    {
        "id": 75,
        "source_id": "20560463",
        "title": "w-最新cann版本在哪里",
        "body": "![输入图片说明](https://foruda.gitee.com/images/1747622363243328011/6407e8a4_1215735.png \"屏幕截图\")只有6.0的对应配套吗，最新8.0的在哪里 \r\nhttps://gitee.com/ascend/samples/blob/master/docs/CHANGELOG.md",
        "url": "https://gitee.com/ascend/samples/issues/IC8OJZ",
        "clean_data": "问题标题指示查询CANN最新版本路径，但实际提供的链接指向昇腾样本库的更新日志。核心需求是8 0版本CANN的获取途径，当前资源目录可能未完整展示。简化结论：当前文档未包含最新8 0 CANN版本，需访问官方下载地址或社区文档中心获取。 已去除同义词 配套  资源  如何解决 等冗余表述，关联标题核心诉求",
        "created_at": "2025-05-19T10:40:05+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-22T15:05:55+08:00"
    },
    {
        "id": 149,
        "source_id": "0246172984876137283",
        "title": "CANN8.0.RC1问题导致训练任务启动失败，错误码EI0009",
        "body": "<div class=\"cke-article\"><h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-spacing: 0.0px;\">【问题描述】：</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">模型多机训练任务启动初始化失败</p>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-spacing: 0.0px;\">【告警信息】:</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">EI0009: 2025-01-06-11:45:24.276.468 Transport init error. Reason: [Create][DestLink]Create Dest error! creakLink para:rank[0]-localUserrank[0]-localIpAddr[10.240.32.158], dst_rank[1]-remoteUserrank[8]-remote_ip_addr[10.240.33.78]<br>         Solution: Check other NPUs that are not reporting errors, or check if there are any abnormalities on the other end's NPU.</p>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-spacing: 0.0px;\">【产品及版本】:</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">CANN 8.0.RC1</p>  <h3 style=\"box-sizing: border-box;\">【分析过程】：</h3>  <p style=\"box-sizing: border-box;word-break: break-word;\">1. 训练日志报错，错误码EI0009。</p>  <p style=\"box-sizing: border-box;word-break: break-word;\"><br> 2. 查看plog日志，显示HCCP 错误</p>  <p style=\"box-sizing: border-box;word-break: break-word;\">[ERROR] HCCP(2210,python3):2025-01-06-10:04:09.261.455 [ra_hdc.c:876]tid:11543,ra_hdc_qp_create_with_attrs(876) : [create][ra_hdc_qp_with_attrs]ra hdc message process failed ret(-12) phy_id(0)<br> [ERROR] HCCP(2210,python3):2025-01-06-10:04:09.261.464 [ra_host.c:1390]tid:11543,ra_qp_create_with_attrs(1390) : [create][ra_qp_with_attrs]create qp fail, ret(-12) phy_id(0)</p>  <p style=\"box-sizing: border-box;word-break: break-word;\"><br> 3. 进一步查看device日志，RoCE用户态驱动报错，显示HCCP内存初始化失败</p>  <p style=\"box-sizing: border-box;word-break: break-word;\">ERROR] ROCE(23559,hccp_service.bin):2025-01-06-10:04:10.520.336 [hns_roce_hal.c:82]hns_roce_hal_alloc_buf(82) : hns_roce_hal_alloc_buf mmap fail. start addr 0xffffffffffffffff length 0x400000<br> [ERROR] ROCE(23559,hccp_service.bin):2025-01-06-10:04:10.520.362 [hns_roce_u_buf.c:210]roce_init_mem_pool(210) : hns init pool failed, hal_alloc_buf failed ret = -12<br> [ERROR] HCCP(23559,hccp_service.bin):2025-01-06-10:04:10.520.371 [rs_rdma.c:1453]tid:23569,rs_init_mem_pool(1453) : rs_roce_init_mem_pool failed, ret=-12, chip_id=0<br> [ERROR] HCCP(23559,hccp_service.bin):2025-01-06-10:04:10.520.379 [rs_rdma.c:1655]tid:23569,rs_alloc_qpcb_with_attrs(1655) : init mem pool failed ret -12<br> [ERROR] HCCP(23559,hccp_service.bin):2025-01-06-10:04:10.520.395 [rs_rdma.c:1714]tid:23569,rs_qp_create_with_attrs(1714) : alloc mem for qp_cb fail, ret:-12<br> [ERROR] HCCP(23559,hccp_service.bin):2025-01-06-10:04:10.520.408 [ra_adp.c:553]tid:23569,ra_rs_qp_create_with_attrs(553) : qp create failed ret[-12].</p>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-spacing: 0.0px;\">【根因】：</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">CANN8.0.RC1版本质量问题，在主机内存页大小如果<strong><span style=\"color: rgb(230,62,60);\">不是</span></strong>4k的场景下会默认开启RDMA lite特性，HCCP通信会申请2MB大页映射内存，如果申请不到则会导致HCCP通信失败。</p>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-spacing: 0.0px;\">【解决方案】：</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">升级CANN至8.0.RC2以及之后版本。</p>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-spacing: 0.0px;\">【相关知识】：</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-align: left;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">使用CANN 8.0.RC2之后的版本，增加了RDMA lite特性开关，可以设置 HCCL_RDMA_PCIE_DIRECT_POST_NOSTRICT = FALSE来关闭该特性。<br> <a href=\"cid:link_0\" style=\"box-sizing: border-box;background: transparent;color: rgb(18,108,168);outline: none;cursor: pointer;text-decoration: none;\" target=\"_blank\">cid:link_0</a></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0246172984876137283-1-1.html",
        "clean_data": "问题精要 CANN8 0 RC1版因主机内存页大小非4K时强制启用RDMA lite特性导致HCCP内存池初始化失败 错误码EI0009 ，多机训练任务无法启动。日志显示RoCE驱动在申请2MB大页时mmap失败 ret  12 。建议升级至8 0 RC2以上版本，通过版本更新解决大页内存分配问题，或级联设置HCCL RDMA PCIE DIRECT POST NOSTRICT False规避。",
        "created_at": "2025-01-23T03:21:16+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-23T03:21:16+08:00"
    },
    {
        "id": 577,
        "source_id": "20780997",
        "title": "CVE-2023-47641",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-47641](https://nvd.nist.gov/vuln/detail/CVE-2023-47641)\n漏洞归属组件：aiohttp\n漏洞归属的版本：3.7.4\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\naiohttp is an asynchronous HTTP client/server framework for asyncio and Python. Affected versions of aiohttp have a security vulnerability regarding the inconsistent interpretation of the http protocol. HTTP/1.1 is a persistent protocol, if both Content-Length(CL) and Transfer-Encoding(TE) header values are present it can lead to incorrect interpretation of two entities that parse the HTTP and we can poison other sockets with this incorrect interpretation. A possible Proof-of-Concept (POC) would be a configuration with a reverse proxy(frontend) that accepts both CL and TE headers and aiohttp as backend. As aiohttp parses anything with chunked, we can pass a chunked123 as TE, the frontend entity will ignore this header and will parse Content-Length. The impact of this vulnerability is that it is possible to bypass any proxy rule, poisoning sockets to other users like passing Authentication Headers, also if it is present an Open Redirect an attacker could combine it to redirect random users to another website and log the request. This vulnerability has been addressed in release 3.8.0 of aiohttp. Users are advised to upgrade. There are no known workarounds for this vulnerability.\n\n漏洞公开时间：2023-11-15 05:15:13\n漏洞创建时间：2025-06-08 01:10:53\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-47641\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEPX",
        "clean_data": "CVE 2023 47641：aiohttp 3 7 4版本存在HTTP协议解析漏洞，当请求同时包含Content Length和Transfer Encoding头时，将错误识别分块编码 如chunked123 ，导致多实体处理冲突。攻击者可通过反向代理配置构造恶意TE头，绕过代理规则并毒害其他用户套接字 如篡改认证头 ，结合开放重定向可实施钓鱼攻击。该漏洞已通过升级至v3 8 0修复，无可用临时缓解方案。",
        "created_at": "2025-06-08T01:10:54+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T01:10:54+08:00"
    },
    {
        "id": 578,
        "source_id": "20781003",
        "title": "CVE-2023-43665",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-43665](https://nvd.nist.gov/vuln/detail/CVE-2023-43665)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn Django 3.2 before 3.2.22, 4.1 before 4.1.12, and 4.2 before 4.2.6, the django.utils.text.Truncator chars() and words() methods (when used with html=True) are subject to a potential DoS (denial of service) attack via certain inputs with very long, potentially malformed HTML text. The chars() and words() methods are used to implement the truncatechars_html and truncatewords_html template filters, which are thus also vulnerable. NOTE: this issue exists because of an incomplete fix for CVE-2019-14232.\n\n漏洞公开时间：2023-11-03 13:15:30\n漏洞创建时间：2025-06-08 01:11:06\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-43665\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEQ3",
        "clean_data": "CVE 2023 43665：Django 3 2 7及更早版本中， django utils text Truncator  的  chars    和  words    方法在启用  html True  参数时存在HTML长文本处理的DoS漏洞 未完全修复CVE 2019 14232 ，建议升级至 3 2 22 4 1 12 4 2 6。详情参考：https   nvd nist gov vuln detail CVE 2023 43665。",
        "created_at": "2025-06-08T01:11:07+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T01:11:07+08:00"
    },
    {
        "id": 579,
        "source_id": "20781004",
        "title": "CVE-2023-46137",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-46137](https://nvd.nist.gov/vuln/detail/CVE-2023-46137)\n漏洞归属组件：twisted\n漏洞归属的版本：17.9.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nTwisted is an event-based framework for internet applications. Prior to version 23.10.0rc1, when sending multiple HTTP requests in one TCP packet, twisted.web will process the requests asynchronously without guaranteeing the response order. If one of the endpoints is controlled by an attacker, the attacker can delay the response on purpose to manipulate the response of the second request when a victim launched two requests using HTTP pipeline. Version 23.10.0rc1 contains a patch for this issue.\n\n漏洞公开时间：2023-10-26 05:15:10\n漏洞创建时间：2025-06-08 01:11:09\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-46137\n",
        "url": "https://gitee.com/ascend/modelzoo-TensorFlow-bak/issues/ICDEQ4",
        "clean_data": "Twisted HTTP pipeline响应顺序漏洞修复方法",
        "created_at": "2025-06-08T01:11:09+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T01:11:09+08:00"
    },
    {
        "id": 580,
        "source_id": "20781012",
        "title": "CVE-2023-41164",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-41164](https://nvd.nist.gov/vuln/detail/CVE-2023-41164)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn Django 3.2 before 3.2.21, 4.1 before 4.1.11, and 4.2 before 4.2.5, django.utils.encoding.uri_to_iri() is subject to a potential DoS (denial of service) attack via certain inputs with a very large number of Unicode characters.\n\n漏洞公开时间：2023-11-03 13:15:29\n漏洞创建时间：2025-06-08 01:11:24\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-41164\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEQC",
        "clean_data": "CVE 2023 41164：Django 3 2 7及4 1 x 4 2 x部分版本中， uri to iri   函数处理大量Unicode字符时存在潜在DoS攻击风险。影响版本：Django 3 2 x 3 2 21、4 1 x 4 1 11、4 2 x 4 2 5。解决方案：升级到对应版本3 2 21 4 1 11 4 2 5以上。",
        "created_at": "2025-06-08T01:11:24+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T01:11:25+08:00"
    },
    {
        "id": 130,
        "source_id": "02102182676529679115",
        "title": "call aclnnCast failed",
        "body": "<div class=\"cke-article\">  <p>python3.10/site-packages/torch_npu/utils/_module.py&quot;, line 73, in convert </p>  <p>    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking) </p>  <p>RuntimeError: call aclnnCast failed, detail:EZ9999: Inner Error! </p>  <p>EZ9999: 2025-05-15-07:14:38.496.256  Parse dynamic kernel config fail. </p>  <p>        TraceBack (most recent call last): </p>  <p>        AclOpKernelInit failed opType </p>  <p>        Op Cast does not has any binary. </p>  <p>        Kernel Run failed. opType: 3, Cast </p>  <p>        launch failed for Cast, errno:561000. </p>    <p>[ERROR] 2025-05-15-07:14:38 (PID:63004, Device:0, RankID:-1) ERR01005 OPS internal error </p></div>",
        "url": "https://www.hiascend.com/forum/thread-02102182676529679115-1-1.html",
        "clean_data": "问题复现于PyTorch使用NPU执行 aclnnCast 转换操作时。关键报错链为： AclOpKernelInit failed opType 3     Op Cast does not has any binary     Parse dynamic kernel config fail ，最终触发 ERR01005 OPS internal error 。验证NPU Cast算子的二进制依赖缺失或内核配置失败导致操作初始化异常。   附关键路径： torch npu utils  module py 第73行类型转换引发内核错误",
        "created_at": "2025-05-15T07:28:50+08:00",
        "topic_summary": "开发者安装配置是漏装必要软件包，导致运行失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-15T11:11:02+08:00"
    },
    {
        "id": 145,
        "source_id": "02113174822711087044",
        "title": "中国区自然资源行业林草局森林防火和生物多样性识别算法如何适配Atlas 500",
        "body": "<div class=\"cke-article\"><p>   从场景洞察出发，森林防火和生物多样识别是林业局的两个职责，森林火情识别和扑灭对森林防火是重中之重的业务场景，前者是森林保护的职责，火情要在2秒内识别出来；后者是生态保护的职责，生物物种被野保相机或摄像头捕捉后能自动被机器识别出来。</p>  <p>  火情识别和生物多样性识别，依靠算法和硬件平台计算。算法部分主要是合作伙伴开发，合作伙伴在行业内积累了二三十年的业务经验，算法准确率比较高。硬件平台主要利用Atlas 500的边缘计算能力，加载识别算法后，对每张图片进行分析，符合算法特征的图片提取出来。</p>  <p>   为了调试算法和智算平台适配，作者根据业务场景设计了方案初稿，验证算法在华为智算平台上功能并完成转商业要求。</p>  <p>    伙伴的“森林眼”算法要适配的功能包括：双光谱识别、RAW数据识别、快速巡航和全量巡航模式识别、边端云三者计算资源使用这几类功能。为了验证调试这些功能，内部做了些准备。</p>  <p>环境配置：至少要求Atlas 500配置两张NPU卡，4P算力，而且需要配合算法，开通华为云和本地部署Atlas互通接口。</p>  <p>数据配置：烟火数据、红外线数据、RAW数据和图片以及几种模式的算法软件</p>  <p>权限配置：外部接入实验室流程申请</p>  <p>过程配置：项目管理监控配置、达标成果汇报</p>  <p></p>  <p>这样的适配通常需要大约两个月的投入，成本估算如下：</p>  <p>     SA：前期业务场景交流调研 5人天，场景洞察设计12人天，成果转化汇报5人天。技术工程师：内部准备22人天。</p>  <p>如果按1075元/人天计算，人力成本47300元。</p>  <p>   </p></div>",
        "url": "https://www.hiascend.com/forum/thread-02113174822711087044-1-1.html",
        "clean_data": "林草局森林防火 需2秒内热成像 可见光 RAW数据识别火情 与生物多样性识别 野保相机物种自动识别 算法适配Atlas 500方案。需配置4P算力双NPU卡设备，开通云端协作接口，准备双光谱 红外 RAW图像数据，并完成实验室接入流程。适配周期约2月，成本约4 73万元 含场景调研 成果转化 内部技术准备 。",
        "created_at": "2025-02-13T09:51:51+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-13T09:51:51+08:00"
    },
    {
        "id": 84,
        "source_id": "20616879",
        "title": "CVE-2021-45116",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-45116](https://nvd.nist.gov/vuln/detail/CVE-2021-45116)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nAn issue was discovered in Django 2.2 before 2.2.26, 3.2 before 3.2.11, and 4.0 before 4.0.1. Due to leveraging the Django Template Language_x27;s variable resolution logic, the dictsort template filter was potentially vulnerable to information disclosure, or an unintended method call, if passed a suitably crafted key.\n\n漏洞公开时间：2022-01-05 08:15:07\n漏洞创建时间：2025-05-23 06:40:04\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-45116\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/IC9W33",
        "clean_data": "CVE 2021 45116 Django 2 2 3 2 4 0版本dictsort过滤器变量解析逻辑漏洞    Django 2 2  2 2 26 、3 2  3 2 11 及 4 0  4 0 1 的 dictsort 模板过滤器因模板变量解析逻辑缺陷，可能因恶意构造的 key 参数触发信息泄露或意外方法调用。需升级至上述版本修复。漏洞公开日期2022 01 05，请参考 NVD详情  https   nvd nist gov vuln detail CVE 2021 45116 。",
        "created_at": "2025-05-23T06:40:04+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-23T06:40:05+08:00"
    },
    {
        "id": 159,
        "source_id": "0248184333883592053",
        "title": "混合型算子融合，如何指定从vec侧或者是cube侧开发",
        "body": "<div class=\"cke-article\"><p><strong><span style=\"font-size: 20.0px;\">op-kernel.cpp侧</span></strong></p>  <p>#define EXEC_MATMUL_CAST0 \\</p>  <p>using xType = MatmulType&lt;AscendC::TPosition::GM, CubeFormat::ND, y_type, trans_a&gt;; \\</p>  <p>using weightType = MatmulType&lt;AscendC::TPosition::GM, CubeFormat::ND, y_type, trans_b&gt;; \\</p>  <p>using yType = MatmulType&lt;AscendC::TPosition::GM, CubeFormat::ND, y_type&gt;; \\</p>  <p>using biasType = MatmulType&lt;AscendC::TPosition::GM, CubeFormat::ND, tensor_type&gt;; \\</p>  <p>using matmulType = matmul::Matmul&lt;xType, weightType, yType, biasType, CFG_MDL&gt;; \\</p>  <p>matmulType mm; \\</p>  <p>REGIST_MATMUL_OBJ(&amp;tPipe, GetSysWorkSpacePtr(), mm, mmTiling);</p>  <p>// mm.SetSubBlockIdx(0);</p>  <p></p>  <p></p>  <p>//定义矩阵乘法操作的执行流程，包括初始化和计算过程</p>  <p>#define EXEC_MATMUL_CAST1 \\</p>  <p>mm.Init(mmTiling, &amp;tPipe); \\</p>  <p>mlp_ops_matmul_cast::MatmulCastCompute&lt;decltype(mm), tensor_type, y_type, trans_a, trans_b&gt; computeOp(mm, tiling_data); \\</p>  <p>computeOp.Init(a, b, y, user); \\</p>  <p>mlp_ops_matmul_cast::MatmulCastProcess&lt;decltype(computeOp)&gt; op(computeOp, tiling_data); \\</p>  <p>op.Init(); \\</p>  <p>op.Process();</p>  <p></p>  <p></p>  <p><span style=\"font-size: 20.0px;\"><strong>在__aicore__ inline void MatmulCastProcess&lt;ComputeType&gt;::Process_() {}中打印</strong></span></p>  <p>if (g_coreType == AIC) {</p>  <p>printf(&quot;g_coreType is AIC\\n&quot;);</p>  <p>} else {</p>  <p>printf(&quot;g_coreType is AiV\\n&quot;);}</p>  <p>printf(&quot;coreIdx: %d\\n&quot;, coreIdx);</p>  <p>// cast A</p>  <p>computeOp.TensorACast(mnConfig.m, mnConfig.k, coreIdx);</p>  <p>printf(&quot;TensorACast finished&quot;)</p>  <p></p>  <p></p>  <p><strong><span style=\"font-size: 20.0px;\">结果都是aicube，</span></strong></p>  <p>这不是指定了aiv嘛？？？ 为什么都是aicube的coreidx？？？输出如下</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_29459.png\" src=\"cid:pic_0\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184333883592053-1-1.html",
        "clean_data": "混合算子核心侧开发配置异常     用户在op kernel中定义 TPosition  GM 和 CubeFormat  ND 并调用 MatmulCastProcess ，但执行时 g coreType 始终为AIC，未按预期切换至AIV。代码路径未触发AIV相关逻辑，需排查如何正确基于AIV标签实现算子执行侧分配。",
        "created_at": "2025-06-03T11:51:24+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T01:09:12+08:00"
    },
    {
        "id": 74,
        "source_id": "20560344",
        "title": "w-内存未释放",
        "body": "一、需求场景&价值\r\n![输入图片说明](https://foruda.gitee.com/images/1747622174722867114/45f25ea3_1215735.png \"屏幕截图\")\r\n参考链接：\r\nhttps://www.hiascend.com/document/detail/zh/canncommercial/800/developmentguide/appdevg/aclcppdevg/aclcppdevg_000063.html\r\n\r\n我们这边在310B上面遇到一个问题，使用dvpp V2解码的时候，不送数据解码多次重启解码器内存使用正常。送入数据正常解码，解码结果、内存都正常。重启解码器6 7次后内存会突然增加很多，关闭解码器内存也不释放。这种情况一台盒子有，一台盒子没有，操作系统是ubuntu22，cann8.0.这一块要怎么排查呢？",
        "url": "https://gitee.com/ascend/samples/issues/IC8OGO",
        "clean_data": "问题：dvpp V2解码器在Ubuntu22 CANN8 0环境中多次重启导致内存异常增长且未释放 现象：送入数据解码后重复重启6 7次，内存持续增加且关闭后无法释放；同机型另一设备未复现该问题 需排查方向：1 内存释放逻辑是否执行完整 2 解码场景是否存在缓存机制未触发 3 设备间系统环境 CANN组件 驱动版本差异 4 采用内存监控工具定位泄漏点",
        "created_at": "2025-05-19T10:36:57+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-22T15:06:30+08:00"
    },
    {
        "id": 61,
        "source_id": "20497631",
        "title": "模型推理中使用torch_atb linear报错",
        "body": "一、问题现象（附报错日志上下文）：\r\nSegmentation fault (core dumped)\r\nroot@6f3a09c20be0:/dfs/home/liujing/aaa/vllm-ascend-test/examples# [ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n/usr/local/python3.10.17/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 30 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  8.1.RC1\r\n--Pytorch 版本:2.5.1\r\n--Python 版本 (e.g., Python 3.7.5):3.10.17\r\n--操作系统版本 (e.g., Ubuntu 18.04):Ubuntu 22.04\r\n\r\n三、测试步骤：\r\n执行代码：\r\nlinear_param = torch_atb.LinearParam()\r\nlinear_param.has_bias = False\r\nlinear_param.out_data_type = torch_atb.AclDataType.ACL_BF16\r\nlinear = torch_atb.Operation(linear_param)\r\nresult = linear.forward([x, layer.weight, layer.deq_scale])[0]\r\nreturn result\r\n\r\n\r\n四、日志信息:\r\nSegmentation fault (core dumped)\r\nroot@6f3a09c20be0:/dfs/home/liujing/aaa/vllm-ascend-test/examples# [ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!\r\n/usr/local/python3.10.17/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 30 leaked semaphore objects to clean up at shutdown\r\n  warnings.warn('resource_tracker: There appear to be %d '\r\nplog为空",
        "url": "https://gitee.com/ascend/ascend-transformer-boost/issues/IC7C2N",
        "clean_data": "模型推理中使用Torch ATB Linear报错：出现Segmentation fault和多个 main process disappeared 子进程错误，同时伴随信号量泄露警告。核心问题在于调用Operation forward方法时导致进程异常。",
        "created_at": "2025-05-13T10:45:44+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-13T10:45:44+08:00"
    },
    {
        "id": 28,
        "source_id": "19936482",
        "title": "版权信息更新到2025",
        "body": "\r\n\r\n\r\n\r\n![输入图片说明](https://foruda.gitee.com/images/1742546574827601533/4a1875dd_15112809.png \"屏幕截图\")",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBVB36",
        "clean_data": "更新许可证文件版权年份至2025：定位并修改 license cann arm linux eva xml 中的年份字段为2025。  并非所有文件都需更新年份，但涉及以下关键场景时需要检查： 1    新安装环境  ：若安装包路径包含2024年份 如  home  userdriversdk liccann arm linux lic2024 CC BCL HA     ，需要更新对应许可证文件的  标签 2    临时授权重命名  ：修改临时许可证文件名后 如 licwhatever ko2024 CC BCL HA     ，需同步更新年份信息以匹配系统时间校验 3    多版本共存  ：同一测试环境中保留旧版本授权文件时，需更新所有处于使用状态的许可证文件  保留原有格式时请务必：   保持XML结构完整性 勿手动修改  值    确保SHA256哈希校验正常   使用系统自带编辑器执行修改操作",
        "created_at": "2025-03-21T16:42:56+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-21T16:42:56+08:00"
    },
    {
        "id": 85,
        "source_id": "20619828",
        "title": "修改aclnn注释",
        "body": "一、问题现象（附报错日志上下文）：\r\naclnn函数注释不规范",
        "url": "https://gitee.com/ascend/canndev/issues/IC9YD0",
        "clean_data": "问题描述  ：请求规范ACLNN函数注释格式，不符合社区文档标准。     关键需求  ：提出对ACLNN函数注释的修改建议，如格式、内容或风格的优化要求。",
        "created_at": "2025-05-23T10:15:04+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T15:39:29+08:00"
    },
    {
        "id": 52,
        "source_id": "20397431",
        "title": "CVE-2020-5555",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2020-5555](https://nvd.nist.gov/vuln/detail/CVE-2020-5555)\n漏洞归属组件：mypy\n漏洞归属的版本：1.9.0\nCVSS V3分值：\n&emsp;BaseScore: 7.3 High\n&emsp;Vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:L\n\n漏洞简述：\nFastCGI fcgi2 (aka fcgi) 2.x through 2.4.4 has an integer overflow (and resultant heap-based buffer overflow) via crafted nameLen or valueLen values in data to the IPC socket. This occurs in ReadParams in fcgiapp.c.\n\n漏洞公开时间：2020-01-10 20:15:25\n漏洞创建时间：2025-04-30 15:40:00\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2020-5555\n",
        "url": "https://gitee.com/ascend/pytorch_dsv3/issues/IC56RB",
        "clean_data": "CVE 2020 5555  mypy 1 9 0组件整数溢出漏洞 CVSS 7 3 ，影响FastCGI fcgi2 2 x至2 4 4版本。漏洞存在于fcgiapp c的ReadParams函数，通过nameLen valueLen参数触发堆栈溢出。公开时间2020 01 10，详情参考 NVD链接  https   nvd nist gov vuln detail CVE 2020 5555 。",
        "created_at": "2025-04-30T15:40:00+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-30T15:40:00+08:00"
    },
    {
        "id": 152,
        "source_id": "0205184470621344055",
        "title": "简化版Aclnn样例编写",
        "body": "<div class=\"cke-article\">教您怎么编写简化版Aclnn样例</div>",
        "url": "https://www.hiascend.com/forum/thread-0205184470621344055-1-1.html",
        "clean_data": "简化版Aclnn样例编写需包含核心算子接口，去除冗余依赖库，保留必要逻辑结构以便测试验证。",
        "created_at": "2025-06-05T01:50:21+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T02:01:12+08:00"
    },
    {
        "id": 12,
        "source_id": "19208994",
        "title": "【Codegen】Codegen时需要对变量名做无害化处理",
        "body": "一、问题现象（附报错日志上下文）：\n如果变量名字中有.，例如auto xxx.xxx = 1;编译会报错\n\n二、软件版本:\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \n--Tensorflow/Pytorch/MindSpore 版本:\n--Python 版本 (e.g., Python 3.7.5):\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\n--操作系统版本 (e.g., Ubuntu 18.04):\n\n三、测试步骤：\nxxxx\n\n\n四、日志信息:\nxxxx\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\n\n日志提供方式:\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\n\n获取方法请参考wiki：\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFPR6",
        "clean_data": "Codegen编译错误：变量名含 xxx xxx 语法需改为 xxx xxx 等合法命名格式以避免编译报错。",
        "created_at": "2025-01-05T10:22:18+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-05T10:23:49+08:00"
    },
    {
        "id": 127,
        "source_id": "0226183977591658038",
        "title": "float乘法问题",
        "body": "<div class=\"cke-article\"><p>atlas 300v pro,查看cann算子清单中有mul，支持float输入，请问这里的乘法运算是否有精度问题，因为提供的nn算子接口aclnnMatmul，不支持float，会转成float16，</p>  <p>cann算子是否也是会转成float16运算</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0226183977591658038-1-1.html",
        "clean_data": "标题：ATLAS 300V Pro CANN乘法算子float精度疑问 问题：确认CANN mul算子在float输入时是否隐式转换为float16计算。已知aclnnMatmul接口会强制float转float16，需明确通用mul算子对float输入的处理方式是否相同。",
        "created_at": "2025-05-30T08:53:12+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T02:31:33+08:00"
    },
    {
        "id": 10,
        "source_id": "19201744",
        "title": "【Lowering】Lowering完成，删除孤立节点报错，同名节点第二次删除报错",
        "body": "一、问题现象（附报错日志上下文）：\r\nxxxx\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFK5S",
        "clean_data": "问题标题：模型Lowering后删除孤立节点及同名节点二次删除时报错  问题描述：在模型Lowering处理完成后，存在以下两种节点删除异常： 1  独立节点删除时触发报错 2  同名节点在首次删除成功后，第二次删除操作再次报错  关键点：   问题发生在模型图转换阶段后续的节点清理过程   约束涉及孤立节点和同名节点两种特殊情形   存在重复报错状态 同名节点二次操作仍报错",
        "created_at": "2025-01-03T18:09:16+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-03T18:09:16+08:00"
    },
    {
        "id": 20,
        "source_id": "19388648",
        "title": "[Bug-Report|缺陷反馈]: DTS2025010903292 华为云环境40节点场景网络拉起失败",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\n华为云环境40节点场景网络拉起失败\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\n910A3超节点\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n华为云环境40节点拉起整网\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\n拉起成功\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\n[图片上传中…(image-mRscJ2dBbAgx27juzaxl)]\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-hccl-dev/issues/IBJKDK",
        "clean_data": "标题： Bug Report   DTS2025010903292 华为云40节点整网拉起失败  问题描述：华为云910A3超节点环境下，40节点整网拉起时网络未能成功启动。相关日志截图显示未完成上传。",
        "created_at": "2025-01-24T00:31:31+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-24T00:32:06+08:00"
    },
    {
        "id": 95,
        "source_id": "20676525",
        "title": "补充获取硬件信息的util函数供用户使用",
        "body": "当前代码`ascend/backend/driver.py`中有比如`get_device_properties, get_arch, get_aicore_num`等函数，需要继续扩充，并补充到说明文档[Python API](https://gitee.com/ascend/triton-ascend/blob/master/docs/Python_API.md)中。",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICB63X",
        "clean_data": "Need to expand hardware info utility functions in  ascend backend driver py   e g   new device property query functions  and update the Python API docs at  Python API md  https   gitee com ascend triton ascend blob master docs Python API md  accordingly",
        "created_at": "2025-05-28T16:03:35+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-28T16:04:49+08:00"
    },
    {
        "id": 44,
        "source_id": "20328861",
        "title": "多余的局部变量dims",
        "body": "多余的局部变量dims\r\n\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IC3PUL",
        "clean_data": "存在未使用的局部变量dims，需排查其冗余或残留代码并删除。",
        "created_at": "2025-04-24T17:16:35+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-24T17:16:35+08:00"
    },
    {
        "id": 582,
        "source_id": "20784000",
        "title": "310P虚拟化单卡多芯片同时运行推理失败",
        "body": "一、问题现象（附报错日志上下文）：\r\n(310P3)我们这边把推理卡的两个模组分别绑在不同的虚拟机里，里面分别前后运行同样的程序，但是后运行的程序到下图显示的这部分就会报错，这个可能是什么原因呀？\r\n\r\n两个模组单独运行都是正常的。同时运行就会同时卡死，卡死后，npu-smi info还扫不到npu设备，重启设备才能恢复\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n7.0.RC1.3\r\n\r\n三、测试步骤：\r\n\r\n代码涉密不方便公开。\r\n\r\n四、日志信息:\r\n![输入图片说明](https://foruda.gitee.com/images/1749384890471181068/7ace2c06_5745011.png \"屏幕截图\")\r\n![输入图片说明](https://foruda.gitee.com/images/1749384900860166820/b499fa6f_5745011.png \"屏幕截图\")    \r\n![输入图片说明](https://foruda.gitee.com/images/1749384907969886837/c0b69552_5745011.png \"屏幕截图\")\r\n![输入图片说明](https://foruda.gitee.com/images/1749384917122958379/9a46f58a_5745011.png \"屏幕截图\")\r\n",
        "url": "https://gitee.com/ascend/samples/issues/ICDH1C",
        "clean_data": "标题：310P虚拟化单卡多芯片同时运行推理失败  现象：310P单卡双芯片推理卡组，分别部署于两个虚拟机并行推理时，后续程序运行到特定阶段会报错，设备会持续卡死且无法通过npu smi检测到NPU，需重启设备恢复。单一虚拟机运行相同程序不异常。",
        "created_at": "2025-06-08T20:19:38+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-10T14:55:56+08:00"
    },
    {
        "id": 38,
        "source_id": "20167210",
        "title": "BatchNormV3,LayerNormV4,SoftmaxV2算子",
        "body": "BatchNormV3,LayerNormV4,SoftmaxV2算子",
        "url": "https://gitee.com/ascend/canndev/issues/IC094A",
        "clean_data": "Ascend CANN支持BatchNormV3、LayerNormV4、SoftmaxV2算子的使能与模型转换吗？   注：该问题未提供具体异常现象或使用场景，根据约束规则直接返回关联标题内容的标准化信息查询",
        "created_at": "2025-04-11T10:15:57+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-11T10:15:57+08:00"
    },
    {
        "id": 136,
        "source_id": "02101178804967429131",
        "title": "ACL,pyACL推理结果后续数据处理",
        "body": "<div class=\"cke-article\"><p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">pyacl推理结果后续处理比acl麻烦，因为pyacl使用python开发，而acl使用c++来开发，acl可以直接操作内存指针，所以在推理结束后可以直接利用指针获取数据，但是pyacl不行，需要做的事情也会比较多，下面我们来看看因该如何操作，才能得到最后的结果。</p>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;position: relative;text-transform: none;white-space: normal;word-spacing: 0.0px;\">acl</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><strong>1.</strong> 首先我们假设已经有了输出数据集aclmdlDataset *inferenceOutput（在推理过程中就已经创建好的），在此基础上，我们获取输出buffer</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">aclDataBuffer* dataBuffer = aclmdlGetDatasetBuffer(inferenceOutput, 0);//以第0个输出作为例子\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><strong>2.</strong> 接下来获取输出的大小和内存指针</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">void* dataBufferDev = aclGetDataBufferAddr(dataBuffer);\nsize_t bufferSize = aclGetDataBufferSizeV2(dataBuffer);\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><strong>3.</strong> 最后一步将数据从device侧拷贝到host侧，如下</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">void* data = nullptr;\naclrtMemcpy(data, bufferSize, dataBufferDev, bufferSize, ACL_MEMCPY_DEVICE_TO_HOST);\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">接下来看看pyacl该如何操作</p>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;position: relative;text-transform: none;white-space: normal;word-spacing: 0.0px;\">pyacl</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><strong>1.</strong> 首先我们需要根据模型的输出创建0的numpy数组。形状和大小，还有数据类型需要根据每个输出来定。我们要用到<br> get_output_dims来获取每个输出的数组维度，</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">dims = acl.mdl.get_output_dims(model_desc, i)、\nshape = tuple(dims[0]['dims'])\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">用到get_output_data_type来获取数组的数据类型，</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">datatype = acl.mdl.get_output_data_type(model_desc, i)\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">另外，还要用到get_output_size_by_index获取数组的大小，</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">size = acl.mdl.get_output_size_by_index(model_desc, i)\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><strong>2.</strong> 接下来我们按照这三个数据创建numpy数组，他的形状就是上述的shape,数据类型就是datatype,那么我们需要按照以下方式创建数组</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">\ndims = acl.mdl.get_output_dims(model_desc, i)\nshape = tuple(dims[0]['dims'])\ndatatype = acl.mdl.get_output_data_type(model_desc, i)\nsize = acl.mdl.get_output_size_by_index(model_desc, i)\nif datatype == const.ACL_FLOAT:\n    np_type = np.float32\n    output_tensor = np.zeros(\n        size // 4, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_DOUBLE:\n    np_type = np.float64\n    output_tensor = np.zeros(\n        size // 8, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_INT64:\n    np_type = np.int64\n    output_tensor = np.zeros(\n        size // 8, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_UINT64:\n    np_type = np.uint64\n    output_tensor = np.zeros(\n        size // 8, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_INT32:\n    np_type = np.int32\n    output_tensor = np.zeros(\n        size // 4, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_UINT32:\n    np_type = np.uint32\n    output_tensor = np.zeros(\n        size // 4, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_FLOAT16:\n    np_type = np.float16\n    output_tensor = np.zeros(\n        size // 2, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_INT16:\n    np_type = np.int16\n    output_tensor = np.zeros(\n        size // 2, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_UINT16:\n    np_type = np.uint16\n    output_tensor = np.zeros(\n        size // 2, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_INT8:\n    np_type = np.int8\n    output_tensor = np.zeros(\n        size, dtype=np_type).reshape(shape)\nelif datatype == const.ACL_BOOL or datatype == const.ACL_UINT8:\n    np_type = np.uint8\n    output_tensor = np.zeros(\n        size, dtype=np_type).reshape(shape)\nelse:\n    print(&quot;Unspport model output datatype &quot;, datatype)\n    return None\n\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">这里出现size // 4，size // 8等是因为不同的数据类型占用的内存大小不一样，比如float64，每个数占用8个字节，所以把数据平铺开来就是有size // 8的长度。其他类似。然后转换成c语言能使用的数据。</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">out_bytes_data = output_tensor.tobytes()\ntensor_ptr = acl.util.bytes_to_ptr(out_bytes_data)\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><strong>3.</strong> 接下来读取输出数据大小以及内存地址，</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">buf = acl.mdl.get_dataset_buffer(output_dataset, i)\ndata = acl.get_data_buffer_addr(buf)\nsize = int(acl.get_data_buffer_size(buf))\noutput_ptr = tensor_list[i][&quot;ptr&quot;]\noutput_data = tensor_list[i]['tensor']\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><strong>4.</strong> 最后考入将数据拷贝到之前创建的数组中，并读取结果，output_data</p>  <pre style=\"background-color: rgb(246,248,250);box-sizing: border-box;font-size: 14.0px;min-height: 52.0px;overflow: auto;padding: 16.0px;\">\n<code style=\"background: transparent;box-sizing: border-box;display: inline;font-size: 14.0px;font-weight: normal;overflow: visible;padding: 0.0px;white-space: pre;word-break: normal;\">ret = acl.rt.memcpy(output_ptr, data_size, data, size, copy_policy)\noutput_data = np.frombuffer(output_data, dtype=tensor_list[i]['dtype']).reshape(tensor_list[i][&quot;shape&quot;])\n</code></pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(64,72,91);letter-spacing: normal;text-transform: none;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">相比之下，pyacl推理结果后续处理比acl麻烦，区别在于c++可以直接操作指针而python不行。</p></div>",
        "url": "https://www.hiascend.com/forum/thread-02101178804967429131-1-1.html",
        "clean_data": "ACL与pyACL推理结果数据处理差异     ACL通过内存指针直取数据，使用 aclmdlGetDatasetBuffer 获取缓冲区， aclrtMemcpy 完成拷贝。   pyACL需借助numpy数组桥接：   1  获取模型输出参数  get output dims 定义形状， get output data type 识别数据类型， get output size by index 确定大小    2  根据数据类型和尺寸构造numpy数组 如float32需 size  4     3  通过 bytes to ptr 转换内存地址，使用 acl rt memcpy 实现数据拷贝   核心差异源自C  可直接操作指针，Python需依托numpy进行内存映射。",
        "created_at": "2025-03-31T12:02:47+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-31T12:02:47+08:00"
    },
    {
        "id": 583,
        "source_id": "20785174",
        "title": "CVE-2024-4068",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-4068](https://nvd.nist.gov/vuln/detail/CVE-2024-4068)\n漏洞归属组件：braces\n漏洞归属的版本：3.0.2\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe NPM package `braces`, versions prior to 3.0.3, fails to limit the number of characters it can handle, which could lead to Memory Exhaustion. In `lib/parse.js,` if a malicious user sends \"imbalanced braces\" as input, the parsing will enter a loop, which will cause the program to start allocating heap memory without freeing it at any moment of the loop. Eventually, the JavaScript heap limit is reached, and the program will crash.\n\n漏洞公开时间：2024-05-14 23:42:48\n漏洞创建时间：2025-06-09 04:10:06\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-4068\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDHXY",
        "clean_data": "CVE 2024 4068 braces 3 0 2内存耗尽漏洞：处理不平衡花括号输入时进入循环导致堆内存溢出崩溃，需升级3 0 3修复。",
        "created_at": "2025-06-09T04:10:06+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T04:10:07+08:00"
    },
    {
        "id": 88,
        "source_id": "20648950",
        "title": "MakeTensorPtrCanonicalizer 补齐功能：补全需要修改 tl.load/store 的 boundary_check 的功能和用例",
        "body": "",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICAKTY",
        "clean_data": "MakeTensorPtrCanonicalizer功能补全需求：完善Triton代码中tl load store的边界检查 boundary check 逻辑，补充完整实现代码和对应测试用例。",
        "created_at": "2025-05-26T16:02:45+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T16:02:45+08:00"
    },
    {
        "id": 14,
        "source_id": "19209049",
        "title": "【lowering】ascbc直连ascbc场景，下一个ascbc内部的dtype刷错了",
        "body": "一、问题现象（附报错日志上下文）：\nxxxx\n\n二、软件版本:\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \n--Tensorflow/Pytorch/MindSpore 版本:\n--Python 版本 (e.g., Python 3.7.5):\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\n--操作系统版本 (e.g., Ubuntu 18.04):\n\n三、测试步骤：\nxxxx\n\n\n四、日志信息:\nxxxx\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\n\n日志提供方式:\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\n\n获取方法请参考wiki：\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFPSP",
        "clean_data": "Ascend编译直连场景中后续算子的数据类型被错误覆盖",
        "created_at": "2025-01-05T10:38:14+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-05T10:38:25+08:00"
    },
    {
        "id": 18,
        "source_id": "19209148",
        "title": "【Schedule】reduce轴的strides为1，后端要求设置为0，导致impl graph失败",
        "body": "一、问题现象（附报错日志上下文）：\r\nxxxx\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFPVG",
        "clean_data": "问题描述：reduce轴strides设为1时后端要求设为0，导致impl graph失败。",
        "created_at": "2025-01-05T11:05:35+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-05T11:05:35+08:00"
    },
    {
        "id": 22,
        "source_id": "19476457",
        "title": "A2机器编译mem_set算子报错",
        "body": "一、问题现象（附报错日志上下文）：\nA2机器编译memset算子报错：\n路径：canndev-master/ops/built-in/kernel/binary_script\nbash build_binary_single_op.sh MemSet ascend910b ./\n\n二、软件版本:\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \n8.0\n--Tensorflow/Pytorch/MindSpore 版本:\n--Python 版本 (e.g., Python 3.8.19):\n--操作系统版本 (e.g., Ubuntu 18.04):\n\n三、测试步骤：\ncd canndev-master/ops/built-in/kernel/binary_script\nexport HI_PYTHON=python3\nbash build_binary_single_op.sh MemSet ascend910b ./\n\n四、日志信息:\n[ERROR] TBE(2702416,python3):2025-02-11-03:07:01.759.696 [../../../opc_tool/op_compilation.py:338][__single_op_compile] Exception occured, ({'errCode': 'E80003', 'op_name': 'mem_set', 'param_name': 'dtypes', 'para    m_type': \"<class 'int'>\", 'actual_type': 'list'}, \"In op[mem_set], the parameter[dtypes]'s type should be [<class 'int'>], but actually is [list].\").\n  2 [ERROR] TBE(2702416,python3):2025-02-11-03:07:01.761.208 [../../../opc_tool/opc_common.py:231][_log_error] Traceback (most recent call last):\n  3   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/opc_tool/op_compilation.py\", line 330, in __single_op_compile\n  4     json_file_path = single_op_obj.op_compile()\n  5   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/opc_tool/single_op_compile.py\", line 234, in op_compile\n  6     json_file_path = self.__call_op()\n  7   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/opc_tool/single_op_compile.py\", line 145, in __call_op\n  8     op_func(*inputs, *outputs, *new_attrs, self.__op_info.get(OpcOptions.KERNEL_NAME), **kwargs)\n  9 [ERROR] TBE(2702416,python3):2025-02-11-03:07:01.761.267 [../../../opc_tool/opc_common.py:231][_log_error]   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/tbe/common/register/operat    ion_func_mgr.py\", line 214, in wrapper\n 10     return func(*args, **kwargs)\n 11   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/tbe/common/utils/para_check.py\", line 532, in _in_wrapper\n 12     _check_one_op_param(one_args, formal_parameter_list[i][0],\n 13   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/tbe/common/utils/para_check.py\", line 520, in _check_one_op_param\n 14     _check_attr(op_param, param_name, param_type, op_name)\n 15   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/tbe/common/utils/para_check.py\", line 468, in _check_attr\n 16     _check_list_attr(op_param, param_name, param_type, op_name)\n 17 [ERROR] TBE(2702416,python3):2025-02-11-03:07:01.761.316 [../../../opc_tool/opc_common.py:231][_log_error]   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/tbe/common/utils/para_chec    k.py\", line 406, in _check_list_attr\n 18     _check_attr_type(one_attr, param_name, int, \"int\", op_name)\n 19   File \"/home/xxx/ascend0210/ascend-toolkit/8.1.RC1/python/site-packages/tbe/common/utils/para_check.py\", line 380, in _check_attr_type\n 20     raise RuntimeError(\n 21 RuntimeError: ({'errCode': 'E80003', 'op_name': 'mem_set', 'param_name': 'dtypes', 'param_type': \"<class 'int'>\", 'actual_type': 'list'}, \"In op[mem_set], the parameter[dtypes]'s type should be [<class 'int'>], bu    t actually is [list].\")\n 22 [ERROR] TBE(2702416,python3):2025-02-11-03:07:01.761.366 [../../../opc_tool/op_compilation.py:211][record_compile_error_info] Op[MemSet] of index[0] compile failed, kernelName: MemSet_3d50057c0908da5fb558c27054320    2e6_high_performance\n 23 [ERROR] TBE(2702416,python3):2025-02-11-03:07:01.761.544 [../../../opc_tool/opc_common.py:524][opc_log_full] [op_compilation.py:213][record_compile_error_info] reason is:[({'errCode': 'E80003', 'op_name': 'mem_set    ', 'param_name': 'dtypes', 'param_type': \"<class 'int'>\", 'actual_type': 'list'}, \"In op[mem_set], the parameter[dtypes]'s type should be [<class 'int'>], but actually is [list].\")]\n 24 [ERROR] TBE(2702416,python3):2025-02-11-03:07:01.762.034 [../../../opc_tool/opc.py:721][main] Opc tool compile failed.\n\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\n\n日志提供方式:\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\n\n获取方法请参考wiki：\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/canndev/issues/IBLG4P",
        "clean_data": "A2机器编译mem set算子报错     CANN 8 0环境使用 build binary single op sh 编译MemSet算子时，报 dtypes 参数类型错误。系统要求 dtypes 为整数类型  int  ，但实际传入为列表  list  ，导致 E80003 异常 日志关键路径：  tbe common utils para check py  。需检查算子定义中 dtypes 参数的数据类型格式是否符合规范，确保其以整数而非列表形式传递。",
        "created_at": "2025-02-11T11:11:55+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-11T11:14:58+08:00"
    },
    {
        "id": 42,
        "source_id": "20315589",
        "title": "函数名修改",
        "body": "### 该问题是怎么引起的？\r\n`runner/jit_execution/exe_points/guard_cache.cc`\r\n\r\n`AddCompliedCompliedGraph`函数名需修改为`AddCompliedGraph`\r\n\r\n\r\n### 重现步骤\r\n\r\n\r\n\r\n### 报错信息\r\n\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IC3FLX",
        "clean_data": "guard cache cc文件需将函数名AddCompliedCompliedGraph修正为AddCompliedGraph",
        "created_at": "2025-04-23T17:29:09+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T14:52:26+08:00"
    },
    {
        "id": 121,
        "source_id": "0248184388134955061",
        "title": "atc转化的时候有问题",
        "body": "<div class=\"cke-article\">ATC run success, welcome to the next use.  <p>W11001: Op [trans_Cast_9] does not hit the high-priority operator information library, which might result in compromised performance. </p>  <p>W11001: Op [trans_Cast_8] does not hit the high-priority operator information library, which might result in compromised performance. </p>  <p>W11001: Op [trans_Cast_11] does not hit the high-priority operator information library, which might result in compromised performance. </p>  <p>W11001: Op [trans_Cast_10] does not hit the high-priority operator information library, which might result in compromised performance.</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184388134955061-1-1.html",
        "clean_data": "ATC模型转换成功，但出现多个Cast操作符 trans Cast 8 9 10 11 未命中高优先级算子库的警告 W11001 ，需排查模型中相关算子配置或优化策略。确认模型中Cast算子输入输出类型是否符合高优先级库支持范围，或联系社区提供模型细节以进一步定位原因。",
        "created_at": "2025-06-04T02:55:35+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T03:16:52+08:00"
    },
    {
        "id": 97,
        "source_id": "20703157",
        "title": "在算子工程中使用模板库矩阵计算结果不对",
        "body": "一、问题现象（附报错日志上下文）：\n在 msopgen 算子工程中使用模板库，矩阵计算结果不对\n\n```\nextern \"C\" __global__ __aicore__ void test_catlass(GM_ADDR a, GM_ADDR b, GM_ADDR c, GM_ADDR workspace, GM_ADDR tiling) {\n    GET_TILING_DATA(tiling_data, tiling);\n\n    // printf(\"M: %d\\n\", tiling_data.M);\n    // printf(\"N: %d\\n\", tiling_data.N);\n    // printf(\"K: %d\\n\", tiling_data.K);\n\n    GemmCoord problemShape{tiling_data.M, tiling_data.N, tiling_data.K};\n    \n    using LayoutA = layout::RowMajor;\n    using LayoutB = layout::RowMajor;\n    using LayoutC = layout::RowMajor;\n    LayoutA layoutA{tiling_data.M, tiling_data.K};\n    LayoutB layoutB{tiling_data.K, tiling_data.N};\n    LayoutC layoutC{tiling_data.M, tiling_data.N};\n\n\n    using ArchTag = Arch::AtlasA2;\n    using DispatchPolicy = Gemm::MmadAtlasA2Pingpong<true>;\n    using L1TileShape = GemmShape<64, 64, 64>;\n\n    using L0TileShape = GemmShape<64, 64, 64>;\n\n    using AType = Gemm::GemmType<float, LayoutA>;\n    using BType = Gemm::GemmType<float, LayoutB>;\n    using CType = Gemm::GemmType<float, LayoutC>;\n\n    using BlockMmad = Gemm::Block::BlockMmad<DispatchPolicy, L1TileShape, L0TileShape, AType, BType, CType>;\n    using BlockEpilogue = void;\n\n    // Swizzle offset is 3 and direction is 0.\n    using BlockScheduler = typename Gemm::Block::GemmIdentityBlockSwizzle<3, 0>;\n\n    // kernel level\n    using MatmulKernel = Gemm::Kernel::BasicMatmul<BlockMmad, BlockEpilogue, BlockScheduler>;\n\n    MatmulKernel::Params params{problemShape, a, layoutA, b, layoutB, c, layoutC};\n    MatmulKernel matmulKernel;\n    matmulKernel(params);\n}\n```\n\n\n二、软件版本:\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  8.1.RC1\n--Tensorflow/Pytorch/MindSpore 版本:\n--Python 版本 (e.g., Python 3.7.5):  3.10.17\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\n--操作系统版本 (e.g., Ubuntu 18.04):  Ubuntu 22.04.5 LTS\n\n三、测试步骤：\n1. 创建算子工程\n\n```\n[\n    {\n        \"op\": \"TestCatlass\",\n        \n        \"input_desc\": [\n            {\n                \"name\": \"a\",\n                \"param_type\": \"required\",\n                \"format\": [\n                    \"ND\"\n                ],\n                \"type\": [\n                    \"float\"\n                ]\n            },\n            {\n                \"name\": \"b\",\n                \"param_type\": \"required\",\n                \"format\": [\n                    \"ND\"\n                ],\n                \"type\": [\n                    \"float\"\n                ]\n            }\n        ],\n        \"output_desc\": [\n            {\n                \"name\": \"c\",\n                \"param_type\": \"required\",\n                \"format\": [\n                    \"ND\"\n                ],\n                \"type\": [\n                    \"float\"\n                ]\n            }\n        ]\n    }\n]\n\n```\n\n2. host 侧代码\n\n```\n\n#include \"test_catlass_tiling.h\"\n#include \"register/op_def_registry.h\"\n\n\nnamespace optiling {\nstatic ge::graphStatus TilingFunc(gert::TilingContext* context)\n{\n\n  TestCatlassTilingData tiling;\n  const gert::StorageShape* a_shape = context->GetInputShape(0);\n  const gert::StorageShape* b_shape = context->GetInputShape(1);\n    uint32_t M = a_shape->GetStorageShape().GetDim(0);\n    uint32_t K = a_shape->GetStorageShape().GetDim(1);\n    uint32_t N = b_shape->GetStorageShape().GetDim(1);\n\n  tiling.set_M(M);\n  tiling.set_K(K);\n  tiling.set_N(N);\n  context->SetBlockDim(1);\n  tiling.SaveToBuffer(context->GetRawTilingData()->GetData(), context->GetRawTilingData()->GetCapacity());\n  context->GetRawTilingData()->SetDataSize(tiling.GetDataSize());\n\n  return ge::GRAPH_SUCCESS;\n}\n}\n\n\nnamespace ge {\nstatic ge::graphStatus InferShape(gert::InferShapeContext* context)\n{\n    const gert::Shape* x1_shape = context->GetInputShape(0);\n    gert::Shape* y_shape = context->GetOutputShape(0);\n    *y_shape = *x1_shape;\n    return GRAPH_SUCCESS;\n}\nstatic ge::graphStatus InferDataType(gert::InferDataTypeContext *context)\n{\nconst auto inputDataType = context->GetInputDataType(0);\ncontext->SetOutputDataType(0, inputDataType);\nreturn ge::GRAPH_SUCCESS;\n}\n}\n\n\nnamespace ops {\nclass TestCatlass : public OpDef {\npublic:\n    explicit TestCatlass(const char* name) : OpDef(name)\n    {\n        this->Input(\"a\")\n            .ParamType(REQUIRED)\n            .DataType({ge::DT_FLOAT})\n            .Format({ge::FORMAT_ND})\n            .UnknownShapeFormat({ge::FORMAT_ND});\n        this->Input(\"b\")\n            .ParamType(REQUIRED)\n            .DataType({ge::DT_FLOAT})\n            .Format({ge::FORMAT_ND})\n            .UnknownShapeFormat({ge::FORMAT_ND});\n        this->Output(\"c\")\n            .ParamType(REQUIRED)\n            .DataType({ge::DT_FLOAT})\n            .Format({ge::FORMAT_ND})\n            .UnknownShapeFormat({ge::FORMAT_ND});\n\n        this->SetInferShape(ge::InferShape).SetInferDataType(ge::InferDataType);\n\n        this->AICore()\n            .SetTiling(optiling::TilingFunc);\n        this->AICore().AddConfig(\"ascend910b\");\n\n    }\n};\n\nOP_ADD(TestCatlass);\n}\n```\n\n\n3. kernel 侧代码\n\n```\n#include \"kernel_operator.h\"\n\n#include \"catlass/catlass.hpp\"\n#include \"catlass/arch/arch.hpp\"\n#include \"catlass/gemm/block/block_mmad.hpp\"\n#include \"catlass/gemm/block/block_swizzle.hpp\"\n#include \"catlass/gemm/dispatch_policy.hpp\"\n#include \"catlass/gemm/kernel/basic_matmul.hpp\"\n#include \"catlass/gemm/gemm_type.hpp\"\n#include \"catlass/layout/layout.hpp\"\n\n#include \"catlass/status.hpp\"\n\nusing namespace AscendC;\nusing namespace Catlass;\n\nextern \"C\" __global__ __aicore__ void test_catlass(GM_ADDR a, GM_ADDR b, GM_ADDR c, GM_ADDR workspace, GM_ADDR tiling) {\n    GET_TILING_DATA(tiling_data, tiling);\n\n    // printf(\"M: %d\\n\", tiling_data.M);\n    // printf(\"N: %d\\n\", tiling_data.N);\n    // printf(\"K: %d\\n\", tiling_data.K);\n\n    GemmCoord problemShape{tiling_data.M, tiling_data.N, tiling_data.K};\n    \n    using LayoutA = layout::RowMajor;\n    using LayoutB = layout::RowMajor;\n    using LayoutC = layout::RowMajor;\n    LayoutA layoutA{tiling_data.M, tiling_data.K};\n    LayoutB layoutB{tiling_data.K, tiling_data.N};\n    LayoutC layoutC{tiling_data.M, tiling_data.N};\n\n\n    using ArchTag = Arch::AtlasA2;\n    using DispatchPolicy = Gemm::MmadAtlasA2Pingpong<true>;\n    using L1TileShape = GemmShape<64, 64, 64>;\n\n    using L0TileShape = GemmShape<64, 64, 64>;\n\n    using AType = Gemm::GemmType<float, LayoutA>;\n    using BType = Gemm::GemmType<float, LayoutB>;\n    using CType = Gemm::GemmType<float, LayoutC>;\n\n    using BlockMmad = Gemm::Block::BlockMmad<DispatchPolicy, L1TileShape, L0TileShape, AType, BType, CType>;\n    using BlockEpilogue = void;\n\n    // Swizzle offset is 3 and direction is 0.\n    using BlockScheduler = typename Gemm::Block::GemmIdentityBlockSwizzle<3, 0>;\n\n    // kernel level\n    using MatmulKernel = Gemm::Kernel::BasicMatmul<BlockMmad, BlockEpilogue, BlockScheduler>;\n\n    MatmulKernel::Params params{problemShape, a, layoutA, b, layoutB, c, layoutC};\n    MatmulKernel matmulKernel;\n    matmulKernel(params);\n}\n```\n\n4. 通过设置 CPLUS_INCLUDE_PATH=/path/to/catlass 编译安装算子并测试\n\n\n\n四、日志信息:\nxxxx\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\n\n日志提供方式:\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\n\n获取方法请参考wiki：\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/catlass/issues/ICBQNP",
        "clean_data": "标题：算子工程中CatLass模板库矩阵计算结果异常       问题简述  ：在CANN 8 1 RC1编译环境下，基于CatLass模板库开发的算子工程  test catlass c  矩阵乘法计算结果错误，可能由于Tile参数配置 GemmShape BlockSwizzle 与硬件架构AtlasA2不匹配，或Host侧TilingFunc未正确绑定输入维度 M K N 。需检查模板参数合理性及内存布局 RowMajor 是否与输入数据一致。",
        "created_at": "2025-05-30T17:25:39+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-06T10:04:49+08:00"
    },
    {
        "id": 105,
        "source_id": "20727641",
        "title": "去除调试代码",
        "body": "一、问题现象（附报错日志上下文）：\r\nxxxx\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICC9JT",
        "clean_data": "去除调试代码：问题涉及具体环境配置，需提供明确版本信息及测试日志。开发者可通过MindStudio或Wiki指引收集UT ST测试、单算子集成测试等日志，并上传至论坛获取支持。",
        "created_at": "2025-06-03T17:35:15+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T17:35:15+08:00"
    },
    {
        "id": 99,
        "source_id": "20714491",
        "title": "CVE-2025-48387",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-48387](https://nvd.nist.gov/vuln/detail/CVE-2025-48387)\n漏洞归属组件：tar-fs\n漏洞归属的版本：3.0.6\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nA vulnerability, which was classified as critical, has been found in mafintosh tar-fs up to 1.16.4/2.1.2/3.0.8. This issue affects an unknown functionality. Upgrading to version 1.16.5, 2.1.3 or 3.0.9 eliminates this vulnerability.\n\n漏洞公开时间：2025-06-03 03:59:25\n漏洞创建时间：2025-06-03 04:40:44\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-48387\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICBZEJ",
        "clean_data": "CVE 2025 48387 漏洞影响 mafintosh tar fs 版本 3 0 8，通过升级至 3 0 9 可修复。",
        "created_at": "2025-06-03T04:40:44+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T04:40:44+08:00"
    },
    {
        "id": 100,
        "source_id": "20721564",
        "title": "未使用代码应当删除。",
        "body": "一、问题现象（附报错日志上下文）：\r\nxxxx\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICC4V0",
        "clean_data": "未使用代码应当删除。",
        "created_at": "2025-06-03T13:56:33+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T17:29:43+08:00"
    },
    {
        "id": 140,
        "source_id": "0292176091068234172",
        "title": "Hisi3519使用 atc时会有mapper_error.log",
        "body": "<div class=\"cke-article\">Hisi3519使用 atc时 WARN[CheckLtpParam][1593] Op[encoder_conf] Data Scale[4.125049] Offset[31.000000] Min[-38.544994] Max[23.272453] Weight[3] Scale[235978272.000000] Min[-5.381851e-07] Max[5.381851e-7] 这种Warning会影响om的效果吗？</div>",
        "url": "https://www.hiascend.com/forum/thread-0292176091068234172-1-1.html",
        "clean_data": "ATC编译Hisi3519产生mapper error日志，核心询问警告信息是否影响OM模型效果。  简要说明：   ATC编译Hisi3519时显示encoder conf操作的量化参数警告，需确认Data Weight的Scale、Offset、Min Max取值是否合理，建议核查量化配置与模型需求匹配性。",
        "created_at": "2025-02-28T02:11:08+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-28T02:11:08+08:00"
    },
    {
        "id": 133,
        "source_id": "0278179647575496043",
        "title": "适配华为Atlas300I卡，模型推理精度达不到；",
        "body": "<div class=\"cke-article\"><div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>尝试过的方案：</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>1、atc转模型时设置fp32、高精度推理。精度依旧不达标；</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>2、服务器重启，再测试 结果推理结果有变化。</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>自研模型，都是常规算子。</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>之前适配过Atlas 300IPro卡，推理精度没问题。之前适配环境是6.0.1，刚开始适配是环境也是6.0.1，因为精度达不到升级到8.0.1</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>-----------------------------------------------------------------------------------</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span><strong>环境：</strong></span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>架构：                              aarch64</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>CPU 运行模式：                      64-bit</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>字节序：                            Little Endian</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>CPU:                                64</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>在线 CPU 列表：                     0-63</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>每个核的线程数：                    1</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>每个座的核数：                      32</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>座：                                2</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>NUMA 节点：                         2</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>厂商 ID：                           HiSilicon</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>BIOS Vendor ID:                     HiSilicon</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>型号：                              0</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>型号名称：                          Kunpeng-920</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>BIOS Model name:                    HUAWEI Kunpeng 920 5220</span></span></span></span></span></span></span></span></span></span></span></span></p> </div> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>-----------------------------------------------------------------------------------</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span><strong>驱动：</strong></span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>npu-smi info</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+--------------------------------------------------------------------------------------------------------+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| npu-smi 24.1.0                                   Version: 24.1.0                                       |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+-------------------------------+-----------------+------------------------------------------------------+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| NPU     Name                  | Health          | Power(W)     Temp(C)           Hugepages-Usage(page) |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| Chip    Device                | Bus-Id          | AICore(%)    Memory-Usage(MB)                        |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+===============================+=================+======================================================+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| 3       310                   | OK              | 12.8         54                0     / 969           |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| 0       0                     | 0000:0A:00.0    | 0            630  / 7759                             |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+-------------------------------+-----------------+------------------------------------------------------+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| 3       310                   | OK              | 12.8         51                0     / 969           |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| 1       1                     | 0000:0B:00.0    | 0            631  / 7759                             |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+-------------------------------+-----------------+------------------------------------------------------+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| 3       310                   | OK              | 12.8         52                0     / 969           |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| 2       2                     | 0000:0C:00.0    | 0            649  / 7759                             |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+-------------------------------+-----------------+------------------------------------------------------+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| 3       310                   | OK              | 12.8         49                0     / 969           |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| 3       3                     | 0000:0D:00.0    | 0            628  / 7759                             |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+===============================+=================+======================================================+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+-------------------------------+-----------------+------------------------------------------------------+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| NPU     Chip                  | Process id      | Process name             | Process memory(MB)        |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+===============================+=================+======================================================+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>| No running processes found in NPU 3                                                                    |</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>+===============================+=================+======================================================+</span></span></span></span></span></span></span></span></span></span></span></span></p> </div> </div>  <div style=\"\"> <p></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span>-----------------------------------------------------------------------------------</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span><strong>昇腾卡转模型工具</strong>：Ascend-cann-toolkit_8.0.1_linux-x86_64.run</span></span></span></span></span></span></span></span></span></span></span></span></p> </div>  <div style=\"\"> <p><span style=\"font-size: 14.0px;\"><span style=\"color: rgb(0,0,0);\"><span><span style=\"font-style: normal;\"><span style=\"\"><span style=\"font-weight: 400;\"><span style=\"white-space: normal;\"><span style=\"background-color: rgb(255,255,255);\"><span><span style=\"\"><span style=\"\"><span><strong>推理</strong>：Ascend-cann-nnrt_8.0.1_linux-aarch64.run</span></span></span></span></span></span></span></span></span></span></span></span></p> </div></div>",
        "url": "https://www.hiascend.com/forum/thread-0278179647575496043-1-1.html",
        "clean_data": "问题描述：   开发者使用8 0 1版本的ATC工具 Ascend cann toolkit 8 0 1 linux x86 64 run 将自研模型 常规算子 转为fp32格式，并在Atlas300I卡上运行推理 Ascend cann nnrt 8 0 1 linux aarch64 run 时精度不达标。重启服务器后推理结果发生波动。此前相同模型在Atlas300IPro卡6 0 1版本下推理精度正常。    关键点：   1  问题仅出现在Atlas300I卡8 0 1版本环境中；   2  ATC转模型设为fp32及高精度模式无效；   3  重启后精度结果不稳定；   4  对比历史环境 ATLAS300IPro   CANN6 0 1 无问题。",
        "created_at": "2025-04-10T06:06:16+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-22T06:22:45+08:00"
    },
    {
        "id": 181,
        "source_id": "0266176882143830052",
        "title": "sad123",
        "body": "<div class=\"cke-article\">  <p># ResNet50图像分类 </p>    <p></p>  <p>图像分类是最基础的计算机视觉应用，属于有监督学习类别，如给定一张图像(猫、狗、飞机、汽车等等)，判断图像所属的类别。本案例将介绍使用ResNet50网络对CIFAR-10数据集进行分类。 </p>    <p>## ResNet网络介绍 </p>    <p>ResNet50网络是2015年由微软实验室的何恺明提出，获得ILSVRC2015图像分类竞赛第一名。在ResNet网络提出之前，传统的卷积神经网络都是将一系列的卷积层和池化层堆叠得到的，但当网络堆叠到一定深度时，就会出现退化问题。下图是在CIFAR-10数据集上使用56层网络与20层网络训练误差和测试误差图，由图中数据可以看出，56层网络比20层网络训练误差和测试误差更大，随着网络的加深，其误差并没有如预想的一样减小。 </p>    <p>![resnet-1](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0/tutorials/application/source_zh_cn/cv/images/resnet_1.png) </p>    <p>ResNet网络提出了残差网络结构(Residual Network)来减轻退化问题，使用ResNet网络可以实现搭建较深的网络结构（突破1000层）。论文中使用ResNet网络在CIFAR-10数据集上的训练误差与测试误差图如下图所示，图中虚线表示训练误差，实线表示测试误差。由图中数据可以看出，ResNet网络层数越深，其训练误差和测试误差越小。 </p>    <p>![resnet-4](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0/tutorials/application/source_zh_cn/cv/images/resnet_4.png) </p>    <p></p>  <p>pip install download </p>    <p>## 设置运行环境 </p>    <p> max_device_memory=&quot;2GB&quot; : 设置设备可用的最大内存为2GB。 </p>    <p> mode=mindspore.GRAPH_MODE : 表示在GRAPH_MODE模式中运行。 </p>    <p> device_target=&quot;Ascend&quot; : 表示待运行的目标设备为Ascend。 </p>    <p> jit_config={&quot;jit_level&quot;:&quot;O2&quot;} : 编译优化级别开启极致性能优化，使用下沉的执行方式。 </p>    <p> scend_config={&quot;precision_mode&quot;:&quot;allow_mix_precision&quot;} : 自动混合精度，自动将部分算子的精度降低到float16或bfloat16。 </p>  <p>import mindspore </p>  <p>mindspore.set_context(device_target=&quot;CPU&quot;, mode=mindspore.GRAPH_MODE) </p>  <p>## 数据集准备与加载 </p>    <p>[CIFAR-10数据集]()共有60000张32*32的彩色图像，分为10个类别，每类有6000张图，数据集一共有50000张训练图片和10000张评估图片。首先，如下示例使用`download`接口下载并解压，目前仅支持解析二进制版本的CIFAR-10文件（CIFAR-10 binary version）。 </p>  <p>from download import download </p>    <p>url = &quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz&quot; </p>    <p>download(url, &quot;./datasets-cifar10-bin&quot;, kind=&quot;tar.gz&quot;, replace=True) </p>  <p>下载后的数据集目录结构如下： </p>    <p>```text </p>  <p>datasets-cifar10-bin/cifar-10-batches-bin </p>  <p>├── batches.meta.text </p>  <p>├── data_batch_1.bin </p>  <p>├── data_batch_2.bin </p>  <p>├── data_batch_3.bin </p>  <p>├── data_batch_4.bin </p>  <p>├── data_batch_5.bin </p>  <p>├── readme.html </p>  <p>└── test_batch.bin </p>    <p>``` </p>    <p>然后，使用`mindspore.dataset.Cifar10Dataset`接口来加载数据集，并进行相关图像增强操作。 </p>  <p>import mindspore.dataset as ds </p>  <p>import mindspore.dataset.vision as vision </p>  <p>import mindspore.dataset.transforms as transforms </p>  <p>from mindspore import dtype as mstype </p>    <p>data_dir = &quot;./datasets-cifar10-bin/cifar-10-batches-bin&quot;  # 数据集根目录 </p>  <p>batch_size = 4  # 批量大小 </p>  <p>image_size = 32  # 训练图像空间大小 </p>  <p>workers = 4 </p>  <p>num_classes = 10  # 分类数量 </p>    <p></p>  <p>def create_dataset_cifar10(dataset_dir, usage, resize, batch_size, workers): </p>    <p>    data_set = ds.Cifar10Dataset(dataset_dir=dataset_dir, </p>  <p>                                 usage=usage, </p>  <p>                                 num_parallel_workers=workers, </p>  <p>                                 num_samples=32, </p>  <p>                                 shuffle=True) </p>    <p>    trans = [] </p>  <p>     </p>  <p>    trans += [ </p>  <p>        vision.Resize(resize), </p>  <p>        vision.Rescale(1.0 / 255.0, 0.0), </p>  <p>        vision.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]), </p>  <p>        vision.HWC2CHW() </p>  <p>    ] </p>    <p>    target_trans = transforms.TypeCast(mstype.int32) </p>    <p>    # 数据映射操作 </p>  <p>    data_set = data_set.map(operations=trans, </p>  <p>                            input_columns='image', </p>  <p>                            num_parallel_workers=workers) </p>    <p>    data_set = data_set.map(operations=target_trans, </p>  <p>                            input_columns='label', </p>  <p>                            num_parallel_workers=workers) </p>    <p>    # 批量操作 </p>  <p>    data_set = data_set.batch(batch_size) </p>    <p>    return data_set </p>    <p></p>  <p># 获取处理后的验证数据集 </p>  <p>dataset_val = create_dataset_cifar10(dataset_dir=data_dir, </p>  <p>                                     usage=&quot;test&quot;, </p>  <p>                                     resize=image_size, </p>  <p>                                     batch_size=batch_size, </p>  <p>                                     workers=workers) </p>  <p>step_size_val = dataset_val.get_dataset_size() </p>  <p>对CIFAR-10验证数据集进行可视化。 </p>  <p>import matplotlib.pyplot as plt </p>  <p>import numpy as np </p>    <p>data_iter = next(dataset_val.create_dict_iterator()) </p>    <p>images = data_iter[&quot;image&quot;].asnumpy() </p>  <p>labels = data_iter[&quot;label&quot;].asnumpy() </p>  <p>print(f&quot;Image shape: {images.shape}, Label shape: {labels.shape}&quot;) </p>    <p># 验证数据集中，前四张图片所对应的标签 </p>  <p>print(f&quot;Labels: {labels[:4]}&quot;) </p>    <p>classes = [] </p>    <p>with open(data_dir + &quot;/batches.meta.txt&quot;, &quot;r&quot;) as f: </p>  <p>    for line in f: </p>  <p>        line = line.rstrip() </p>  <p>        if line: </p>  <p>            classes.append(line) </p>    <p># 验证数据集的前四张图片 </p>  <p>plt.figure() </p>  <p>for i in range(4): </p>  <p>    plt.subplot(2, 2, i + 1) </p>  <p>    image_trans = np.transpose(images[i], (1, 2, 0)) </p>  <p>    mean = np.array([0.4914, 0.4822, 0.4465]) </p>  <p>    std = np.array([0.2023, 0.1994, 0.2010]) </p>  <p>    image_trans = std * image_trans + mean </p>  <p>    image_trans = np.clip(image_trans, 0, 1) </p>  <p>    plt.title(f&quot;-{classes[labels[i]]}&quot;) </p>  <p>    plt.imshow(image_trans) </p>  <p>    plt.axis(&quot;off&quot;) </p>  <p>plt.show() </p>    <p>## 构建网络 </p>    <p>残差网络结构(Residual Network)是ResNet网络的主要亮点，ResNet使用残差网络结构后可有效地减轻退化问题，实现更深的网络结构设计，提高网络的训练精度。本节首先讲述如何构建残差网络结构，然后通过堆叠残差网络来构建ResNet50网络。 </p>    <p>### 构建残差网络结构 </p>    <p>残差网络结构图如下图所示，残差网络由两个分支构成：一个主分支，一个shortcuts（图中弧线表示）。主分支通过堆叠一系列的卷积操作得到，shortcuts从输入直接到输出，主分支输出的特征矩阵$F(x)$加上shortcuts输出的特征矩阵$x$得到$F(x)+x$，通过Relu激活函数后即为残差网络最后的输出。 </p>    <p>![residual](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0/tutorials/application/source_zh_cn/cv/images/resnet_3.png) </p>    <p>残差网络结构主要由两种，一种是Building Block，适用于较浅的ResNet网络，如ResNet18和ResNet34；另一种是Bottleneck，适用于层数较深的ResNet网络，如ResNet50、ResNet101和ResNet152。 </p>    <p>#### Building Block </p>    <p>Building Block结构图如下图所示，主分支有两层卷积网络结构： </p>    <p>+ 主分支第一层网络以输入channel为64为例，首先通过一个$3\\times3$的卷积层，然后通过Batch Normalization层，最后通过Relu激活函数层，输出channel为64； </p>  <p>+ 主分支第二层网络的输入channel为64，首先通过一个$3\\times3$的卷积层，然后通过Batch Normalization层，输出channel为64。 </p>    <p>最后将主分支输出的特征矩阵与shortcuts输出的特征矩阵相加，通过Relu激活函数即为Building Block最后的输出。 </p>    <p>![building-block-5](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0/tutorials/application/source_zh_cn/cv/images/resnet_5.png) </p>    <p>主分支与shortcuts输出的特征矩阵相加时，需要保证主分支与shortcuts输出的特征矩阵shape相同。如果主分支与shortcuts输出的特征矩阵shape不相同，如输出channel是输入channel的一倍时，shortcuts上需要使用数量与输出channel相等，大小为$1\\times1$的卷积核进行卷积操作；若输出的图像较输入图像缩小一倍，则要设置shortcuts中卷积操作中的`stride`为2，主分支第一层卷积操作的`stride`也需设置为2。 </p>    <p>如下代码定义`ResidualBlockBase`类实现Building Block结构。 </p>  <p>from typing import Type, Union, List, Optional </p>  <p>import mindspore.nn as nn </p>  <p>from mindspore.common.initializer import Normal </p>    <p># 初始化卷积层与BatchNorm的参数 </p>  <p>weight_init = Normal(mean=0, sigma=0.02) </p>  <p>gamma_init = Normal(mean=1, sigma=0.02) </p>    <p>class ResidualBlockBase(nn.Cell): </p>  <p>    expansion: int = 1  # 最后一个卷积核数量与第一个卷积核数量相等 </p>    <p>    def __init__(self, in_channel: int, out_channel: int, </p>  <p>                 stride: int = 1, norm: Optional[nn.Cell] = None, </p>  <p>                 down_sample=None):  # 补全参数列表，添加右括号和冒号 </p>  <p>        super(ResidualBlockBase, self).__init__() </p>  <p>        if not norm: </p>  <p>            self.norm = nn.BatchNorm2d(out_channel) </p>  <p>        else: </p>  <p>            self.norm = norm </p>    <p>        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, weight_init=weight_init) </p>  <p>        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, weight_init=weight_init)  # 修正输入通道数 </p>  <p>        self.relu = nn.ReLU() </p>  <p>        self.down_sample = down_sample </p>    <p>    def construct(self, x): </p>  <p>        &quot;&quot;&quot;ResidualBlockBase construct.&quot;&quot;&quot; </p>  <p>        identity = x  # shortcuts分支 </p>    <p>        out = self.conv1(x)  # 主分支第一层：3*3卷积层 </p>  <p>        out = self.norm(out) </p>  <p>        out = self.relu(out) </p>  <p>        out = self.conv2(out)  # 主分支第二层：3*3卷积层 </p>  <p>        out = self.norm(out) </p>    <p>        if self.down_sample is not None: </p>  <p>            identity = self.down_sample(x) </p>  <p>        out += identity  # 输出为主分支与shortcuts之和 </p>  <p>        out = self.relu(out) </p>    <p>        return out </p>  <p>#### Bottleneck </p>    <p>Bottleneck结构图如下图所示，在输入相同的情况下Bottleneck结构相对Building Block结构的参数数量更少，更适合层数较深的网络，ResNet50使用的残差结构就是Bottleneck。该结构的主分支有三层卷积结构，分别为$1\\times1$的卷积层、$3\\times3$卷积层和$1\\times1$的卷积层，其中$1\\times1$的卷积层分别起降维和升维的作用。 </p>    <p>+ 主分支第一层网络以输入channel为256为例，首先通过数量为64，大小为$1\\times1$的卷积核进行降维，然后通过Batch Normalization层，最后通过Relu激活函数层，其输出channel为64； </p>  <p>+ 主分支第二层网络通过数量为64，大小为$3\\times3$的卷积核提取特征，然后通过Batch Normalization层，最后通过Relu激活函数层，其输出channel为64； </p>  <p>+ 主分支第三层通过数量为256，大小$1\\times1$的卷积核进行升维，然后通过Batch Normalization层，其输出channel为256。 </p>    <p>最后将主分支输出的特征矩阵与shortcuts输出的特征矩阵相加，通过Relu激活函数即为Bottleneck最后的输出。 </p>    <p>![building-block-6](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0/tutorials/application/source_zh_cn/cv/images/resnet_6.png) </p>    <p>主分支与shortcuts输出的特征矩阵相加时，需要保证主分支与shortcuts输出的特征矩阵shape相同。如果主分支与shortcuts输出的特征矩阵shape不相同，如输出channel是输入channel的一倍时，shortcuts上需要使用数量与输出channel相等，大小为$1\\times1$的卷积核进行卷积操作；若输出的图像较输入图像缩小一倍，则要设置shortcuts中卷积操作中的`stride`为2，主分支第二层卷积操作的`stride`也需设置为2。 </p>    <p>如下代码定义`ResidualBlock`类实现Bottleneck结构。 </p>  <p>class ResidualBlock(nn.Cell): </p>  <p>    expansion = 4  # 最后一个卷积核的数量是第一个卷积核数量的4倍 </p>    <p>    def __init__(self, in_channel: int, out_channel: int, </p>  <p>                 stride: int = 1, down_sample: Optional[nn.Cell] = None) -&gt; None: </p>  <p>        super(ResidualBlock, self).__init__() </p>    <p>        self.conv1 = nn.Conv2d(in_channel, out_channel,kernel_size=1, weight_init=weight_init) </p>  <p>        self.norm1 = nn.BatchNorm2d(out_channel) </p>  <p>        self.conv2 = nn.Conv2d(out_channel, out_channel,kernel_size=3, stride=stride,weight_init=weight_init) </p>  <p>        self.norm2 = nn.BatchNorm2d(out_channel) </p>  <p>        self.conv3 = nn.Conv2d(out_channel, out_channel * self.expansion,kernel_size=1, weight_init=weight_init) </p>  <p>        self.norm3 = nn.BatchNorm2d(out_channel * self.expansion) </p>    <p>        self.relu = nn.ReLU() </p>  <p>        self.down_sample = down_sample </p>    <p>    def construct(self, x): </p>    <p>        identity = x  # shortscuts分支 </p>    <p>        out = self.conv1(x)  # 主分支第一层：1*1卷积层 </p>  <p>        out = self.norm1(out) </p>  <p>        out = self.relu(out) </p>  <p>        out = self.conv2(out)  # 主分支第二层：3*3卷积层 </p>  <p>        out = self.norm2(out) </p>  <p>        out = self.relu(out) </p>  <p>        out = self.conv3(out)  # 主分支第三层：1*1卷积层 </p>  <p>        out = self.norm3(out) </p>    <p>        if self.down_sample is not None: </p>  <p>            identity = self.down_sample(x) </p>    <p>        out += identity  # 输出为主分支与shortcuts之和 </p>  <p>        out = self.relu(out) </p>    <p>        return out </p>  <p>#### 构建ResNet50网络 </p>    <p>ResNet网络层结构如下图所示，以输入彩色图像$224\\times224$为例，首先通过数量64，卷积核大小为$7\\times7$，stride为2的卷积层conv1，该层输出图片大小为$112\\times112$，输出channel为64；然后通过一个$3\\times3$的最大下采样池化层，该层输出图片大小为$56\\times56$，输出channel为64；再堆叠4个残差网络块（conv2_x、conv3_x、conv4_x和conv5_x），此时输出图片大小为$7\\times7$，输出channel为2048；最后通过一个平均池化层、全连接层和softmax，得到分类概率。 </p>    <p>![resnet-layer](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0/tutorials/application/source_zh_cn/cv/images/resnet_2.png) </p>    <p>对于每个残差网络块，以ResNet50网络中的conv2_x为例，其由3个Bottleneck结构堆叠而成，每个Bottleneck输入的channel为64，输出channel为256。 </p>    <p>如下示例定义`make_layer`实现残差块的构建，其参数如下所示: </p>    <p>+ `last_out_channel`：上一个残差网络输出的通道数。 </p>  <p>+ `block`：残差网络的类别，分别为`ResidualBlockBase`和`ResidualBlock`。 </p>  <p>+ `channel`：残差网络块1*1卷积层的输出通道数 </p>  <p>+ `block_nums`：残差网络块堆叠的个数。 </p>  <p>+ `stride`：卷积移动的步幅。 </p>  <p>def make_layer(last_out_channel, block: Type[Union[ResidualBlockBase, ResidualBlock]], </p>  <p>               channel: int, block_nums: int, stride: int = 1): </p>  <p>    down_sample = None  # shortcuts分支 </p>    <p>    if stride != 1 or last_out_channel != channel * block.expansion: </p>    <p>        down_sample = nn.SequentialCell([ </p>  <p>            nn.Conv2d(last_out_channel, channel * block.expansion,kernel_size=1, stride=stride, weight_init=weight_init), </p>  <p>            nn.BatchNorm2d(channel * block.expansion, gamma_init=gamma_init) </p>  <p>        ]) </p>    <p>    layers = [] </p>  <p>    layers.append(block(last_out_channel, channel, stride=stride, down_sample=down_sample)) </p>    <p>    in_channel = channel * block.expansion </p>  <p>    # 堆叠残差网络 </p>  <p>    for _ in range(1, block_nums): </p>    <p>        layers.append(block(in_channel, channel)) </p>    <p>    return nn.SequentialCell(layers) </p>  <p>ResNet50网络共有5个卷积结构，一个平均池化层，一个全连接层，以CIFAR-10数据集为例： </p>    <p>+ **conv1**：输入图片大小为$32\\times32$，输入channel为3。首先经过一个卷积核数量为64，卷积核大小为$7\\times7$，stride为2的卷积层；然后通过一个Batch Normalization层；最后通过ReLu激活函数。该层输出feature map大小为$16\\times16$，输出channel为64。 </p>  <p>+ **conv2_x**：输入feature map大小为$16\\times16$，输入channel为64。首先经过一个卷积核大小为$3\\times3$，stride为2的最大下采样池化操作；然后堆叠3个$[1\\times1，64；3\\times3，64；1\\times1，256]$结构的Bottleneck。该层输出feature map大小为$8\\times8$，输出channel为256。 </p>  <p>+ **conv3_x**：输入feature map大小为$8\\times8$，输入channel为256。该层堆叠4个[1×1，128；3×3，128；1×1，512]结构的Bottleneck。该层输出feature map大小为$4\\times4$，输出channel为512。 </p>  <p>+ **conv4_x**：输入feature map大小为$4\\times4$，输入channel为512。该层堆叠6个[1×1，256；3×3，256；1×1，1024]结构的Bottleneck。该层输出feature map大小为$2\\times2$，输出channel为1024。 </p>  <p>+ **conv5_x**：输入feature map大小为$2\\times2$，输入channel为1024。该层堆叠3个[1×1，512；3×3，512；1×1，2048]结构的Bottleneck。该层输出feature map大小为$1\\times1$，输出channel为2048。 </p>  <p>+ **average pool &amp; fc**：输入channel为2048，输出channel为分类的类别数。 </p>    <p>如下示例代码实现ResNet50模型的构建，通过用调函数`resnet50`即可构建ResNet50模型，函数`resnet50`参数如下： </p>    <p>+ `num_classes`：分类的类别数，默认类别数为1000。 </p>  <p>+ `pretrained`：下载对应的训练模型，并加载预训练模型中的参数到网络中。 </p>  <p>from mindspore import load_checkpoint, load_param_into_net </p>    <p></p>  <p>class ResNet(nn.Cell): </p>  <p>    def __init__(self, block: Type[Union[ResidualBlockBase, ResidualBlock]], </p>  <p>                 layer_nums: List[int], num_classes: int, input_channel: int) -&gt; None: </p>  <p>        super(ResNet, self).__init__() </p>    <p>        self.relu = nn.ReLU() </p>  <p>        # 第一个卷积层，输入channel为3（彩色图像），输出channel为64 </p>  <p>        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, weight_init=weight_init) </p>  <p>        self.norm = nn.BatchNorm2d(64) </p>  <p>        # 最大池化层，缩小图片的尺寸 </p>  <p>        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='same') </p>  <p>        # 各个残差网络结构块定义 </p>  <p>        self.layer1 = make_layer(64, block, 64, layer_nums[0]) </p>  <p>        self.layer2 = make_layer(64 * block.expansion, block, 128, layer_nums[1], stride=2) </p>  <p>        self.layer3 = make_layer(128 * block.expansion, block, 256, layer_nums[2], stride=2) </p>  <p>        self.layer4 = make_layer(256 * block.expansion, block, 512, layer_nums[3], stride=2) </p>  <p>        # 平均池化层 </p>  <p>        self.avg_pool = nn.AvgPool2d() </p>  <p>        # flattern层 </p>  <p>        self.flatten = nn.Flatten() </p>  <p>        # 全连接层 </p>  <p>        self.fc = nn.Dense(in_channels=input_channel, out_channels=num_classes) </p>    <p>    def construct(self, x): </p>    <p>        x = self.conv1(x) </p>  <p>        x = self.norm(x) </p>  <p>        x = self.relu(x) </p>  <p>        x = self.max_pool(x) </p>    <p>        x = self.layer1(x) </p>  <p>        x = self.layer2(x) </p>  <p>        x = self.layer3(x) </p>  <p>        x = self.layer4(x) </p>    <p>        x = self.avg_pool(x) </p>  <p>        x = self.flatten(x) </p>  <p>        x = self.fc(x) </p>    <p>        return x </p>  <p>def _resnet(model_url: str, block: Type[Union[ResidualBlockBase, ResidualBlock]], </p>  <p>            layers: List[int], num_classes: int, pretrained: bool, pretrained_ckpt: str, </p>  <p>            input_channel: int): </p>  <p>    model = ResNet(block, layers, num_classes, input_channel) </p>    <p>    if pretrained: </p>  <p>        # 加载预训练模型 </p>  <p>        download(url=model_url, path=pretrained_ckpt, replace=True) </p>  <p>        param_dict = load_checkpoint(pretrained_ckpt) </p>  <p>        load_param_into_net(model, param_dict) </p>    <p>    return model </p>    <p></p>  <p>def resnet50(num_classes: int = 1000, pretrained: bool = False): </p>  <p>    &quot;&quot;&quot;ResNet50模型&quot;&quot;&quot; </p>  <p>    resnet50_url = &quot;https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/models/application/resnet50_224_new.ckpt&quot; </p>  <p>    resnet50_ckpt = &quot;./LoadPretrainedModel/resnet50_224_new.ckpt&quot; </p>  <p>    return _resnet(resnet50_url, ResidualBlock, [3, 4, 6, 3], num_classes, </p>  <p>                   pretrained, resnet50_ckpt, 2048) </p>  <p>## 可视化模型预测 </p>    <p>定义`visualize_model`函数，对CIFAR-10测试数据集进行预测，并将预测结果可视化。若预测字体颜色为蓝色表示为预测正确，预测字体颜色为红色则表示预测错误。 </p>  <p>import mindspore as ms </p>  <p>import matplotlib.pyplot as plt </p>    <p>def visualize_model(best_ckpt_path, dataset_val): </p>  <p>    num_class = 10 </p>  <p>    net = resnet50(num_class) </p>  <p>    # 加载模型参数 </p>  <p>    param_dict = ms.load_checkpoint(best_ckpt_path) </p>  <p>    ms.load_param_into_net(net, param_dict) </p>  <p>    # 加载验证集的数据进行验证 </p>  <p>    data = next(dataset_val.create_dict_iterator()) </p>  <p>    images = data[&quot;image&quot;] </p>  <p>    labels = data[&quot;label&quot;] </p>  <p>    # 预测图像类别 </p>  <p>    output = net(data['image']) </p>  <p>    pred = np.argmax(output.asnumpy(), axis=1) </p>    <p>    # 图像分类 </p>  <p>    classes = [] </p>    <p>    with open(data_dir + &quot;/batches.meta.txt&quot;, &quot;r&quot;) as f: </p>  <p>        for line in f: </p>  <p>            line = line.rstrip() </p>  <p>            if line: </p>  <p>                classes.append(line) </p>    <p>    # 显示图像及图像的预测值 </p>  <p>    plt.figure() </p>  <p>    for i in range(4): </p>  <p>        plt.subplot(2, 2, i + 1) </p>  <p>        # 若预测正确，显示为蓝色；若预测错误，显示为红色 </p>  <p>        color = 'blue' if pred[i] == labels.asnumpy()[i] else 'red' </p>  <p>        plt.title('predict:{}'.format(classes[pred[i]]), color=color) </p>  <p>        picture_show = np.transpose(images.asnumpy()[i], (1, 2, 0)) </p>  <p>        mean = np.array([0.4914, 0.4822, 0.4465]) </p>  <p>        std = np.array([0.2023, 0.1994, 0.2010]) </p>  <p>        picture_show = std * picture_show + mean </p>  <p>        picture_show = np.clip(picture_show, 0, 1) </p>  <p>        plt.imshow(picture_show) </p>  <p>        plt.axis('off') </p>    <p>    plt.show() </p>    <p></p>  <p># download ckpt </p>  <p>resnet50_url = &quot;https://mindspore-courses.obs.cn-north-4.myhuaweicloud.com/orange-pi-online-infer/02-ResNet50/resnet50-best.ckpt&quot; </p>  <p>path = &quot;./resnet50-best.ckpt&quot; </p>  <p>best_ckpt_path = download(resnet50_url, path, replace=True) </p>    <p># 使用验证数据集进行验证 </p>  <p>visualize_model(best_ckpt_path=best_ckpt_path, dataset_val=dataset_val) </p></div>",
        "url": "https://www.hiascend.com/forum/thread-0266176882143830052-1-1.html",
        "clean_data": "sad123 使用ResNet50在Ascend设备上实现CIFAR 10图像分类，涵盖数据集加载、模型构建和预测可视化。关键步骤包括： 1  配置昇腾硬件环境 2GB内存 GRAPH MODE O2优化级别  2  加载CIFAR 10二进制数据集并标准化处理 3  构建ResNet50网络 56层残差结构：3个Bottleneck组成的conv2 x conv5 x  4  加载预训练模型参数进行10类分类预测 5  可视化验证集前4张预测结果 用蓝 红区分正误",
        "created_at": "2025-03-09T05:55:44+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-09T05:55:59+08:00"
    },
    {
        "id": 40,
        "source_id": "20300772",
        "title": "使用Ais_bench推理多次报错[-1][ACL: general failure]",
        "body": "一、问题现象（附报错日志上下文）：\r\n使用Ais_bench的API推理paddle的det模型，已经转为om，结构为`（-1，3，-1，-1）`，单次推理可以成功，但批量推理一个文件夹的数据会失败。即第一次推理成功，后面会报错。\r\n\r\n可以查看下面的代码。\r\n如果`session = InferSession(device_id, model_path)`初始化代码放在for循环中，即每次推理时都重新加载session，可以成功推理，但不符合生产环境，每次初始化会很耗时。\r\n\r\n请问这种多次推理的情况，应该如何配置呢？关于Ais_bench的API文档没有看到有这方面的知识。\r\n\r\n同时我也参考这个issue：#I9T6T3:推理时报错[-1][ACL: general failure]\r\n设置`session.set_staticbatch()`，但仍错误\r\n\r\n二、软件版本:\r\n\r\n三、测试步骤：\r\n代码\r\n``` python\r\nimport os\r\nimport time\r\nimport numpy as np\r\n\r\nfrom ais_bench.infer.interface import InferSession\r\nfrom ais_bench.infer.common.utils import logger_print\r\n\r\nclass AisBenchInfer:\r\n    def __init__(self, device_id=1):\r\n        \"\"\"\r\n        初始化推理模型\r\n        \r\n        Args:\r\n            device_id: 设备ID\r\n            model_path: 模型路径\r\n        \"\"\"\r\n        self.device_id = device_id\r\n        self.model_path_rec = \"/home/aicc/mineru/model/d_n_recfix.om\"\r\n        self.model_path_det = \"/home/aicc/mineru/model/d_n_decfix_linux_aarch64.om\"\r\n        self.session_rec = InferSession(device_id, self.model_path_rec)\r\n        self.session_det = InferSession(device_id, self.model_path_det)\r\n        print(\"初始化完成:\")\r\n    \r\n    def free_resource(self):\r\n        \"\"\"释放模型资源\"\"\"\r\n        if hasattr(self, 'session'):\r\n            self.session.free_resource()\r\n \r\n    @staticmethod\r\n    def infer_folder_det(folder_path, device_id=0, model_path='/home/aicc/mineru/model/d_n_decfix_linux_aarch64.om'):\r\n        \"\"\"\r\n        处理文件夹中的所有bin文件进行检测推理\r\n        \r\n        Args:\r\n            folder_path: 包含bin文件和shape.txt文件的文件夹路径\r\n            device_id: 设备ID\r\n            model_path: 模型路径\r\n            \r\n        Returns:\r\n            所有bin文件的推理结果字典，键为bin文件名，值为推理输出\r\n        \"\"\"\r\n        session = InferSession(device_id, model_path)\r\n        # session.set_staticbatch()\r\n        results = {}\r\n        \r\n        # 获取文件夹中所有bin文件\r\n        bin_files = [f for f in os.listdir(folder_path) if f.endswith('.bin') and not f.endswith('.shape.txt')]\r\n        \r\n        for bin_file in bin_files:\r\n            bin_file_path = os.path.join(folder_path, bin_file)\r\n            shape_file_path = bin_file_path + '.shape.txt'\r\n            \r\n            # 检查shape文件是否存在\r\n            if not os.path.exists(shape_file_path):\r\n                print(f\"跳过 {bin_file}: 找不到shape文件\")\r\n                continue\r\n            \r\n            # 读取shape数据\r\n            with open(shape_file_path, 'r') as f:\r\n                shape_str = f.read().strip()\r\n            \r\n            # 解析shape数据\r\n            shape = tuple(map(int, shape_str.split(',')))\r\n            \r\n            # 读取bin数据\r\n            ndata = np.fromfile(bin_file_path, dtype=np.float32)\r\n            print(f\"处理 {bin_file}\")\r\n            print(f\"原始数据shape: {ndata.shape}\")\r\n            print(f\"从shape文件读取的形状: {shape}\")\r\n       \r\n            \r\n            # 重塑数据\r\n            try:\r\n                ndata = ndata.reshape(shape)\r\n                print(f\"重塑后的数据shape: {ndata.shape}\")\r\n                \r\n                # 执行推理\r\n                outputs = session.infer([ndata], mode='dymshape')\r\n                print(f\"{bin_file} 推理成功\")\r\n                \r\n                # 记录结果\r\n                results[bin_file] = outputs\r\n                \r\n            except Exception as e:\r\n                print(f\"处理 {bin_file} 时出错: {e}\")\r\n        \r\n        # 释放资源\r\n        session.free_resource()\r\n        \r\n        return results\r\n    \r\n\r\nresults = AisBenchInfer.infer_folder_det('/home/aicc/mineru/MinerU_1.3.0/demo/preprocessed_data/det')\r\n```\r\n\r\n四、日志信息:\r\n```\r\n[INFO] acl init success\r\n[INFO] open device 0 success\r\n[INFO] create new context\r\n[INFO] load model /home/aicc/mineru/model/d_n_decfix_linux_aarch64.om success\r\n[INFO] create model description success\r\n处理 det_input_20250421_034744_568.bin\r\n原始数据shape: (460800,)\r\n从shape文件读取的形状: (1, 3, 160, 960)\r\n重塑后的数据shape: (1, 3, 160, 960)\r\ndet_input_20250421_034744_568.bin 推理成功\r\n处理 det_input_20250421_034744_662.bin\r\n原始数据shape: (331776,)\r\n从shape文件读取的形状: (1, 3, 192, 576)\r\n重塑后的数据shape: (1, 3, 192, 576)\r\n[WARN] exception_cb deviceId:0 streamId:4 taskId:308 failed:500002\r\n[WARN] exception_cb deviceId:0 streamId:4 taskId:320 failed:500002\r\n[WARN] exception_cb deviceId:0 streamId:4 taskId:335 failed:500002\r\n[WARN] exception_cb deviceId:0 streamId:4 taskId:357 failed:500002\r\n[ACL ERROR] EZ9999: Inner Error!\r\nEZ9999: 2025-04-22-08:34:05.260.731  The error from device(chipId:0, dieId:0), serial number is 846, there is an aivec error exception, core id is 35, error code = 0x10, dump info: pc start: 0x12c0c002e06c, current: 0x12c0c002e080, vec error info: 0xeb109f6e3d, mte error info: 0xa10600004c, ifu error info: 0x517003d43c100, ccu error info: 0x378000005c00001b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c10044d000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212]\r\n        TraceBack (most recent call last):\r\n        The extend info: errcode:(0x10, 0, 0) errorStr: Illegal instruction, which is usually caused by unaligned UUB addresses. fixp_error0 info: 0x600004c, fixp_error1 info: 0xa1 fsmId:0, tslot:0, thread:0, ctxid:0, blk:15, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224]\r\n        The error from device(chipId:0, dieId:0), serial number is 846, there is an aivec error exception, core id is 36, error code = 0x10, dump info: pc start: 0x12c0c002e06c, current: 0x12c0c002e080, vec error info: 0x571add9e04, mte error info: 0xa10600004c, ifu error info: 0x67e85f015cc0, ccu error info: 0x378000005c00001b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c10044d000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212]\r\n        The extend info: errcode:(0x10, 0, 0) errorStr: Illegal instruction, which is usually caused by unaligned UUB addresses. fixp_error0 info: 0x600004c, fixp_error1 info: 0xa1 fsmId:0, tslot:0, thread:0, ctxid:0, blk:16, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224]\r\n        The error from device(chipId:0, dieId:0), serial number is 846, there is an aivec error exception, core id is 37, error code = 0x10, dump info: pc start: 0x12c0c002e06c, current: 0x12c0c002e080, vec error info: 0x7600f5366f, mte error info: 0xa10600004c, ifu error info: 0x5f467beb04e40, ccu error info: 0x378000005c00001b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c10044d000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212]\r\n        The extend info: errcode:(0x10, 0, 0) errorStr: Illegal instruction, which is usually caused by unaligned UUB addresses. fixp_error0 info: 0x600004c, fixp_error1 info: 0xa1 fsmId:0, tslot:0, thread:0, ctxid:0, blk:17, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224]\r\n        ****** 备注：类似的错误日志 **********\r\n       \r\n        The error from device(chipId:0, dieId:0), serial number is 849, there is an aivec error exception, core id is 44, error code = 0x10, dump info: pc start: 0x12c0c00463b8, current: 0x12c0c00463e8, vec error info: 0x9116822c8d, mte error info: 0xf90600004c, ifu error info: 0x89cebc0f3200, ccu error info: 0x3f8000000c0000ee, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c100459400.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212]\r\n        The extend info: errcode:(0x10, 0, 0) errorStr: Illegal instruction, which is usually caused by unaligned UUB addresses. fixp_error0 info: 0x600004c, fixp_error1 info: 0xf9 fsmId:1, tslot:0, thread:0, ctxid:0, blk:39, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224]\r\n        get opdesc info failed, device_id:0, stream_id:4, task_id:357.[FUNC:GetOpDescInfo][FILE:ge_executor.cc][LINE:1310]\r\n        [Get][OpDescInfo]get op desc faild, ge result[-1], deviceId[0], streamId[4], taskId[357][FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]\r\n        AIV Kernel happen error, retCode=0x31.[FUNC:GetError][FILE:stream.cc][LINE:1082]\r\n        Aicore kernel execute failed, device_id=0, stream_id=4, report_stream_id=4, task_id=308, flip_num=0, fault kernel_name=te_add_bffaa59b24835a39a16ebebb901bfe6348252fb2631a844142f0942bca747739_1_210000000, fault kernel info ext=none, program id=42, hash=15921761091410364091.[FUNC:GetError][FILE:stream.cc][LINE:1082]\r\n        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1082]\r\n        Aicore kernel execute failed, device_id=0, stream_id=4, report_stream_id=4, task_id=320, flip_num=0, fault kernel_name=te_add_bffaa59b24835a39a16ebebb901bfe6348252fb2631a844142f0942bca747739_1_210000000, fault kernel info ext=none, program id=42, hash=15921761091410364091.[FUNC:GetError][FILE:stream.cc][LINE:1082]\r\n        Aicore kernel execute failed, device_id=0, stream_id=4, report_stream_id=4, task_id=335, flip_num=0, fault kernel_name=te_add_bffaa59b24835a39a16ebebb901bfe6348252fb2631a844142f0942bca747739_1_210000000, fault kernel info ext=none, program id=42, hash=15921761091410364091.[FUNC:GetError][FILE:stream.cc][LINE:1082]\r\n        rtStreamSynchronizeWithTimeout execute failed, reason=[vector core exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]\r\n        Assert ((rt_ret) == 0) failed[FUNC:DoRtStreamSyncWithTimeout][FILE:utils.cc][LINE:45]\r\n        Assert ((DoRtStreamSyncWithTimeout(default_stream_)) == ge::SUCCESS) failed[FUNC:ExecuteSync][FILE:model_v2_executor.cc][LINE:240]\r\n        [Exec][Model]Execute model failed, ge result[1343225857], modelId[2147483648][FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]\r\n        [Exec][Model]modelId[2147483648] execute failed, result[500002][FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]\r\n\r\n[ERROR] execute model failed, modelId is 2147483648\r\n[ERROR] acl execute failed:1\r\n[ERROR] execute Infer failed ret:-1\r\n处理 det_input_20250421_034744_662.bin 时出错: [-1][ACL: general failure] \r\n```",
        "url": "https://gitee.com/ascend/tools/issues/IC346C",
        "clean_data": "动态输入模型多次推理时Ais bench报ACL l i   1      使用Ais bench加载Paddle模型 动态输入结构   1 3  1  1   进行文件夹批量推理时，首次成功后后续报错 500002 。日志显示非法指令异常 Illegal instruction 与未对齐的UUB地址 unaligned UUB addresses 相关。尝试通过 set staticbatch   方法或直接加载OM模型均未解决问题。生产环境要求避免重复初始化Session耗时操作，需探索适配动态输入形状的持久会话配置方案 如资源预加载 自动形状适配机制 。",
        "created_at": "2025-04-22T17:08:10+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-22T17:08:11+08:00"
    },
    {
        "id": 131,
        "source_id": "0255181304377969037",
        "title": "Orange PiA I Pro烧录系统盘时可能遇到的问题",
        "body": "<div class=\"cke-article\"><p>本人使用的Orange PiA I Pro版本如下图</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_165.png\" src=\"cid:pic_0\"></span></p>  <p>经历了至少三次重复下载，（由于在复现mobilenetv2，yolo时出现版本之类的不符合的问题！）</p>  <p>Orange PiA I Pro对应的cann包版本应如下</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_5323.png\" src=\"cid:pic_1\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0255181304377969037-1-1.html",
        "clean_data": "问题描述     Orange Pi AI Pro板载系统烧写过程中需确认与CANN包版本匹配。开发者因未匹配正确CANN版本导致模型 如MobileNetV2 YOLO 复现失败，需多次重装系统。关键操作点：烧写前需核对板卡硬件版本与对应的CANN版本编号，避免因版本不兼容引发问题。",
        "created_at": "2025-04-29T10:19:38+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-29T10:19:38+08:00"
    },
    {
        "id": 148,
        "source_id": "02108173814998442274",
        "title": "sensevoice推理报错，返回错误码500002",
        "body": "<div class=\"cke-article\"><p>为更快的帮您定位问题，推荐您用以下模板反馈：</p>  <p>1、出现问题时，您做了哪些操作？</p>  <p>答复：执行命令</p>  <p>python3 infer_ds.py --model_path=SenseVoiceSmall --om_path=model_linux_aarch64.om --device=0 --input=&quot;./SenseVoiceSmall/example/zh.mp3&quot;</p>  <p>2、在哪个步骤出现了问题？</p>  <p>答复：acl.mdl.execute报错</p>  <p>3、您希望得到什么结果？</p>  <p>答复：成功执行推理代码</p>  <p>4、您实际得到什么结果？</p>  <p>答复：推理失败返回错误码500002</p>  <p>5、请附上您出现问题页面的整屏截图或者日志信息;</p>  <p>日志信息如下</p>  <p>答复：(base) HwHiAiUser@orangepiaipro-20t:~/ModelZoo-PyTorch/ACL_PyTorch/built-in/audio/SenseVoice/SenseVoice$ python3 infer_ds.py --model_path=SenseVoiceSmall --om_path=SenseVoice_linux_aarch64.om --device=0 --input=&quot;./SenseVoiceSmall/example/zh.mp3&quot; </p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:36:58.604.446 [task_fail_callback_manager.cc:52] 71011 TaskFailCallBackManager: Constructor.</p>  <p>[EVENT] PROFILING(71011,python3):2025-02-01-12:36:58.691.785 [msprof_callback_impl.cpp:336] &gt;&gt;&gt; (tid:71011) Started to register profiling ctrl callback.</p>  <p>[EVENT] PROFILING(71011,python3):2025-02-01-12:36:58.691.970 [msprof_callback_impl.cpp:343] &gt;&gt;&gt; (tid:71011) Started to register profiling hash id callback.</p>  <p>[INFO] PROFILING(71011,python3):2025-02-01-12:36:58.691.985 [prof_atls_plugin.cpp:117] (tid:71011) RegisterProfileCallback, callback type is 7</p>  <p>[EVENT] PROFILING(71011,python3):2025-02-01-12:36:58.691.993 [msprof_callback_impl.cpp:350] &gt;&gt;&gt; (tid:71011) Started to register profiling enable host freq callback.</p>  <p>[INFO] PROFILING(71011,python3):2025-02-01-12:36:58.692.001 [prof_atls_plugin.cpp:117] (tid:71011) RegisterProfileCallback, callback type is 8</p>  <p>Loading remote code successfully: model</p>  <p>[INFO] PROFILING(71011,python3):2025-02-01-12:37:16.703.686 [prof_atls_plugin.cpp:210] (tid:71011) Module[48] register callback of ctrl handle.</p>  <p>[INFO] PROFILING(71011,python3):2025-02-01-12:37:16.703.729 [prof_atls_plugin.cpp:210] (tid:71011) Module[45] register callback of ctrl handle.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:16.958.493 [op_tiling_manager.cc:109]71011 ~FuncPerfScope:[GEPERFTRACE] The time cost of OpTilingManager::LoadSo is [254739] micro second.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:37:18.061.627 [runtime.cc:5471] 71011 GetVisibleDevices: ASCEND_RT_VISIBLE_DEVICES param was not set</p>  <p>[INFO] PROFILING(71011,python3):2025-02-01-12:37:18.063.994 [prof_atls_plugin.cpp:210] (tid:71011) Module[7] register callback of ctrl handle.</p>  <p>[EVENT] PROFILING(71011,python3):2025-02-01-12:37:18.064.086 [msprof_callback_impl.cpp:89] &gt;&gt;&gt; (tid:71011) MsprofCtrlCallback called, type: 255</p>  <p>[EVENT] PROFILING(71011,python3):2025-02-01-12:37:18.064.537 [ai_drv_dev_api.cpp:333] &gt;&gt;&gt; (tid:71011) Succeeded to DrvGetApiVersion version: 0x72313</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.064.831 [client_manager.cpp:462][GetClientRunMode][tid:71011] runningMode:0</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.064.846 [client_manager.cpp:126][GetInstance][tid:71011] [ClientManager] Current mode:2</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.064.857 [thread_mode_manager.cpp:70][Open][tid:71011] [ThreadModeManager] enter into open process deviceId[0] rankSize[0]</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.065.719 [thread_mode_manager.cpp:280][HandleAICPUPackage][tid:71011] begin load aicpu package dstPath[/home/HwHiAiUser/], srcpath[/usr/local/Ascend/ascend-toolkit/latest/opp/Ascend/aicpu/] file[Ascend-aicpu_syskernels.tar.gz]</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.065.743 [package_worker.cpp:338][LoadAICPUPackageForThreadMode][tid:71011] Package checkcode is [57460226]</p>  <p>[WARNING] TDT(71011,python3):2025-02-01-12:37:18.065.765 [package_worker.cpp:342][LoadAICPUPackageForThreadMode][tid:71011] Open aicpu_package_install.info verifyFile[/home/HwHiAiUser/aicpu_package_install.info], strerror[File exists]</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.066.039 [thread_mode_manager.cpp:280][HandleAICPUPackage][tid:71011] begin load aicpu package dstPath[/home/HwHiAiUser/], srcpath[/usr/local/Ascend/ascend-toolkit/latest/opp/Ascend/aicpu/] file[Ascend-aicpu_extend_syskernels.tar.gz]</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.066.059 [package_worker.cpp:338][LoadAICPUPackageForThreadMode][tid:71011] Package checkcode is [8052802]</p>  <p>[WARNING] TDT(71011,python3):2025-02-01-12:37:18.066.076 [package_worker.cpp:342][LoadAICPUPackageForThreadMode][tid:71011] Open aicpu_package_install.info verifyFile[/home/HwHiAiUser/extend_aicpu_package_install.info], strerror[File exists]</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.142.306 [thread_mode_manager.cpp:159][SetAICPUProfilingCallback][tid:71011] [ThreadModeManager] profiling callback is nullptr, skip set aicpu profiling callback</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.350 [aicpusd_interface_process.cpp:525][TryGetLogLevelFromParentProcess][tid:71011] get ASCEND_GLOBAL_LOG_LEVEL [] and ASCEND_GLOBAL_EVENT_ENABLE []</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.545 [aicpusd_interface_process.cpp:467][GetCurrentRunMode][tid:71011] Current aicpu mode is offline (call by api).</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.576 [aicpusd_drv_manager.cpp:327][MarkMdc][tid:71011] Get hardware version[7] success.</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.594 [aicpusd_drv_manager.cpp:190][GetNormalAicpuInfo][tid:71011] aicpuBitMap[8], aicpuNum[1].</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.607 [aicpusd_drv_manager.cpp:224][GetCcpuInfo][tid:71011] ccpuBitMap[7].</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.636 [aicpusd_drv_manager.cpp:110][GetNormalAicpuDCpuInfo][tid:71011] GetNormalAicpuDCpuInfo, deviceId[0], aicpu_num[1], aicpu_os_sched[281470681743361], ccpu_num[255082402676739], ccpu_os_sched[255082402676737], dcpu_num[255082402676736], dcpu_os_sched[281470681743361], tscpu_num[187651416129536], tscpu_os_sched[0].</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.650 [aicpusd_drv_manager.cpp:306][InitDrvMgrCaluniqueVfId][tid:71011] InitDrvMgr uniqueVfId=0, deviceId=0</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.658 [aicpusd_drv_manager.cpp:377][InitDrvMgr][tid:71011] host pid[71011], host proc name[], vf id[0], first aicpu index[0], aicpu num[1], dcpu base index[3], dcpu num[0].</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.142.779 [aicpusd_resource_manager.cpp:257][InitBufManager][tid:71011] Aicpu schedule SetBuffCfg successed!</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.143.098 [aicpusd_worker.cpp:74][ThreadPool][tid:71011] ThreadPool</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.143.244 [aicpusd_worker.cpp:274][AddPidToTask][tid:71042] Bind pid by hal.</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.143.262 [aicpusd_worker.cpp:276][AddPidToTask][tid:71042] AddPidToTask by halBindCgroup</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.165.599 [aicpusd_worker.cpp:323][SetAffinityBySelf][tid:71042] [hw]SetAffinityBySelf, physIndex[3], devNum[0]</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.165.634 [aicpusd_worker.cpp:389][SetAffinity][tid:71042] aicpu bind tid by self, index[0], deviceId[0], res[0].</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:37:18.165.869 [aicpusd_cust_so_manager.cpp:77][InitAicpuCustSoManager][tid:71011] cust so dir name is /home/HwHiAiUser/cust_aicpu_0_0_71011/.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:37:18.174.264 [raw_device.cc:237] 71011 Init: isAddrFlat:0</p>  <p>[EVENT] DRV(71011,python3):2025-02-01-12:37:18.174.481 [grp_mng.c:81][bufmng] [halGrpCreate 81] Create grp. (grp_name=private_buff_grp_71011; grp_id=20; max_size=0; cache_flag=0)</p>  <p>[EVENT] DRV(71011,python3):2025-02-01-12:37:18.174.509 [grp_mng.c:144][bufmng] [halGrpAddProc 144] add grp succ, name:private_buff_grp_71011, pid:71011, grp_id:20, admin:1 alloc:1 read:1 write:1 </p>  <p>[EVENT] DRV(71011,python3):2025-02-01-12:37:18.174.669 [buff_recycle.c:758][bufmng] [procMngInit 758] poolId 20 add task node uid 21 pid 71011</p>  <p>[EVENT] DRV(71011,python3):2025-02-01-12:37:18.174.683 [drv_buff_mbuf.c:65][bufmng] [mbufSetPrivFlag 65] Set mbuf priv flag sucess. (flag=0, g_mbuf_priv_flag=0)</p>  <p>[EVENT] DRV(71011,python3):2025-02-01-12:37:18.174.693 [grp_mng.c:212][bufmng] [halGrpAttach 212] grp attach, grp_name:private_buff_grp_71011, grp_id:20, timeout:1000</p>  <p>[EVENT] DRV(71011,python3):2025-02-01-12:37:18.174.705 [drv_buff_memzone.c:450][bufmng] [memzone_cfg 450] BuffCfg success. (cfg num=4; huge_prior=393216; normal=393216; huge_only=393216; dvpp_huge_prior=393216; dvpp_normal=393216; dvpp_huge_only=393216)</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.176.648 [tsd_client.cpp:172][TsdCapabilityGet][tid:71011] TsdCapabilityGet Begin.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:37:18.176.672 [engine.cc:76] 71011 Engine: Constructor.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:37:18.176.681 [stars_engine.cc:41] 71011 StarsEngine: Constructor.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:37:18.179.568 [npu_driver.cc:5784] 71045 GetDeviceStatus: GetDeviceStatus status=1.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:37:18.180.535 [device_error_proc.cc:446] 71011 GetTschCapability: Tsch not support capability feature, use old solution.</p>  <p>[INFO] TDT(71011,python3):2025-02-01-12:37:18.180.583 [client_manager.cpp:195][SetProfilingCallback][tid:71011] [TsdClient] set profiling callback success</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:33.947.513 [model_converter.cc:483]71011 CollectAndReserveStreamResource:Model SenseVoice require reusable stream num is 1 attached stream num is 0 event num is 0 notify num is 0.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:33.951.463 [op_impl_registry_holder_manager.cc:361]71011 GetOrCreateOpImplRegistryHolder:so has been loaded, so name: /libcust_opsproto_rt2.0.so, version:7.6.0.1.220, cpu:aarch64, os:linux</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:33.957.336 [op_impl_registry_holder_manager.cc:361]71011 GetOrCreateOpImplRegistryHolder:so has been loaded, so name: /libcust_opmaster_rt2.0.so, version:7.6.0.1.220, cpu:aarch64, os:linux</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:34.103.265 [op_impl_registry_holder_manager.cc:361]71011 GetOrCreateOpImplRegistryHolder:so has been loaded, so name: /libopsproto_rt.so, version:7.6.0.1.220, cpu:aarch64, os:linux</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:34.502.480 [op_impl_registry_holder_manager.cc:361]71011 GetOrCreateOpImplRegistryHolder:so has been loaded, so name: /libopmaster_rt.so, version:7.6.0.1.220, cpu:aarch64, os:linux</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:34.684.547 [op_impl_registry_holder_manager.cc:361]71011 GetOrCreateOpImplRegistryHolder:so has been loaded, so name: /libopsproto_rt.so, version:7.6.0.1.220, cpu:aarch64, os:linux</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:35.150.137 [op_impl_registry_holder_manager.cc:361]71011 GetOrCreateOpImplRegistryHolder:so has been loaded, so name: /libopmaster_rt.so, version:7.6.0.1.220, cpu:aarch64, os:linux</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:48.536.160 [graph_converter.cc:858]71011 ConvertComputeGraphToExecuteGraph:[GEPERFTRACE] The time cost of ConvertComputeGraphToExecuteGraph::CreateMainNode is [12224825] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:48.717.261 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of ZeroCopy is [181039] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:51.746.267 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of CEM is [3028953] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:52.050.005 [copy_flow_launch_fuse.cc:499]71011 Run:[GEPERFTRACE] The time cost of Pass::CopyFlowLaunchFuse is [303691] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:52.050.047 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of CopyFlowLaunch is [303740] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:52.050.063 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of TrustOutTensor is [1] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:52.050.074 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of AicpuFuseHostInputs is [1] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:52.250.542 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of ZeroCopy is [200454] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:52.914.345 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of CEM is [663758] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:53.213.118 [copy_flow_launch_fuse.cc:499]71011 Run:[GEPERFTRACE] The time cost of Pass::CopyFlowLaunchFuse is [298724] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:53.213.161 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of CopyFlowLaunch is [298773] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:53.213.173 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of TrustOutTensor is [1] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:53.213.185 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of AicpuFuseHostInputs is [2] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:53.414.228 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of ZeroCopy is [201028] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:53.947.252 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of CEM is [532985] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:54.243.591 [copy_flow_launch_fuse.cc:499]71011 Run:[GEPERFTRACE] The time cost of Pass::CopyFlowLaunchFuse is [296295] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:54.243.634 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of CopyFlowLaunch is [296343] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:54.243.646 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of TrustOutTensor is [1] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:54.243.657 [base_optimizer.cc:63]71011 Run:[GEPERFTRACE] The time cost of AicpuFuseHostInputs is [2] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:54.273.292 [graph_converter.cc:869]71011 ConvertComputeGraphToExecuteGraph:[GEPERFTRACE] The time cost of ConvertComputeGraphToExecuteGraph::RunAllPass is [5737080] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:55.414.947 [graph_converter.cc:873]71011 ConvertComputeGraphToExecuteGraph:[GEPERFTRACE] The time cost of ConvertComputeGraphToExecuteGraph::TopologicalSorting is [1141610] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:59.010.924 [graph_converter.cc:879]71011 ConvertComputeGraphToExecuteGraph:[GEPERFTRACE] The time cost of ConvertComputeGraphToExecuteGraph::AppendGraphLevelData is [3343852] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:59.608.821 [graph_converter.cc:884]71011 ConvertComputeGraphToExecuteGraph:[GEPERFTRACE] The time cost of ConvertComputeGraphToExecuteGraph::CalculatePriority is [597852] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:37:59.657.903 [graph_converter.cc:889]71011 ConvertComputeGraphToExecuteGraph:[GEPERFTRACE] The time cost of ConvertComputeGraphToExecuteGraph::All is [23347894] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:03.153.327 [model_v2_executor_builder.cc:117]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::UpdateEquivalentEdges is [3388958] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:03.309.903 [model_v2_executor_builder.cc:120]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::AllocRootGraphAnyValues is [156532] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:03.336.468 [model_v2_executor_builder.cc:124]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::ReadInBuffer is [26523] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:03.350.451 [model_v2_executor_builder.cc:129]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::ReadInComputeNodeInfo is [13944] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:03.391.617 [model_v2_executor_builder.cc:134]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::ReadInKernelExtendInfo is [41127] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:03.394.524 [model_v2_executor_builder.cc:139]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::ReadInModelDesc is [2869] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:07.855.633 [model_v2_executor_builder.cc:170]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::BuildGraph is [4461077] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:08.040.420 [model_v2_executor_builder.cc:186]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::SubscribersSchedulerInit is [184712] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:08.040.464 [model_v2_executor_builder.cc:187]71011 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::All is [8294500] micro second.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:08.994.388 [scalable_config.cc:74]71011 ScalableConfig:device total max size: 24823529472, page_mem_size_total_threshold: 23582352998, uncacheable_size_threshold: 17179869184</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:38:09.122.742 [tf_adpt_session_mgr.cc:393][CreateSession][tid:71042][TFAdapter][sessionID:9223372036854775808] Create session success.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:09.134.620 [davinci_model.cc:1337]71011 InitNodes:[GEPERFTRACE] The time cost of GraphLoader::InitTbeHandle. is [239] micro second, call num is 3</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:09.134.658 [davinci_model.cc:1338]71011 InitNodes:[GEPERFTRACE] The time cost of DavinciModel::InitNodes is [1046] micro second.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:38:09.136.313 [api_error.cc:2431] 71011 ModelBindStream: model_id=0, stream_id=4, model_name=SenseVoice_sub_1_know, flag=0, group_id=255.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:09.138.819 [davinci_model.cc:927]71011 PrintfModelProfOfModelLoad:[GEPERFTRACE] The time cost of GraphLoader::DavinciModel::Init is [7571] micro second, name[SenseVoice_sub_1_know]model_id[4294967295]graph_id[0].</p>  <p>init resource success</p>  <p>Inputs: 4, Outputs: 2</p>  <p>Speech shape: torch.Size([1, 94, 560]), speech_lengths shape: torch.Size([1])</p>  <p>speech_np shape: (1, 94, 560), speech_lengths_np shape: (1,)</p>  <p>language shape: (1,), textnorm shape: (1,)</p>  <p>in 255086697884672 210560</p>  <p>in 255086698095616 4</p>  <p>in 255086698096640 4</p>  <p>in 255086698097152 4</p>  <p>out 255086698097152 0</p>  <p>out 255086698097152 0</p>  <p>[ERROR] GE(71011,python3):2025-02-01-12:38:13.791.132 [shape_utils.cc:35]71011 CalcAlignedSizeByShape: ErrorNo: 4294967295(failed) [EXEC][DEFAULT][Calc][TensorSizeByShape] shape_size[-560] data_type[DT_FLOAT] failed</p>  <p>[ERROR] ASCENDCL(71011,python3):2025-02-01-12:38:13.791.303 [model.cpp:757]71011 RuntimeV2ModelExecute: [EXEC][DEFAULT][Exec][Model]Execute model failed, ge result[4294967295], modelId[2147483648]</p>  <p>[ERROR] ASCENDCL(71011,python3):2025-02-01-12:38:13.791.446 [model.cpp:2104]71011 aclmdlExecute: [EXEC][DEFAULT][Exec][Model]modelId[2147483648] execute failed, result[500002]</p>  <p>Traceback (most recent call last):</p>  <p>  File &quot;/home/HwHiAiUser/ModelZoo-PyTorch/ACL_PyTorch/built-in/audio/SenseVoice/SenseVoice/infer_ds.py&quot;, line 233, in &lt;module&gt;</p>  <p>    res, _ = m.infer_acl(</p>  <p>  File &quot;/home/HwHiAiUser/ModelZoo-PyTorch/ACL_PyTorch/built-in/audio/SenseVoice/SenseVoice/infer_ds.py&quot;, line 172, in infer_acl</p>  <p>    assert ret == 0, f&quot;推理执行失败，错误码: {ret}&quot;</p>  <p>AssertionError: 推理执行失败，错误码: 500002</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:38:15.976.836 [aicpusd_worker.cpp:168][WaitForStop][tid:71011] WaitForStop begin.</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:38:18.377.743 [aicpusd_worker.cpp:174][WaitForStop][tid:71011] WaitForStop end.</p>  <p>[EVENT] CCECPU(71011,python3):2025-02-01-12:38:18.421.848 [aicpusd_mpi_mgr.cpp:48][PrintStatisticInfo][tid:71011] Mpi Dvpp event statistic: [0]</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:38:24.186.871 [api_error.cc:2445] 71011 ModelUnbindStream: model_id=0, stream_id=4, model_name=SenseVoice_sub_1_know, group_id=255.</p>  <p>[INFO] GE(71011,python3):2025-02-01-12:38:24.187.397 [davinci_model.cc:7470]71011 LogModelDevMemInfo:model_metrics:name=SenseVoice_sub_1_know, alloc_dev_mem=1024 B, shared_dev_mem=0 B, device_id=0, rts_model_id=0</p>  <p>[ERROR] GE(71011,python3):2025-02-01-12:38:24.188.256 [tbe_handle_store.cc:151]71011 EraseTBEHandle: ErrorNo: 1343225860(Internal errors) [Check][Param] Kernel[te_add_04a5147823af71da3a6df3f8cdf3fc248b872646296f63aa49aaa4b027cb69d72951db123d93246c68f633fd5550cc1368955c77a31aa01a2a7d23426e337bd8_static_bin] not found in stored.</p>  <p>[ERROR] GE(71011,python3):2025-02-01-12:38:24.188.301 [tbe_handle_store.cc:151]71011 EraseTBEHandle: ErrorNo: 1343225860(Internal errors) [Check][Param] Kernel[te_cast_40ee5b4e88c86f609e9d5367a147bd9b03bcd04d985d7a00e60abf792fc5387ee016bc9f35e4743fa3a4e28e8d604856bc3583ac7a08c910e451e59c6000564c_static_bin] not found in stored.</p>  <p>[ERROR] GE(71011,python3):2025-02-01-12:38:24.188.334 [tbe_handle_store.cc:151]71011 EraseTBEHandle: ErrorNo: 1343225860(Internal errors) [Check][Param] Kernel[te_cast_4978a1c9fe5106d2fbc311acae52d11bee65e963a8cf6d8e8c943b9bae3c383f565b533879a6576b3fbf762017264bf3d34b20211f13a666075ed5dc78255993_static_bin] not found in stored.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:38:24.579.272 [task_fail_callback_manager.cc:57] 71011 ~TaskFailCallBackManager: Destructor.</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:38:24.580.692 [runtime.cc:2033] 71011 ~Runtime: deconstruct runtime</p>  <p>[INFO] RUNTIME(71011,python3):2025-02-01-12:38:24.580.713 [runtime.cc:2040] 71011 ~Runtime: wait monitor success, use=0.</p>  <p>推理代码如下</p>  <pre><br># Copyright 2024 Huawei Technologies Co., Ltd<br># (此处保留原有License声明，需根据实际需求调整)<br><br>import argparse<br>import time<br>import numpy as np<br>import torch<br>import acl<br>from funasr import AutoModel<br>from funasr.utils.postprocess_utils import rich_transcription_postprocess<br>from funasr.utils.load_utils import load_audio_text_image_video, extract_fbank<br><br># error code<br>ACL_SUCCESS = 0<br><br># rule for mem<br>ACL_MEM_MALLOC_HUGE_FIRST = 0<br>ACL_MEM_MALLOC_HUGE_ONLY = 1<br>ACL_MEM_MALLOC_NORMAL_ONLY = 2<br><br># rule for memory copy<br>ACL_MEMCPY_HOST_TO_HOST = 0<br>ACL_MEMCPY_HOST_TO_DEVICE = 1<br>ACL_MEMCPY_DEVICE_TO_HOST = 2<br>ACL_MEMCPY_DEVICE_TO_DEVICE = 3<br><br>def check_ret(message, ret):<br>    if ret != ACL_SUCCESS:<br>        raise Exception(&quot;{} failed ret={}&quot;<br>                        .format(message, ret))<br><br><br>class SenseVoiceACLModel:<br>    def __init__(self, device_id, om_path):<br>        self.device_id = device_id<br>        self.om_path = om_path<br>        self.model_id = None<br>        self.context = None<br>        self.stream = None<br>        self.blank_id = 0<br>        self.lid_dict = {&quot;auto&quot;: 0, &quot;zh&quot;: 3, &quot;en&quot;: 4, &quot;yue&quot;: 7, &quot;ja&quot;: 11, &quot;ko&quot;: 12, &quot;nospeech&quot;: 13}<br>        self.textnorm_dict = {'withitn': 14, &quot;woitn&quot;: 15}<br>        self.input_data = []<br>        self.output_data = []<br><br>        # 初始化ACL环境<br>        self._init_acl()<br><br>    def _init_acl(self):<br>        &quot;&quot;&quot;显式初始化ACL环境&quot;&quot;&quot;<br>        # 初始化ACL<br>        ret = acl.init()<br>        assert ret == 0, f&quot;ACL初始化失败，错误码: {ret}&quot;<br><br>        # 设置NPU设备<br>        ret = acl.rt.set_device(self.device_id)<br>        assert ret == 0, f&quot;设置设备失败，错误码: {ret}&quot;<br><br>        # 创建Context和Stream<br>        self.context, ret = acl.rt.create_context(self.device_id)<br>        assert ret == 0, f&quot;创建Context失败，错误码: {ret}&quot;<br><br>        self.stream, ret = acl.rt.create_stream()<br>        assert ret == 0, f&quot;创建Stream失败，错误码: {ret}&quot;<br><br>        # 加载OM模型<br>        self.model_id, ret = acl.mdl.load_from_file(self.om_path)<br>        assert ret == 0, f&quot;模型加载失败，错误码: {ret}&quot;<br>        <br>        self.model_desc = acl.mdl.create_desc()<br>        ret = acl.mdl.get_desc(self.model_desc, self.model_id)<br>        check_ret(&quot;acl.mdl.get_desc&quot;, ret)<br>        print(&quot;init resource success&quot;)<br><br>        input_num = acl.mdl.get_num_inputs(self.model_desc)<br>        output_num = acl.mdl.get_num_outputs(self.model_desc)<br>        print(f&quot;Inputs: {input_num}, Outputs: {output_num}&quot;)<br><br><br>    def _destroy_acl(self):<br>        &quot;&quot;&quot;释放ACL资源&quot;&quot;&quot;<br>        if self.model_id:<br>            acl.mdl.unload(self.model_id)<br>        if self.stream:<br>            acl.rt.free_stream(self.stream)<br>        if self.context:<br>            acl.rt.destroy_context(self.context)<br>        acl.rt.reset_device(self.device_id)<br>        acl.finalize()<br>    <br>    def _gen_dataset(self, type_str=&quot;input&quot;):<br>        dataset = acl.mdl.create_dataset()<br><br>        temp_dataset = None<br>        if type_str == &quot;in&quot;:<br>            self.load_input_dataset = dataset<br>            temp_dataset = self.input_data<br>        else:<br>            self.load_output_dataset = dataset<br>            temp_dataset = self.output_data<br><br>        for item in temp_dataset:<br>            data = acl.create_data_buffer(item[&quot;buffer&quot;], item[&quot;size&quot;])<br>            _, ret = acl.mdl.add_dataset_buffer(dataset, data)<br>            print(type_str,item[&quot;buffer&quot;], item[&quot;size&quot;])<br><br>            if ret != ACL_SUCCESS:<br>                ret = acl.destroy_data_buffer(data)<br>                check_ret(&quot;acl.destroy_data_buffer&quot;, ret)<br><br>    def infer_acl(self, data_in,tokenizer=None,frontend=None, **kwargs):<br>        &quot;&quot;&quot;手动管理ACL的推理逻辑&quot;&quot;&quot;<br>        # 数据预处理（与原始代码相同）<br>        audio_sample_list = load_audio_text_image_video(<br>            data_in,<br>            fs=frontend.fs,<br>            audio_fs=kwargs.get(&quot;fs&quot;, 16000),<br>            data_type=kwargs.get(&quot;data_type&quot;, &quot;sound&quot;),<br>            tokenizer=tokenizer,<br>        )<br>        speech, speech_lengths = extract_fbank(<br>            audio_sample_list, data_type=kwargs.get(&quot;data_type&quot;, &quot;sound&quot;), frontend=frontend<br>        )<br>        print(f&quot;Speech shape: {speech.shape}, speech_lengths shape: {speech_lengths.shape}&quot;)  # 添加调试信息<br>        # 转换为NPU Tensor（假设数据已在CPU）<br>        speech_np = speech.numpy().astype(np.float32)<br>        speech_lengths_np = speech_lengths.numpy().astype(np.int32)<br>        language = torch.LongTensor([self.lid_dict[kwargs.get(&quot;language&quot;, &quot;auto&quot;)]]).numpy().astype(np.int32)<br>        textnorm = torch.LongTensor([self.textnorm_dict[&quot;woitn&quot;]]).numpy().astype(np.int32)<br>        print(f&quot;speech_np shape: {speech_np.shape}, speech_lengths_np shape: {speech_lengths_np.shape}&quot;)<br>        print(f&quot;language shape: {language.shape}, textnorm shape: {textnorm.shape}&quot;)<br><br>        # 为输入数据分配Device内存<br>        for data in [speech_np, speech_lengths_np, language, textnorm]:<br>            size = data.nbytes<br>            ptr = acl.util.bytes_to_ptr(data.tobytes())<br>            buf, ret = acl.rt.malloc(size, ACL_MEM_MALLOC_HUGE_FIRST)  # 在NPU上分配内存<br>            assert ret == 0, f&quot;内存分配失败，错误码: {ret}&quot;<br>            acl.rt.memcpy(buf, size, ptr, size, ACL_MEMCPY_HOST_TO_DEVICE)<br>            self.input_data.append({&quot;buffer&quot;: buf,<br>                                    &quot;size&quot;: size})<br><br><br>        # 准备输出内存<br>        output_size = acl.mdl.get_num_outputs(self.model_desc)<br>        for i in range(output_size):<br>            size = acl.mdl.get_output_size_by_index(self.model_desc, i)<br>            # buf, ret = acl.rt.malloc(size, ACL_MEM_MALLOC_HUGE_FIRST)<br>            # assert ret == 0, f&quot;输出内存分配失败，错误码: {ret}&quot;<br>            self.output_data.append({&quot;buffer&quot;: buf,<br>                                     &quot;size&quot;: 0})<br>        '''<br>        for size in output_sizes:<br>            buf, ret = acl.rt.malloc(size, ACL_MEM_MALLOC_HUGE_FIRST)<br>            assert ret == 0, f&quot;输出内存分配失败，错误码: {ret}&quot;<br>            output_buffers.append(buf)<br>        '''<br>        <br>        # load input data into model<br>        self._gen_dataset(&quot;in&quot;)<br>        # load output data into model<br>        self._gen_dataset(&quot;out&quot;)<br><br><br>        # 执行推理<br>        start_time = time.time()<br>        ret = acl.mdl.execute(<br>            self.model_id,<br>            self.load_input_dataset,<br>            self.load_output_dataset)<br><br>        assert ret == 0, f&quot;推理执行失败，错误码: {ret}&quot;<br>        cost_time = time.time() - start_time<br><br>        # 从Device拷贝输出到Host<br>        '''<br>        outputs = []<br>        for buf, size in zip(output_buffers, output_sizes):<br>            host_buf = np.zeros(size // np.dtype(np.float32).itemsize, dtype=np.float32)<br>            acl.rt.memcpy(host_buf.tobytes(), size, buf, size, ACL_MEMCPY_DEVICE_TO_HOST)<br>            outputs.append(torch.from_numpy(host_buf).npu())<br><br>        # 释放Device内存<br>        for buf in input_buffers + output_buffers:<br>            acl.rt.free(buf)<br>        '''<br>        outputs = []<br>        for item in self.output_data:<br>            host_buf = np.zeros(item[&quot;size&quot;] // np.dtype(np.float32).itemsize, dtype=np.float32)<br>            ret = acl.rt.memcpy(host_buf.tobytes(), item[&quot;size&quot;], item[&quot;buffer&quot;], item[&quot;size&quot;], ACL_MEMCPY_DEVICE_TO_HOST)<br>            assert ret == 0, f&quot;数据拷贝失败，错误码: {ret}&quot;<br>            outputs.append(torch.from_numpy(host_buf).npu())<br><br>        # 释放Device内存<br>        for item in self.input_data + self.output_data:<br>            acl.rt.free(item[&quot;buffer&quot;])<br><br><br>        # 后处理（与原始代码相同）<br>        ctc_logits, encoder_out_lens = outputs[0], outputs[1]<br>        results = []<br>        x = ctc_logits[0, : encoder_out_lens[0].item(), :]<br>        yseq = x.argmax(dim=-1)<br>        yseq = torch.unique_consecutive(yseq, dim=-1)<br>        mask = yseq != self.blank_id<br>        token_int = yseq[mask].tolist()<br>        text = tokenizer.decode(token_int)<br>        results.append({&quot;key&quot;: &quot;wav_file_tmp_name&quot;, &quot;text&quot;: text})<br><br>        return results, cost_time<br><br>    def __del__(self):<br>        self._destroy_acl()<br><br>if __name__ == '__main__':<br>    parser = argparse.ArgumentParser(description=&quot;SenseVoice ACL推理&quot;)<br>    parser.add_argument(&quot;--model_path&quot;, type=str, help=&quot;PyTorch模型路径&quot;)<br>    parser.add_argument('--om_path', type=str, help='OM模型路径')<br>    parser.add_argument('--device', type=int, default=0, help='NPU设备ID')<br>    parser.add_argument('--input', type=str, help='输入音频文件')<br>    parser.add_argument('--perform', action='store_true', help='性能测试模式')<br>    parser.add_argument('--loop', default=10, type=int, help='循环次数')<br>    args = parser.parse_args()<br><br>    # 加载PyTorch模型配置<br>    _, kwargs = AutoModel.build_model(model=args.model_path, trust_remote_code=True)<br><br>    # 初始化ACL推理器<br>    m = SenseVoiceACLModel(device_id=args.device, om_path=args.om_path)<br><br>    with torch.no_grad():<br>        # 执行推理<br>        res, _ = m.infer_acl(<br>            data_in=args.input,<br>            # tokenizer=kwargs[&quot;tokenizer&quot;],<br>            # frontend=kwargs[&quot;frontend&quot;],<br>            language=&quot;auto&quot;,<br>            use_itn=False,<br>            **kwargs<br>        )<br>        text = rich_transcription_postprocess(res[0]['text'])<br>        print('语音输出:', text)<br><br>        if args.perform:<br>            total_time = 0.0<br>            for _ in range(args.loop):<br>                _, cost_time = m.infer_acl(<br>                    data_in=args.input,<br>                    tokenizer=kwargs[&quot;tokenizer&quot;],<br>                    frontend=kwargs[&quot;frontend&quot;],<br>                    language=&quot;auto&quot;,<br>                    use_itn=False,<br>                    **kwargs<br>                )<br>                total_time += cost_time<br>            print(f'平均推理耗时: {total_time / args.loop:.4f}s')</pre></div>",
        "url": "https://www.hiascend.com/forum/thread-02108173814998442274-1-1.html",
        "clean_data": "SenseVoice推理报错500002：ACL模型执行失败，日志显示 CalcAlignedSizeByShape 计算输入形状尺寸异常  shape size  560   ，且 EraseTBEHandle 提示模型所需内核未在NPUC存储中找到。模型输入输出配置声明为4输入2输出，但数据转换 内存分配流程中存在输入重复覆盖与Kernel缺失问题。核心问题为模型实际输入格式与OM模型定义不匹配或运行时未正确加载定制算子。",
        "created_at": "2025-02-01T17:56:38+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-31T03:33:16+08:00"
    },
    {
        "id": 157,
        "source_id": "0205184405035055050",
        "title": "Ascend C算子开发能力认证考试(中级)",
        "body": "<div class=\"cke-article\"><p>基础环境都搞定了，还差代码这块。谁做了帮我看看，应该怎么改，主要是：Compute函数这块。</p>  <pre><br><code class=\"language-cpp\">#include &quot;kernel_operator.h&quot;<br>using namespace AscendC;<br>constexpr int32_t BUFFER_NUM = 2;<br>class KernelSigmoid {<br>public:<br>    __aicore__ inline KernelSigmoid() {}<br>    __aicore__ inline void Init(GM_ADDR x, GM_ADDR y, uint32_t totalLength, uint32_t tileNum)<br>    {<br>        //考生补充初始化代码<br>        ASSERT(GetBlockNum() != 0 &amp;&amp; &quot;block dim can not be zero!&quot;);<br>        this-&gt;blockLength = totalLength / GetBlockNum();<br>        this-&gt;tileNum = tileNum;<br>        ASSERT(tileNum != 0 &amp;&amp; &quot;tile num can not be zero!&quot;);<br>        this-&gt;tileLength = this-&gt;blockLength / tileNum / BUFFER_NUM;<br>        xGm.SetGlobalBuffer((__gm__ DTYPE_X *)x + this-&gt;blockLength * GetBlockIdx(), <br>        this-&gt;blockLength);<br>        yGm.SetGlobalBuffer((__gm__ DTYPE_Y *)y + this-&gt;blockLength * GetBlockIdx(), <br>        this-&gt;blockLength);<br>        pipe.InitBuffer(inQueueX, BUFFER_NUM, this-&gt;tileLength * sizeof(DTYPE_X));<br>        pipe.InitBuffer(outQueueY, BUFFER_NUM, this-&gt;tileLength * sizeof(DTYPE_Y));<br>        pipe.InitBuffer(tmpBuffer1, this-&gt;tileLength * sizeof(DTYPE_X));<br>        pipe.InitBuffer(tmpBuffer2, this-&gt;tileLength * sizeof(DTYPE_X));<br>        pipe.InitBuffer(tmpBuffer3, this-&gt;tileLength * sizeof(DTYPE_X));<br>        pipe.InitBuffer(tmpBuffer4, this-&gt;tileLength * sizeof(DTYPE_X));<br>    }<br>    __aicore__ inline void Process()<br>    {<br>        // 补充对“loopCount”的定义，注意对Tiling的处理<br>        int32_t loopCount = this-&gt;blockLength / this-&gt;tileLength;<br>        for (int32_t i = 0; i &lt; loopCount; i++) {<br>            CopyIn(i);<br>            Compute(i);<br>            CopyOut(i);<br>        }<br>    }<br><br>private:<br>    __aicore__ inline void CopyIn(int32_t progress)<br>    {<br>        //考生补充算子代码<br>        LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.AllocTensor&lt;DTYPE_X&gt;();<br>        DataCopy(xLocal, xGm[progress * this-&gt;tileLength ], this-&gt;tileLength);<br>        inQueueX.EnQue(xLocal);<br>    }<br>    __aicore__ inline void Compute(int32_t progress)<br>    {<br>        //考生补充算子计算代码: sigmoid(x) = 1/(1 + exp(-x)) <br>        LocalTensor&lt;DTYPE_X&gt; xLocal = inQueueX.DeQue&lt;DTYPE_X&gt;();<br>        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.AllocTensor&lt;DTYPE_Y&gt;();<br>        LocalTensor&lt;DTYPE_X&gt; tmpTensor1 = tmpBuffer1.Get&lt;DTYPE_X&gt;();<br>        LocalTensor&lt;DTYPE_X&gt; tmpTensor2 = tmpBuffer2.Get&lt;DTYPE_X&gt;();<br>        LocalTensor&lt;DTYPE_X&gt; tmpTensor3 = tmpBuffer3.Get&lt;DTYPE_X&gt;();<br>        LocalTensor&lt;DTYPE_X&gt; tmpTensor4 = tmpBuffer4.Get&lt;DTYPE_X&gt;();<br>        DTYPE_X inputVal1 = -1;<br>        //目标公式：sigmoid(x) = 1/(1 + exp(-x)) <br>        /**<br>        将输入张量乘以-1（Muls），得到-x。<br>        计算exp(-x)（Exp）。<br>        计算1 + exp(-x)（Add）。<br>        计算1 / (1 + exp(-x))（Reciprocal）。<br>        **/<br>        DTYPE_X inputVal3 = 1;<br>        Muls(tmpTensor1, xLocal, inputVal1, this-&gt;tileLength);<br>        Exp(tmpTensor2, tmpTensor1, this-&gt;tileLength);<br>        Adds(tmpTensor3, tmpTensor2, inputVal3, this-&gt;tileLength);<br>        // 精度问题，需要使用Div但是Div这个函数使用不熟悉，下面这句应该如何改。<br>        Reciprocal(yLocal, tmpTensor3, this-&gt;tileLength);<br>        outQueueY.EnQue&lt;DTYPE_Y&gt;(yLocal);<br>        inQueueX.FreeTensor(xLocal);<br>    }<br>    __aicore__ inline void CopyOut(int32_t progress)<br>    {<br>        // 考生补充算子代码<br>        LocalTensor&lt;DTYPE_Y&gt; yLocal = outQueueY.DeQue&lt;DTYPE_Y&gt;();<br>        DataCopy(yGm[progress * this-&gt;tileLength], yLocal, this-&gt;tileLength);<br>        outQueueY.FreeTensor(yLocal);<br>    }<br><br>private:<br>    TPipe pipe;<br>    //create queue for input, in this case depth is equal to buffer num<br>    TQue&lt;QuePosition::VECIN, BUFFER_NUM&gt; inQueueX;<br>    //create queue for output, in this case depth is equal to buffer num<br>    TQue&lt;QuePosition::VECOUT, BUFFER_NUM&gt; outQueueY;<br>    GlobalTensor&lt;half&gt; xGm;<br>    GlobalTensor&lt;half&gt; yGm;<br><br>    //考生补充自定义成员变量<br>    TBuf&lt;QuePosition::VECCALC&gt; tmpBuffer1, tmpBuffer2, tmpBuffer3, tmpBuffer4;<br>    uint32_t blockLength;<br>    uint32_t tileNum;<br>    uint32_t tileLength;<br>};<br>extern &quot;C&quot; __global__ __aicore__ void sigmoid_custom(GM_ADDR x, GM_ADDR y, GM_ADDR workspace, GM_ADDR tiling) {<br>    GET_TILING_DATA(tiling_data, tiling);<br>    KernelSigmoid op;<br>    //补充init和process函数调用内容<br>    op.Init(x, y, tiling_data.totalLength, tiling_data.tileNum);<br>    op.Process();<br>}</code></pre></div>",
        "url": "https://www.hiascend.com/forum/thread-0205184405035055050-1-1.html",
        "clean_data": "Ascend C中级算子认证：Compute函数实现sigmoid x  1  1 exp  x  的四步运算，需修正Div函数调用逻辑。核心问题在于将单量Reciprocal改为双量Div操作时，需要创建全为1的分子张量，建议使用预定义常量张量替代标量。代码关键修改点位于Compute函数中的倒数计算步骤：  1  预定义全为1的常量张量 需考虑数据类型对齐  2  修正计算流程：Add后使用Div操作代替Reciprocal 3  保留原有内存释放机制，确保队列状态正确。",
        "created_at": "2025-06-04T07:37:15+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T01:23:54+08:00"
    },
    {
        "id": 39,
        "source_id": "20246133",
        "title": "addcmul/addcdiv",
        "body": "一、需求场景&价值\r\n\r\n二、需求建议实现的规格\r\n\r\n三、竞品比较（选填）",
        "url": "https://gitee.com/ascend/canndev/issues/IC1Y0L",
        "clean_data": "addcmul addcdiv算子实现需求：场景价值、实现规格及竞品分析",
        "created_at": "2025-04-17T16:06:01+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-17T16:13:15+08:00"
    },
    {
        "id": 154,
        "source_id": "0226184468452524060",
        "title": "OpenCV编译 CANN没有打开",
        "body": "<div class=\"cke-article\"><p>1、按文档操作，https://gitee.com/ascend/samples/blob/master/inference/contributeSamples/contrib/samplesOpenCV/README.md</p>  <p>2、配置后，显示CANN 没有打开</p>  <p>cmake -D WITH_CANN=ON \\</p>  <p>            -D CMAKE_INSTALL_PREFIX=install \\</p>  <p>            -D BUILD_opencv_gapi=OFF \\</p>  <p>            -D OPENCV_DOWNLOAD_MIRROR_ID=gitcode \\</p>  <p>            -D BUILD_opencv_python2=OFF \\</p>  <p>            -D BUILD_opencv_python3=ON \\</p>  <p>            -D PYTHON3_EXECUTABLE=/usr/local/python3.7.5/bin/python3.7m \\</p>  <p>            -D PYTHON3_LIBRARY=/usr/local/python3.7.5/lib/libpython3.7m.so \\</p>  <p>            -D PYTHON3_INCLUDE_DIR=/usr/local/python3.7.5/include/python3.7m \\</p>  <p>            ..</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_6207.png\" src=\"cid:pic_0\"></span></p>  <p>3、机器是Atlas 800训练服务器，显卡是910a</p>  <p>4、镜像使用swr.cn-south-1.myhuaweicloud.com/ascendhub/ascend-infer:24.0.0-ubuntu20.04</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0226184468452524060-1-1.html",
        "clean_data": "Title    OpenCV编译时CANN未启用问题     Description    按官方文档配置cmake参数启用WITH CANN，但编译显示CANN未打开，使用Atlas 800训练服务器 910a芯片 及ascend infer 24 0 0 ubuntu20 04镜像。需检查环境变量、CANN依赖库是否正确配置，或镜像与CANN版本兼容性。",
        "created_at": "2025-06-05T01:14:13+08:00",
        "topic_summary": "昇腾CANN开发者如何解决cmake无法启用WITH_CANN选项的编译问题",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T05:47:49+08:00"
    },
    {
        "id": 164,
        "source_id": "0237180980015919006",
        "title": "Ascend C使用vscode开发时遇到的#include\"kernel_oprator.h\"报错以及解决方法",
        "body": "<div class=\"cke-article\"><p>查了下网上有人提出这个问题但没有详细解决方案，这边写一下。#include&quot;kernel_oprator.h&quot;如果报错，是因为环境没有配置好，刚入门的小白确实不好处理这个。</p>  <p>在.vscode/c_cpp_properties.json中添加include以及ascendc/include即可：</p>  <p><code>                &quot;/安装目录/Ascend/ascend-toolkit/latest/x86_64-linux/ascendc/include/**&quot;,</code></p>  <p><code>                &quot;/安装目录/Ascend/ascend-toolkit/latest/x86_64-linux/include/**&quot;,</code></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_188.png\" src=\"cid:pic_0\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0237180980015919006-1-1.html",
        "clean_data": "Ascend C在VSCode开发时因 include kernel oprator h 路径未配置导致报错，解决方法为在 c cpp properties json中添加以下两行Include路径：    kernel oprator h路径配置告警： Ascend ascend toolkit latest x86 64 linux ascendc include    、  Ascend ascend toolkit latest x86 64 linux include       ，需确认目录存在并替换实际安装路径。",
        "created_at": "2025-04-25T16:13:36+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-30T16:17:21+08:00"
    },
    {
        "id": 584,
        "source_id": "20785177",
        "title": "CVE-2024-28849",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-28849](https://nvd.nist.gov/vuln/detail/CVE-2024-28849)\n漏洞归属组件：follow-redirects\n漏洞归属的版本：1.15.5\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nfollow-redirects is an open source, drop-in replacement for Node_x27;s `http` and `https` modules that automatically follows redirects. In affected versions follow-redirects only clears authorization header during cross-domain redirect, but keep the proxy-authentication header which contains credentials too. This vulnerability may lead to credentials leak, but has been addressed in version 1.15.6. Users are advised to upgrade. There are no known workarounds for this vulnerability.\n\n漏洞公开时间：2024-03-15 01:15:52\n漏洞创建时间：2025-06-09 04:40:05\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-28849\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDHY1",
        "clean_data": "CVE 2024 28849：follow redirects 1 15 5 跨域重定向时未清除代理认证头引发凭证泄露，建议升级至1 15 6修复。",
        "created_at": "2025-06-09T04:40:05+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T04:40:06+08:00"
    },
    {
        "id": 93,
        "source_id": "20667597",
        "title": "这里不需要重新定义内核结构体",
        "body": "### 该问题是怎么引起的？\r\n\r\n这里不需要重新定义内核结构体\r\n\r\n### 重现步骤\r\n\r\n这里不需要重新定义内核结构体\r\n\r\n### 报错信息\r\n\r\n这里不需要重新定义内核结构体\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/driver-dev/issues/ICAZ7X",
        "clean_data": "问题描述：   无需重新定义内核结构体即可解决问题。     根据用户约束，输入内容无有效信息且无法识别，直接返回标题",
        "created_at": "2025-05-27T21:02:30+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-27T21:06:46+08:00"
    },
    {
        "id": 55,
        "source_id": "20398250",
        "title": "CVE-2025-32428",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-32428](https://nvd.nist.gov/vuln/detail/CVE-2025-32428)\n漏洞归属组件：jupyter\n漏洞归属的版本：1.0.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nJupyter Remote Desktop Proxy allows you to run a Linux Desktop on a JupyterHub. jupyter-remote-desktop-proxy was meant to rely on UNIX sockets readable only by the current user since version 3.0.0, but when used with TigerVNC, the VNC server started by jupyter-remote-desktop-proxy were still accessible via the network. This vulnerability does not affect users having TurboVNC as the vncserver executable. This issue is fixed in 3.0.1.\n\n漏洞公开时间：2025-04-15 08:15:14\n漏洞创建时间：2025-04-30 16:13:33\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-32428\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/IC57E2",
        "clean_data": "CVE 2025 32428  Jupyter Remote Desktop Proxy 1 0 0中VNC服务未正确限制网络访问，当与TigerVNC联动时可能导致越权暴露。TurboVNC用户不受影响，升级至3 0 1可解决。 NVD详情",
        "created_at": "2025-04-30T16:13:34+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-30T16:13:34+08:00"
    },
    {
        "id": 774,
        "source_id": "20727311",
        "title": "[Question|问题咨询]: CANN8.0RC1，kernel包也装了，为什么有这个报错",
        "body": "### 问题描述\r\n\r\n[W OpCommand.cpp:77] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy2048 (function operator())\r\nEZ3002: 2025-06-03-17:12:34.653.082 Optype [MaxPoolWithArgmaxV1] of Ops kernel [AIcoreEngine] is unsupported. Reason: [tbe-custom]:op type MaxPoolWithArgmaxV1 is not found in this op store.[tbe-custom]:op type MaxPoolWithArgmaxV1 is not found in this op store.[Dynamic shape check]: data type DT_FLOAT of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16}Format:{NC1HWC0}[Static shape check]:data type DT_FLOAT of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16}Format:{NC1HWC0}.\r\n        Possible Cause: The operator type is unsupported in the operator information library due to specification mismatch.\r\n        Solution: Submit an issue to request for support at https://gitee.com/ascend, or remove this type of operators from your model.\r\n        TraceBack (most recent call last):\r\n        No supported Ops kernel and engine are found for [MaxPoolWithArgmaxV1228], optype [MaxPoolWithArgmaxV1].\r\n        Optype [TransData] of Ops kernel [AIcoreEngine] is unsupported. Reason: [tbe-custom]:op type TransData is not found in this op store.[tbe-custom]:op type TransData is not found in this op store.[Dynamic shape check]: The format and dtype is not precisely equivalent to format and dtype in op information library[Static shape check]:The format and dtype is not precisely equivalent to format and dtype in op information library.\r\n        Optype [TransData] of Ops kernel [aicpu_ascend_kernel] is unsupported. Reason: Transdata Op does not have attr group..\r\n        No supported Ops kernel and engine are found for [trans_TransData_322], optype [TransData].\r\n        build graph failed, graph id:227, ret:-1[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1615]\r\n        [Build][SingleOpModel]call ge interface generator.BuildSingleOpModel failed. ge result = 4294967295[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]\r\n        [Build][Op]Fail to build op model[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]\r\n        build op model failed, result = 500002[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]\r\n\r\n\r\n### 所属算子\r\n\r\n其他\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops-adv/issues/ICC9AN",
        "clean_data": "CANN 8 0RC1安装kernel包后算子不支持500002报错     MaxPoolWithArgmaxV1和TransData算子因模型输入数据类型 DT FLOAT 或格式 NC1HWC0 不匹配CANN8 0RC1支持的DT FLOAT16，导致AIcoreEngine无法加载，最终报错500002。需检查模型数据类型是否符合要求，或提交昇腾社区请求算子支持，需附上详细复现信息。",
        "created_at": "2025-06-03T17:24:46+08:00",
        "topic_summary": "昇腾CANN开发者如何解决MaxPoolWithArgmaxV1算子未注册错误",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-10T15:29:28+08:00"
    },
    {
        "id": 151,
        "source_id": "0215171508094586189",
        "title": "Label-Free量化时输入数据无效",
        "body": "<div class=\"cke-article\"><p>我的量化代码如下：</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">def custom_read_data():  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">    calib_data = []  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">    image = cv2.imdecode(np.fromfile(&quot;./data_path/L_rec_1_7_16854.jpg&quot;, dtype=np.float16), 1)   </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">    image = cv2.resize(image, (640, 640), interpolation=cv2.INTER_CUBIC)  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">    image = (torch.from_numpy(image).permute(2, 0, 1) / 255).to(torch.float16)  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">    image = image.unsqueeze(0)  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">    calib_data.append([np.array(image).astype(np.float16)])  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">    return calib_data  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">calib_data = custom_read_data() </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">quant_config = QuantConfig(calib_data = calib_data, amp_num = 5)  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">input_model_path = &quot;./sparseinst.onnx&quot;  </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">output_model_path = &quot;./sparseinst_quant.onnx&quot;   </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">run_quantize(input_model_path,output_model_path,quant_config) </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">我发现了这个警告：</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">WARNING - The 0 data records in calib_data is not valid，WARNING - There is no valid data in calib_data, we will generate data randomly；但是我打印calib_data，是有数值的。 [[tensor([[[[0.4470, 0.4626, 0.4548,  ..., 0.6313, 0.6509, 0.6392],           [0.4548, 0.4431, 0.4626,  ..., 0.6392, 0.6392, 0.6392],           [0.4666, 0.4548, 0.4666,  ..., 0.6274, 0.6353, 0.6313],           ...,           [0.4746, 0.4746, 0.4587,  ..., 0.5767, 0.5845, 0.5884],           [0.4746, 0.4275, 0.4038,  ..., 0.5688, 0.5649, 0.5884],           [0.4275, 0.3921, 0.3137,  ..., 0.5605, 0.5806, 0.5728]],           [[0.4470, 0.4626, 0.4548,  ..., 0.6313, 0.6509, 0.6392],           [0.4548, 0.4431, 0.4626,  ..., 0.6392, 0.6392, 0.6392],           [0.4666, 0.4548, 0.4666,  ..., 0.6274, 0.6353, 0.6313],           ...,           [0.4746, 0.4746, 0.4587,  ..., 0.5767, 0.5845, 0.5884],           [0.4746, 0.4275, 0.4038,  ..., 0.5688, 0.5649, 0.5884],           [0.4275, 0.3921, 0.3137,  ..., 0.5605, 0.5806, 0.5728]],           [[0.4470, 0.4626, 0.4548,  ..., 0.6313, 0.6509, 0.6392],           [0.4548, 0.4431, 0.4626,  ..., 0.6392, 0.6392, 0.6392],           [0.4666, 0.4548, 0.4666,  ..., 0.6274, 0.6353, 0.6313],           ...,           [0.4746, 0.4746, 0.4587,  ..., 0.5767, 0.5845, 0.5884],           [0.4746, 0.4275, 0.4038,  ..., 0.5688, 0.5649, 0.5884],           [0.4275, 0.3921, 0.3137,  ..., 0.5605, 0.5806, 0.5728]]]],        dtype=torch.float16)]] </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">我将calib_data更换为这个：</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">calib_data = [np.random.random(size=(1, 3, 640, 640)).astype(np.float16)]，但是还是说数据无效，请问有效的calib_data是什么样的？</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0215171508094586189-1-1.html",
        "clean_data": "Label Free量化时calib data格式不符合要求。校准数据需为float16类型的numpy数组，且数据元素应为扁平化列表形式 如  np array1  np array2      。用户当前代码返回的是嵌套张量结构，且示例数据存在维度冗余。应去除permute unsqueeze等inference操作，直接输出与模型输入维度匹配的numpy数组列表。",
        "created_at": "2025-01-06T01:08:15+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-08T01:54:33+08:00"
    },
    {
        "id": 71,
        "source_id": "20553038",
        "title": "[Bug-Report|缺陷反馈]: isamin 在Atlas 200I DK A2测试大部分均result error",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\n============test 0=============\r\n0\r\n{'id': 0, 'shape': [1], 'n': 1, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\ntest pass\r\n\r\n#####################################\r\nINFO: you have passed the Precision!\r\n#####################################\r\ncase_0 : 2025-05-17 18:24:51\r\n\r\n============test 1=============\r\n1\r\n{'id': 1, 'shape': [7], 'n': 7, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_1 : 2025-05-17 18:25:01\r\n\r\n============test 2=============\r\n2\r\n{'id': 2, 'shape': [8], 'n': 8, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_2 : 2025-05-17 18:25:12\r\n\r\n============test 3=============\r\n3\r\n{'id': 3, 'shape': [8], 'n': 8, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_3 : 2025-05-17 18:25:23\r\n\r\n============test 4=============\r\n4\r\n{'id': 4, 'shape': [9], 'n': 9, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\ntest pass\r\n\r\n#####################################\r\nINFO: you have passed the Precision!\r\n#####################################\r\ncase_4 : 2025-05-17 18:25:34\r\n\r\n============test 5=============\r\n5\r\n{'id': 5, 'shape': [9], 'n': 9, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_5 : 2025-05-17 18:25:44\r\n\r\n============test 6=============\r\n6\r\n{'id': 6, 'shape': [9], 'n': 9, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_6 : 2025-05-17 18:25:55\r\n\r\n============test 7=============\r\n7\r\n{'id': 7, 'shape': [9], 'n': 9, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_7 : 2025-05-17 18:26:06\r\n\r\n============test 8=============\r\n8\r\n{'id': 8, 'shape': [9], 'n': 9, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_8 : 2025-05-17 18:26:16\r\n\r\n============test 9=============\r\n9\r\n{'id': 9, 'shape': [15], 'n': 15, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_9 : 2025-05-17 18:26:27\r\n\r\n============test 10=============\r\n10\r\n{'id': 10, 'shape': [15], 'n': 15, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_10 : 2025-05-17 18:26:37\r\n\r\n============test 11=============\r\n11\r\n{'id': 11, 'shape': [15], 'n': 15, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\ntest pass\r\n\r\n#####################################\r\nINFO: you have passed the Precision!\r\n#####################################\r\ncase_11 : 2025-05-17 18:26:48\r\n\r\n============test 12=============\r\n12\r\n{'id': 12, 'shape': [15], 'n': 15, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_12 : 2025-05-17 18:26:58\r\n\r\n============test 13=============\r\n13\r\n{'id': 13, 'shape': [15], 'n': 15, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_13 : 2025-05-17 18:27:09\r\n\r\n============test 14=============\r\n14\r\n{'id': 14, 'shape': [16], 'n': 16, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_14 : 2025-05-17 18:27:20\r\n\r\n============test 15=============\r\n15\r\n{'id': 15, 'shape': [16], 'n': 16, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_15 : 2025-05-17 18:27:30\r\n\r\n============test 16=============\r\n16\r\n{'id': 16, 'shape': [16], 'n': 16, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_16 : 2025-05-17 18:27:41\r\n\r\n============test 17=============\r\n17\r\n{'id': 17, 'shape': [16], 'n': 16, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_17 : 2025-05-17 18:27:52\r\n\r\n============test 18=============\r\n18\r\n{'id': 18, 'shape': [17], 'n': 17, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_18 : 2025-05-17 18:28:02\r\n\r\n============test 19=============\r\n19\r\n{'id': 19, 'shape': [17], 'n': 17, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_19 : 2025-05-17 18:28:13\r\n\r\n============test 20=============\r\n20\r\n{'id': 20, 'shape': [17], 'n': 17, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_20 : 2025-05-17 18:28:24\r\n\r\n============test 21=============\r\n21\r\n{'id': 21, 'shape': [19], 'n': 19, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_21 : 2025-05-17 18:28:34\r\n\r\n============test 22=============\r\n22\r\n{'id': 22, 'shape': [19], 'n': 19, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_22 : 2025-05-17 18:28:45\r\n\r\n============test 23=============\r\n23\r\n{'id': 23, 'shape': [19], 'n': 19, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_23 : 2025-05-17 18:28:56\r\n\r\n============test 24=============\r\n24\r\n{'id': 24, 'shape': [20], 'n': 20, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_24 : 2025-05-17 18:29:06\r\n\r\n============test 25=============\r\n25\r\n{'id': 25, 'shape': [20], 'n': 20, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_25 : 2025-05-17 18:29:17\r\n\r\n============test 26=============\r\n26\r\n{'id': 26, 'shape': [20], 'n': 20, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_26 : 2025-05-17 18:29:27\r\n\r\n============test 27=============\r\n27\r\n{'id': 27, 'shape': [21], 'n': 21, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_27 : 2025-05-17 18:29:38\r\n\r\n============test 28=============\r\n28\r\n{'id': 28, 'shape': [21], 'n': 21, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_28 : 2025-05-17 18:29:48\r\n\r\n============test 29=============\r\n29\r\n{'id': 29, 'shape': [21], 'n': 21, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_29 : 2025-05-17 18:29:59\r\n\r\n============test 30=============\r\n30\r\n{'id': 30, 'shape': [256], 'n': 256, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_30 : 2025-05-17 18:30:09\r\n\r\n============test 31=============\r\n31\r\n{'id': 31, 'shape': [256], 'n': 256, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_31 : 2025-05-17 18:30:20\r\n\r\n============test 32=============\r\n32\r\n{'id': 32, 'shape': [256], 'n': 256, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_32 : 2025-05-17 18:30:30\r\n\r\n============test 33=============\r\n33\r\n{'id': 33, 'shape': [256], 'n': 256, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_33 : 2025-05-17 18:30:41\r\n\r\n============test 34=============\r\n34\r\n{'id': 34, 'shape': [257], 'n': 257, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_34 : 2025-05-17 18:30:51\r\n\r\n============test 35=============\r\n35\r\n{'id': 35, 'shape': [44980], 'n': 44980, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_35 : 2025-05-17 18:31:02\r\n\r\n============test 36=============\r\n36\r\n{'id': 36, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_36 : 2025-05-17 18:31:12\r\n\r\n============test 37=============\r\n37\r\n{'id': 37, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_37 : 2025-05-17 18:31:23\r\n\r\n============test 38=============\r\n38\r\n{'id': 38, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_38 : 2025-05-17 18:31:34\r\n\r\n============test 39=============\r\n39\r\n{'id': 39, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_39 : 2025-05-17 18:31:44\r\n\r\n============test 40=============\r\n40\r\n{'id': 40, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_40 : 2025-05-17 18:31:55\r\n\r\n============test 41=============\r\n41\r\n{'id': 41, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_41 : 2025-05-17 18:32:05\r\n\r\n============test 42=============\r\n42\r\n{'id': 42, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_42 : 2025-05-17 18:32:16\r\n\r\n============test 43=============\r\n43\r\n{'id': 43, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_43 : 2025-05-17 18:32:26\r\n\r\n============test 44=============\r\n44\r\n{'id': 44, 'shape': [131073], 'n': 131073, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_44 : 2025-05-17 18:32:37\r\n\r\n============test 45=============\r\n45\r\n{'id': 45, 'shape': [10142617], 'n': 10142617, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_45 : 2025-05-17 18:32:49\r\n\r\n============test 46=============\r\n46\r\n{'id': 46, 'shape': [64328047], 'n': 64328047, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\ncase_46 : 2025-05-17 18:33:11\r\n\r\n============test 47=============\r\n47\r\n{'id': 47, 'shape': [91789870], 'n': 91789870, 'incx': 1, 'dtype': 'fp32'}\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\nERROR: run case 47 timeout !\r\ncase_47 2025-05-17 18:33:48\r\n\r\n============test 48=============\r\n48\r\n{'id': 48, 'shape': [641830796], 'n': 641830796, 'incx': 1, 'dtype': 'fp32'}\r\nrun_all.sh: line 67: 35227 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\nrun_all.sh: line 67: 35277 Killed                  timeout 15 ./execute_isamin_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/isamin/AclNNInvocation_test50/verify_result.py\", line 34, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/isamin/AclNNInvocation_test50/verify_result.py\", line 19, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=np.int32) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_48 : 2025-05-17 18:34:15\r\n\r\n============test 49=============\r\n49\r\n{'id': 49, 'shape': [2147483648], 'n': 2147483648, 'incx': 1, 'dtype': 'fp32'}\r\nrun_all.sh: line 67: 35694 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\nrun_all.sh: line 67: 35778 Killed                  timeout 15 ./execute_isamin_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/isamin/AclNNInvocation_test50/verify_result.py\", line 34, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/isamin/AclNNInvocation_test50/verify_result.py\", line 19, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=np.int32) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_49 : 2025-05-17 18:35:57\r\n\r\nEnd Time 2025-05-17 18:35:57\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\nAtlas 200I DK A2\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n算子增加.AddConfig后在Atlas 200I DK A2测试；\r\n仅保留src中common以及isamin算子目录，其余算子目录均删除。\r\n\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\n测试应通过\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\n![输入图片说明](https://foruda.gitee.com/images/1747478440163602076/f96ad79c_8397253.png \"屏幕截图\")\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/IC8ITQ",
        "clean_data": "isamin算子在Atlas 200I DK A2硬件上执行时，超过半数测试用例 约47 50 出现result error且输入维度与设备资源限制相关。主要特征：低维输入 shape 1 9 16 通过测试，中高维输入 shape 8 21 256 131073等 均报错，极端案例 shape 1e8 触发内存溢出 Killed ；该问题在新增AddConfig配置并精简算子目录 仅保留common和isamin 的复现环境中发生。",
        "created_at": "2025-05-17T18:40:43+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-17T18:40:43+08:00"
    },
    {
        "id": 167,
        "source_id": "0292180173354821047",
        "title": "香橙派报错：Numpy没有float属性的解决方法",
        "body": "<div class=\"cke-article\"><p>在香橙派中执行Python代码时，可能报错：module 'numpy' has no attribute 'float'，如下图所示：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1310.png\" src=\"cid:pic_0\" style=\"width: 709.0px;height: 192.0px;\"></span></p>  <p>这是因为np.float从版本1.24起被删除，但是这个项目里的代码是基于旧版本的Numpy编写的，而香橙派上安装的Numpy版本较新。 </p>  <p>一种解决方法是将本机的Numpy降级到老版本，比如1.23.5，因此下面使用pip安装指定老版本的Numpy，如下图所示。 </p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_2408.png\" src=\"cid:pic_1\" style=\"width: 711.0px;height: 414.0px;\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0292180173354821047-1-1.html",
        "clean_data": "标题关联的简洁描述：香橙派Numpy版本升级后缺少np float属性，需将安装版本降级至1 23 5 np float在1 24 版本被移除 。",
        "created_at": "2025-04-16T08:09:15+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-16T08:09:15+08:00"
    },
    {
        "id": 155,
        "source_id": "02115184411602353049",
        "title": "算子demo下 cpu模式指的是什么，以及运行时的打印问题",
        "body": "<div class=\"cke-article\"><p>cpu模式指的是在本地x86上位机（无昇腾npu）进行调试么？<br> 那指令选用cpu时，后面芯片设置什么，不同设置会导致输出不一样，如下：<br> 1、bash run.sh -r cpu -v Ascend310P3</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_4288.png\" src=\"cid:pic_0\"></span></p>  <p>2、bash run.sh -r cpu -v Ascend310B4</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_7994.png\" src=\"cid:pic_1\"></span></p>  <p>这个error有什么说法没有，还是说可以忽略不计</p></div>",
        "url": "https://www.hiascend.com/forum/thread-02115184411602353049-1-1.html",
        "clean_data": "标题：算子demo中cpu模式定义与运行打印error关联   内容：cpu模式指在x86上位机 无昇腾NPU 执行调试，不依赖硬件。运行时不同芯片版本参数  v Ascend310P3 B4 导致结果差异及出现error原因？",
        "created_at": "2025-06-04T09:26:42+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T11:44:13+08:00"
    },
    {
        "id": 50,
        "source_id": "20374152",
        "title": "算子使能到模型后性能降低",
        "body": "一、问题现象：\n算子使能到模型后,模型性能降低。\n- 问题1：当前算子是否在模型中有加速效果。\n- 问题2：如何在模型中进行加速（给出的用例的方法是否可取）。\n- 问题3：在模型层面 如何 无感 进行算子替换？\n\n性能数据信息：https://gitee.com/ascend-operator/traces/tree/master/\n\n\n二、软件版本:\n- CANN 版本:  \n  8.1.RC1.alpha001\n- Pytorch版本:\n  torch                        2.1.0\n  torch_act                    0.1.0.20250428155022\n  torch-npu                    2.1.0.post10\n- Python 版本:\n  Python 3.10.16\n- 操作系统版本:\n  容器 Ubuntu 22.04.4 LTS\n\n三、测试步骤：\n- 编译：bash scripts/build.sh python_extension  ,  安装  pip install   output/python_extension/torch_act-*whl\n- 编写测试脚本：\n\n```\nimport torch_npu\nimport torch\nimport torch_act\nfrom torch import nn\n\nM = 27\nK = 7168\nN = 1536\n\ndef mm_liner(A):\n    mm_test = nn.Linear(K, N, bias=False).npu()\n    mm_test(A)\n\nif __name__ == \"__main__\":\n    # 使用 torch.ops.Act...的方式测试时，加载so\n    # torch.ops.load_library(\"/path/ascendc-templates/output/python_extension/libact_torch.so\")\n    # 生成测试数据\n    a = torch.randn((M, K)).to(torch.bfloat16).npu()\n    \n    # 测试\n    prof = torch_npu.profiler.profile(\n        activities=[\n            torch_npu.profiler.ProfilerActivity.CPU,\n            torch_npu.profiler.ProfilerActivity.NPU\n        ],\n        schedule=torch_npu.profiler.schedule(wait=1, warmup=1, active=1, repeat=1, skip_first=1),\n        on_trace_ready=torch_npu.profiler.tensorboard_trace_handler(\"./result\"),\n        with_stack=True,\n        record_shapes=True,\n        profile_memory=False,\n        with_modules=False,\n        with_flops=False,\n    )\n    prof.start()\n    for step in range(5):\n        mm_liner(a)\n        prof.step()\n    prof.stop()\n\n```\n> 测试说明：\n>- 1：首先使用原生 torch 接口进行测试，得到性能数据1\n>- 2： 修改 lib/python3.10/site-packages/torch/nn/modules/linear.py（约115行） 中 return F.linear(input, self.weight, self.bias) 为 return torch_act.basic_matmul(input, self.weight.T.contiguous(), \"bf16\") 得到性能数据2\n>- 3：脚本加载so，修改 linear.py 中 return F.linear(input, self.weight, self.bias) 为 return torch.ops.ActTorch.basic_matmul(input, self.weight.T.contiguous(), \"bf16\") 得到性能数据3\n\n\n- 结果\n   - 原生torch接口性能最佳，torch_act 与 torch.ops.Act.. 性能较差\n\n",
        "url": "https://gitee.com/ascend/catlass/issues/IC4OSO",
        "clean_data": "问题：     自定义算子使能到模型后性能低于原生Torch接口，且用  torch act  直接调用和  torch ops  加载  so 的性能均不佳，需明确算子是否存在加速效果及正确替换方法。    关键点：     1    算子加速效果  ：需验证自定义算子是否优化了硬件指令或内存访问 如是否利用NPU特性 。 2    低效调用原因  ： torch act  与  torch ops  两种方式未显著提升性能，可能因算子实现未适配计算图优化或执行流水。 3    无感替换方案  ：模型层面需通过工具 如ATC转换、ONNX插件注册等 而非直接修改源码实现算子替换。",
        "created_at": "2025-04-28T17:04:50+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-08T15:15:24+08:00"
    },
    {
        "id": 48,
        "source_id": "20336747",
        "title": "map.emplace可以直接传入pair的构造参数(next_session_id, userGraphsManagerPtr)，能少一次拷贝",
        "body": "map.emplace可以直接传入pair的构造参数(next_session_id, userGraphsManagerPtr)，能少一次拷贝\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IC3VXN",
        "clean_data": "map emplace插入参数直接转发构造pair构造函数，需注意参数须支持移动语义  该标题指出了C  中map emplace的高效用法，核心要点为：通过将参数 next session id  userGraphsManagerPtr 直接转发给pair构造函数，可避免隐式拷贝构造。但需注意两个关键点：1  参数类型必须显式支持移动构造或右值转移 如unique ptr需处理生命周期 ；2  参数顺序应与pair的构造顺序完全匹配 first和second 。若userGraphsManagerPtr是裸指针或无状态对象，可直接构造；若涉及复杂对象则建议传入右值引用。   注：根据约束条件直接关联标题内容",
        "created_at": "2025-04-25T11:50:20+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-25T11:50:20+08:00"
    },
    {
        "id": 86,
        "source_id": "20648853",
        "title": "MakeTensorPtrCanonicalizer 补齐功能：支持 User 为 Atomic 类 Op",
        "body": "",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICAKR9",
        "clean_data": "问题描述：当前MakeTensorPtrCanonicalizer的补齐功能不支持User为Atomic类Op，导致补足时出错。需确认底层机制兼容性及如何适配原子操作类型。",
        "created_at": "2025-05-26T15:56:18+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T16:01:47+08:00"
    },
    {
        "id": 585,
        "source_id": "20785178",
        "title": "CVE-2024-27351",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-27351](https://nvd.nist.gov/vuln/detail/CVE-2024-27351)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn Django 3.2 before 3.2.25, 4.2 before 4.2.11, and 5.0 before 5.0.3, the django.utils.text.Truncator.words() method (with html=True) and the truncatewords_html template filter are subject to a potential regular expression denial-of-service attack via a crafted string. NOTE: this issue exists because of an incomplete fix for CVE-2019-14232 and CVE-2023-43665.\n\n漏洞公开时间：2024-03-16 04:15:09\n漏洞创建时间：2025-06-09 04:40:08\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-27351\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDHY2",
        "clean_data": "修复建议  ：CVE 2024 27351漏洞由Django 3 2 7 4 2 11 5 0 3前版本的 django utils text Truncator words    含 html True 参数 和 truncatewords html 模板过滤器存在ReDoS风险导致，触发方式为构造特殊字符串。原因为针对CVE 2019 14232和CVE 2023 43665的修复不完整，需升级至上述版本对应的修复后版本。",
        "created_at": "2025-06-09T04:40:09+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T04:40:09+08:00"
    },
    {
        "id": 60,
        "source_id": "20435257",
        "title": "优化 PpMatmulEinSumKernel 算子性能",
        "body": "该场景下（deepseek-r1），cube利用率较低，需要优化\r\n\r\nPpMatmulEinSumKernel,\r\nInput Shapes：\"1,8,512;8,512,128\" FLOAT16;FLOAT16\r\nOutput Shape：\"1,8,128\" FLOAT16\r\ncube_utilization(%)：24%",
        "url": "https://gitee.com/ascend/ascend-transformer-boost/issues/IC5ZY1",
        "clean_data": "Deepseek R1模型中PpMatmulEinSumKernel算子cube利用率不足24 ，需通过调整输入 1 8 512   8 512 128 与输出 1 8 128 的计算模式优化。请问如何提升cube利用率、是否存在中间维度合并 tiling策略待调整？",
        "created_at": "2025-05-07T15:07:14+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-07T15:07:14+08:00"
    },
    {
        "id": 56,
        "source_id": "20418514",
        "title": "右矩阵转置后计算错误",
        "body": "一、问题现象（附报错日志上下文）：\n将右矩阵进行转置操作后进行计算，计算结果与原 torch 不一致，计算错误\n\n\n二、软件版本:\n- CANN 版本:  \nCANN 8.1.RC1.alpha001\n- Pytorch 版本:\ntorch                        2.1.0\ntorch_act                    0.1.0.20250506102930\ntorch-npu                    2.1.0.post10\n- Python 版本:\nPython 3.10.16\n- 操作系统版本:\n容器：Ubuntu 22.04.4 LTS\n\n三、测试步骤：\n\n- 编译 & 安装 whl 包\n  bash scripts/build.sh python_extension\n  pip install output/python_extension/torch_act-0.1.0.20250506102930-cp310-cp310-linux_aarch64.whl\n\n- 使用以下代码进行测试：\n \n```python\nimport torch_npu\nimport torch_act\nimport torch\n\na = torch.tensor([[1,2,3],[1,2,3]], device=\"npu:0\", dtype=torch.float16)\nb = torch.tensor([[1,1,1],[2,2,2]], device=\"npu:0\", dtype=torch.float16)\n\norg = torch.mm(a, b.T)\nact = torch_act.basic_matmul(a, b.T, \"float16\")\n\nprint(\"org: \", org)\nprint(\"act: \", act)\n\n\n# 结果：\n'''\n预期结果：\n[[6, 12],\n[6, 12]]\n\n测试结果原生torch 计算正确，act计算错误。\norg:  tensor([[ 6., 12.],\n        [ 6., 12.]], device='npu:0', dtype=torch.float16)\nact:  tensor([[ 9., 11.],\n        [ 9., 11.]], device='npu:0', dtype=torch.float16)\n'''\n```\n\n\n",
        "url": "https://gitee.com/ascend/catlass/issues/IC5N0Y",
        "clean_data": "右矩阵转置后计算错误：在CANN 8 1 RC1 alpha001版本中，当使用torch act进行矩阵乘法计算时，若右矩阵经过 T转置操作，实际输出结果与原生torch不一致。配置环境为torch 2 1 0   torch act 0 1 0 20250506102930，测试代码显示相同形态张量输入下，原生接口输出  6 12   6 12  正确，而自定义算子输出  9 11   9 11  错误。问题可能出在转置张量的数据布局处理及自定义算子的内存对齐机制差异。建议检查转置操作是否导致张量strides与底层算子预期不匹配，并确认basic matmul实现是否完全覆盖T转置场景的计算路径。",
        "created_at": "2025-05-06T11:58:29+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T15:39:02+08:00"
    },
    {
        "id": 587,
        "source_id": "20785873",
        "title": "CVE-2023-45857",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-45857](https://nvd.nist.gov/vuln/detail/CVE-2023-45857)\n漏洞归属组件：axios\n漏洞归属的版本：1.5.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nAn issue discovered in Axios 1.5.1 inadvertently reveals the confidential XSRF-TOKEN stored in cookies by including it in the HTTP header X-XSRF-TOKEN for every request made to any host allowing attackers to view sensitive information.\n\n漏洞公开时间：2023-11-09 05:15:08\n漏洞创建时间：2025-06-09 09:10:48\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-45857\n",
        "url": "https://gitee.com/ascend/Asight/issues/ICDIHD",
        "clean_data": "CVE 2023 45857：Axios 1 5 1版本将敏感XSRF TOKEN泄露至HTTP请求头  详细说明： 该漏洞由Axios 1 5 1在请求处理时无意将Cookie中的XSRF TOKEN添加至所有请求的X XSRF TOKEN头部字段，导致攻击者可通过该头部获取敏感信息。完整技术细节请参考 NIST漏洞数据库  https   nvd nist gov vuln detail CVE 2023 45857",
        "created_at": "2025-06-09T09:10:48+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:10:49+08:00"
    },
    {
        "id": 7,
        "source_id": "19193587",
        "title": "【Lowering】Lowering报错，All auto fused ge nodes should on the same graph",
        "body": "一、问题现象（附报错日志上下文）：\r\nxxxx\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\n933566 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.517 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:313]1088971 BuildNodeScheduleAndViewInfos:Set schedule info to node {mul_1       91_5481 Mul}, axis: [0, 1] successfully, while ascgraph schedule axis: [0, 1]\r\n933567 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.525 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:460]1088971 BuildTensorViewInfoByCb:Set output views info to node {add_24_       5479 Add}, axis: [0, 1], repeat: [128, 1], stride: [1, 1]\r\n933568 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.533 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:59]1088971 UpdateInputsAttrsByPeerOut:Set input views info to node {add_24       _5479 Add}, axis: [0, 1], repeat: [128, 1], stride: [1, 1] by peer node {mul_190_5480 Mul} successfully\r\n933569 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.541 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:59]1088971 UpdateInputsAttrsByPeerOut:Set input views info to node {add_24       _5479 Add}, axis: [0, 1], repeat: [128, 1], stride: [1, 1] by peer node {mul_191_5481 Mul} successfully\r\n933570 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.546 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:313]1088971 BuildNodeScheduleAndViewInfos:Set schedule info to node {add_2       4_5479 Add}, axis: [0, 1] successfully, while ascgraph schedule axis: [0, 1]\r\n933571 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.553 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:59]1088971 UpdateInputsAttrsByPeerOut:Set input views info to node {Store_       5528 Store}, axis: [0, 1], repeat: [128, 1], stride: [1, 1] by peer node {add_24_5479 Add} successfully\r\n933572 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.558 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:313]1088971 BuildNodeScheduleAndViewInfos:Set schedule info to node {Store       _5528 Store}, axis: [0, 1] successfully, while ascgraph schedule axis: [0, 1]\r\n933573 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.563 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:162]1088971 BuildGraphAxisAttr:Add graph (fused_graph_481) axis info:, axi       s name(s0), axis id(0), axis size(128).\r\n933574 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.572 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:162]1088971 BuildGraphAxisAttr:Add graph (fused_graph_481) axis info:, axi       s name(s1), axis id(1), axis size(1).\r\n933575 [INFO] GE(1088479,python3):2025-01-02-22:08:08.271.577 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_asc_graph_builder.cc:181]1088971 BuildAscGraph:Build graph fused_graph_481 successfully\r\n933576 [WARNING] GE(1088479,python3):2025-01-02-22:08:08.271.647 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3838]1088971 MergeNetOutputNode:SubGraph: decomposed_sigmoid_69_3/Sigmoid NetOutput input tensor 0, attr _pare       nt_node_index not found, use anchor index 0.\r\n933577 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.656 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3860]1088971 MergeNetOutputNode:[Div_29] process in node.\r\n933578 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.660 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3704]1088971 UnfoldGraph:[decomposed_sigmoid_69_3/Sigmoid] Merging graph inputs and outputs successfully\r\n933579 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.664 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_69_3/Sigmoid::Neg_24] added to target graph: [ge_default_2025010222       0722].\r\n933580 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.667 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_69_3/Sigmoid::Exp_25] added to target graph: [ge_default_2025010222       0722].\r\n933581 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.671 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_69_3/Sigmoid::Const26] added to target graph: [ge_default_202501022       20722].\r\n933582 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.675 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_69_3/Sigmoid::Cast_27] added to target graph: [ge_default_202501022       20722].\r\n933583 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.678 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_69_3/Sigmoid::Add_28] added to target graph: [ge_default_2025010222       0722].\r\n933584 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.681 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_69_3/Sigmoid::Div_29] added to target graph: [ge_default_2025010222       0722].\r\n933585 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.685 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3735]1088971 UnfoldGraph:[decomposed_sigmoid_69_3/Sigmoid] Done merging graph. remove it from root graph\r\n933586 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.689 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:337]1088971 RemoveSubgraphRecursively:Node sigmoid_69_3/Sigmoid has no subgraph.\r\n933587 [WARNING] GE(1088479,python3):2025-01-02-22:08:08.271.715 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3838]1088971 MergeNetOutputNode:SubGraph: decomposed_sigmoid_68_3/Sigmoid NetOutput input tensor 0, attr _pare       nt_node_index not found, use anchor index 0.\r\n933588 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.723 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3860]1088971 MergeNetOutputNode:[Div_53] process in node.\r\n933589 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.726 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3704]1088971 UnfoldGraph:[decomposed_sigmoid_68_3/Sigmoid] Merging graph inputs and outputs successfully\r\n933590 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.729 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_68_3/Sigmoid::Neg_48] added to target graph: [ge_default_2025010222       0722].\r\n933591 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.736 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_68_3/Sigmoid::Exp_49] added to target graph: [ge_default_2025010222       0722].\r\n933592 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.741 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_68_3/Sigmoid::Const50] added to target graph: [ge_default_202501022       20722].\r\n933593 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.745 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_68_3/Sigmoid::Cast_51] added to target graph: [ge_default_202501022       20722].\r\n933594 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.747 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_68_3/Sigmoid::Add_52] added to target graph: [ge_default_2025010222       0722].\r\n933595 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.751 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3730]1088971 UnfoldGraph:[decomposed_sigmoid_68_3/Sigmoid::Div_53] added to target graph: [ge_default_2025010222       0722].\r\n933596 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.754 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:3735]1088971 UnfoldGraph:[decomposed_sigmoid_68_3/Sigmoid] Done merging graph. remove it from root graph\r\n933597 [DEBUG] GE(1088479,python3):2025-01-02-22:08:08.271.757 [/data03/tf_test/hanshufa/ascgen-dev/base/metadef/graph/utils/graph_utils.cc:337]1088971 RemoveSubgraphRecursively:Node sigmoid_68_3/Sigmoid has no subgraph.\r\n933598 [INFO] GE(1088479,python3):2025-01-02-22:08:08.271.874 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933599 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.271.930 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/decomposed_graph_unfolder.h:49]1088971 SetWorkGeGraph: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]All au       to fused ge nodes should on the same graph\r\n933600 [INFO] GE(1088479,python3):2025-01-02-22:08:08.271.943 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933601 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.271.952 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/decomposed_graph_unfolder.h:39]1088971 UnfoldAllUpwards: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Asse       rt (SetWorkGeGraph(tmp_ge_graph)) failed\r\n933602 [INFO] GE(1088479,python3):2025-01-02-22:08:08.271.959 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933603 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.271.965 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_utils.cc:322]1088971 ApplyToGeGraph: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((work_g       e_graph) != nullptr) failed\r\n933604 [INFO] GE(1088479,python3):2025-01-02-22:08:08.271.972 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933605 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.271.978 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_utils.cc:362]1088971 Realize: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((ApplyToGeGrap       h(asc_graph, builder)) == ge::SUCCESS) failed\r\n933606 [INFO] GE(1088479,python3):2025-01-02-22:08:08.272.096 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933607 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.272.106 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/asc_ir_lowerer.cc:228]1088971 LoweringOneNode: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((Lower       ingUtils::Realize(*attr->inner_attrs.output_compute_buffers.at(anchor->GetIdx()))) == ge::SUCCESS) failed\r\n\r\n933599 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.271.930 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/decomposed_graph_unfolder.h:49]1088971 SetWorkGeGraph: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]All au       to fused ge nodes should on the same graph\r\n933600 [INFO] GE(1088479,python3):2025-01-02-22:08:08.271.943 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933601 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.271.952 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/decomposed_graph_unfolder.h:39]1088971 UnfoldAllUpwards: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Asse       rt (SetWorkGeGraph(tmp_ge_graph)) failed\r\n933602 [INFO] GE(1088479,python3):2025-01-02-22:08:08.271.959 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933603 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.271.965 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_utils.cc:322]1088971 ApplyToGeGraph: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((work_g       e_graph) != nullptr) failed\r\n933604 [INFO] GE(1088479,python3):2025-01-02-22:08:08.271.972 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933605 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.271.978 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/lowering_utils.cc:362]1088971 Realize: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((ApplyToGeGrap       h(asc_graph, builder)) == ge::SUCCESS) failed\r\n933606 [INFO] GE(1088479,python3):2025-01-02-22:08:08.272.096 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933607 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.272.106 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/asc_ir_lowerer.cc:228]1088971 LoweringOneNode: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((Lower       ingUtils::Realize(*attr->inner_attrs.output_compute_buffers.at(anchor->GetIdx()))) == ge::SUCCESS) failed\r\n933608 [INFO] GE(1088479,python3):2025-01-02-22:08:08.272.118 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933609 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.272.128 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/lowering/asc_ir_lowerer.cc:189]1088971 Lowering: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((LoweringOneN       ode(node, nullptr)) == ge::SUCCESS) failed\r\n933610 [INFO] GE(1088479,python3):2025-01-02-22:08:08.275.918 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933611 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.275.940 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/optimize/autofuse/autofuser.cc:100]1088971 Fuse: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((lowerer_.Lowering(graph)) == g       e::SUCCESS) failed\r\n933612 [INFO] GE(1088479,python3):2025-01-02-22:08:08.275.949 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933613 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.275.955 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/passes/feature/auto_fuse_pass.cc:18]1088971 Run: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Assert ((auto_fuser.Fuse(graph)) == ge:       :SUCCESS) failed\r\n933614 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.275.963 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/passes/pass_manager.cc:53]1088971 Run: ErrorNo: 1343225857(Parameter invalid!) [COMP][PRE_OPT][Pass][Run] failed on graph ge_defaul       t_20250102220722\r\n933615 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.275.970 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/manager/graph_manager.cc:892]1088971 PreRunOptimizeOriginalGraph: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]\r\n933616 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.275.978 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/manager/graph_manager.cc:3821]1088971 OptimizeGraph: ErrorNo: 1343225857(Parameter invalid!) [COMP][PRE_OPT][Run][PreRunOptimizeOri       ginalGraph] failed for graph:ge_default_20250102220722, session_id:0\r\n933617 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.275.985 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/pne/model/pne_model_builder.cc:120]1088971 OptimizeGraph: ErrorNo: 4294967295(failed) [COMP][PRE_OPT][Optimize][Graph] failed, graph = ge       _default_20250102220722, engine = NPU\r\n933618 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.276.022 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/manager/graph_manager.cc:1088]1088971 PreRun: ErrorNo: 4294967295(failed) [COMP][PRE_OPT][Build][Model] failed, session_id:0, graph       _id:1.\r\n933619 [INFO] GE(1088479,python3):2025-01-02-22:08:08.276.033 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/manager/util/rt_context_util.cc:85]1088971 DestroyRtContexts:Destroy 2 rts contexts for graph 1 of session 0.\r\n933620 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.276.052 [stream_state_callback_manager.cc:35] 1088971 Notify: notify stream:1408.\r\n933621 [WARNING] RUNTIME(1088479,python3):2025-01-02-22:08:08.276.060 [stream_state_callback_manager.cc:45] 1088971 Notify: not reg stream state callback func!\r\n933622 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.276.068 [stream_sqcq_manage.cc:493] 1088971 DelStreamIdToStream: stream_id=1408.\r\n933623 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.276.084 [stream_sqcq_manage.cc:453] 1088971 FreeLogicCq: Return(0), threadIdentifier(140271585048320), devId(64), tsId(0), cqId(1), isFastCq(0).\r\n933624 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.276.091 [stream.cc:233] 1088971 FreeStreamId: Free stream_id=1408.\r\n933625 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.276.097 [stream_sqcq_manage.cc:189] 1088971 DeAllocStreamSqCq: streamIdToSqIdMap remove:stream_id=1408, sq_id=0, cq_id=0.\r\n933626 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.276.100 [stream_sqcq_manage.cc:233] 1088971 DeAllocStreamSqCq: [SqCqManage]end to release sq, sq is also reuse, sq_id=0, cq_id=0, stream_id=1408, is_sq_need_release=0, drv_flag=0x1.\r\n933627 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.717 [stream_state_callback_manager.cc:35] 1088971 Notify: notify stream:960.\r\n933628 [WARNING] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.733 [stream_state_callback_manager.cc:45] 1088971 Notify: not reg stream state callback func!\r\n933629 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.738 [stream_sqcq_manage.cc:493] 1088971 DelStreamIdToStream: stream_id=960.\r\n933630 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.743 [stream_sqcq_manage.cc:453] 1088971 FreeLogicCq: Return(0), threadIdentifier(140271585048320), devId(64), tsId(0), cqId(1), isFastCq(0).\r\n933631 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.748 [stream.cc:233] 1088971 FreeStreamId: Free stream_id=960.\r\n933632 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.753 [stream_sqcq_manage.cc:189] 1088971 DeAllocStreamSqCq: streamIdToSqIdMap remove:stream_id=960, sq_id=0, cq_id=0.\r\n933633 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.756 [stream_sqcq_manage.cc:233] 1088971 DeAllocStreamSqCq: [SqCqManage]end to release sq, sq is also reuse, sq_id=0, cq_id=0, stream_id=960, is_sq_need_release=0, drv_flag=0x1.\r\n933634 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.918 [device_state_callback_manager.cc:37] 1088971 Notify: stub device is no need callback.\r\n933635 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.278.925 [runtime.cc:4067] 1088971 DeviceRelease: device_id=64 stop profiling\r\n933636 [INFO] ATRACE(1088479,python3):2025-01-02-22:08:08.278.932 [atrace_client_core.c:175](tid:1088971) devId[64] no need to stop a thread.\r\n933637 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.279.413 [stream_sqcq_manage.cc:493] 1088971 DelStreamIdToStream: stream_id=512.\r\n933638 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.279.427 [stream_sqcq_manage.cc:453] 1088971 FreeLogicCq: Return(0), threadIdentifier(140271585048320), devId(64), tsId(0), cqId(1), isFastCq(0).\r\n933639 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.279.431 [stream.cc:233] 1088971 FreeStreamId: Free stream_id=512.\r\n933640 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.279.435 [stream_sqcq_manage.cc:189] 1088971 DeAllocStreamSqCq: streamIdToSqIdMap remove:stream_id=512, sq_id=0, cq_id=0.\r\n933641 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.279.439 [stream_sqcq_manage.cc:230] 1088971 DeAllocStreamSqCq: [SqCqManage]success to release sq, sq_id=0, cq_id=0, stream_id=512, is_sq_need_release=1, drvFlag=0.\r\n933642 [DEBUG] RUNTIME(1088479,python3):2025-01-02-22:08:08.279.539 [memory_pool_manager.cc:26] 1088971 ~MemoryPoolManager: ~MemoryPoolManager release device memory, size=1.\r\n933643 [INFO] RUNTIME(1088479,python3):2025-01-02-22:08:08.279.549 [raw_device.cc:120] 1088971 ~Device: deconstruct device\r\n933644 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.279.599 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/manager/graph_manager.cc:1145]1088971 StartForRunGraph: ErrorNo: 1343225857(Parameter invalid!) [COMP][PRE_OPT][Call][PreRun] Faile       d, graph_id:1, session_id:0.\r\n933645 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.279.607 [/data03/tf_test/zhanjun/cann-graph-engine/compiler/graph/manager/graph_manager.cc:1742]1088971 BuildGraph: ErrorNo: 1343225857(Parameter invalid!) [COMP][PRE_OPT][Call][StartForRunGraph] f       ailed! graph_id:1.\r\n933646 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.279.626 [inner_session.cc:832]1088971 BuildGraph: ErrorNo: 1343225857(Parameter invalid!) [COMP][PRE_OPT][Build][Graph] failed, InnerSession:0 graph_id=1.\r\n933647 [INFO] GE(1088479,python3):2025-01-02-22:08:08.279.643 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933648 [INFO] GE(1088479,python3):2025-01-02-22:08:08.281.093 [error_manager.cc:358]1088971 ReportInterErrMessage:report error_message, error_code:E19999, work_stream_id:1, error_mode:0\r\n933649 [ERROR] GE(1088479,python3):2025-01-02-22:08:08.281.131 [ge_api.cc:1007]1088971 BuildGraph: ErrorNo: 4294967295(failed) [COMP][PRE_OPT]Build graph failed, error code:1343225857, session_id:0, graph_id:1.\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFDV7",
        "clean_data": "Lowering报错 All auto fused ge nodes should on the same graph ：模型自动融合时GE节点分布异常。需检查子图处理逻辑是否合理，确认是否存在节点分散到多个子图的情况，或尝试禁用某些算子融合策略以排查问题。",
        "created_at": "2025-01-03T10:36:24+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-03T10:36:33+08:00"
    },
    {
        "id": 103,
        "source_id": "20727288",
        "title": "[Question|问题咨询]: EZ3002",
        "body": "### 问题描述\r\n\r\n[W OpCommand.cpp:77] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy2048 (function operator())\r\nEZ3002: 2025-06-03-17:12:34.653.082 Optype [MaxPoolWithArgmaxV1] of Ops kernel [AIcoreEngine] is unsupported. Reason: [tbe-custom]:op type MaxPoolWithArgmaxV1 is not found in this op store.[tbe-custom]:op type MaxPoolWithArgmaxV1 is not found in this op store.[Dynamic shape check]: data type DT_FLOAT of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16}Format:{NC1HWC0}[Static shape check]:data type DT_FLOAT of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16}Format:{NC1HWC0}.\r\n        Possible Cause: The operator type is unsupported in the operator information library due to specification mismatch.\r\n        Solution: Submit an issue to request for support at https://gitee.com/ascend, or remove this type of operators from your model.\r\n        TraceBack (most recent call last):\r\n        No supported Ops kernel and engine are found for [MaxPoolWithArgmaxV1228], optype [MaxPoolWithArgmaxV1].\r\n        Optype [TransData] of Ops kernel [AIcoreEngine] is unsupported. Reason: [tbe-custom]:op type TransData is not found in this op store.[tbe-custom]:op type TransData is not found in this op store.[Dynamic shape check]: The format and dtype is not precisely equivalent to format and dtype in op information library[Static shape check]:The format and dtype is not precisely equivalent to format and dtype in op information library.\r\n        Optype [TransData] of Ops kernel [aicpu_ascend_kernel] is unsupported. Reason: Transdata Op does not have attr group..\r\n        No supported Ops kernel and engine are found for [trans_TransData_322], optype [TransData].\r\n        build graph failed, graph id:227, ret:-1[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1615]\r\n        [Build][SingleOpModel]call ge interface generator.BuildSingleOpModel failed. ge result = 4294967295[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]\r\n        [Build][Op]Fail to build op model[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]\r\n        build op model failed, result = 500002[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]\r\n\r\n\r\n### 所属算子\r\n\r\n其他\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops-adv/issues/ICC9A0",
        "clean_data": "Question 问题咨询   EZ3002 及 500002   问题：MaxPoolWithArgmaxV1 和 TransData 算子在AIcoreEngine中不被支持 未找到TBE自定义算子 ，且输入类型DT FLOAT与要求的DT FLOAT16 格式NC1HWC0 不匹配，导致模型构建失败并提示500002 4294967295错误码。   定位：   1  算子兼容性问题 MaxPoolWithArgmaxV1 TransData    2  输入数据类型 需DT FLOAT16 与格式 需NC1HWC0 限制   3  构建阶段错误码500002及4294967295   建议：     提交issue请求算子支持     移除上述算子或转换为支持类型 格式",
        "created_at": "2025-06-03T17:23:03+08:00",
        "topic_summary": "昇腾CANN开发者如何解决MaxPoolWithArgmaxV1算子未注册错误",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-10T15:29:16+08:00"
    },
    {
        "id": 588,
        "source_id": "20785876",
        "title": "CVE-2021-37712",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-37712](https://nvd.nist.gov/vuln/detail/CVE-2021-37712)\n漏洞归属组件：tar\n漏洞归属的版本：7.4.3\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe npm package \"tar\" (aka node-tar) before versions 4.4.18, 5.0.10, and 6.1.9 has an arbitrary file creation/overwrite and arbitrary code execution vulnerability. node-tar aims to guarantee that any file whose location would be modified by a symbolic link is not extracted. This is, in part, achieved by ensuring that extracted directories are not symlinks. Additionally, in order to prevent unnecessary stat calls to determine whether a given path is a directory, paths are cached when directories are created. This logic was insufficient when extracting tar files that contained both a directory and a symlink with names containing unicode values that normalized to the same value. Additionally, on Windows systems, long path portions would resolve to the same file system entities as their 8.3 \"short path\" counterparts. A specially crafted tar archive could thus include a directory with one form of the path, followed by a symbolic link with a different string that resolves to the same file system entity, followed by a file using the first form. By first creating a directory, and then replacing that directory with a symlink that had a different apparent name that resolved to the same entry in the filesystem, it was thus possible to bypass node-tar symlink checks on directories, essentially allowing an untrusted tar file to symlink into an arbitrary location and subsequently extracting arbitrary files into that location, thus allowing arbitrary file creation and overwrite. These issues were addressed in releases 4.4.18, 5.0.10 and 6.1.9. The v3 branch of node-tar has been deprecated and did not receive patches for these issues. If you are still using a v3 release we recommend you update to a more recent version of node-tar. If this is not possible, a workaround is available in the referenced GHSA-qq89-hq3f-393p.\n\n漏洞公开时间：2021-09-01 01:15:00\n漏洞创建时间：2025-06-09 09:10:51\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-37712\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIHG",
        "clean_data": "CVE 2021 37712  node tar v3及旧版本因Unicode路径或Windows长 短路径绕过符号链接检查，允许通过特制tar文件创建任意文件并覆盖。解决方案：升级至4 4 18 5 0 10 6 1 9 版本，或参考GHSA qq89 hq3f 393p临时修复。   说明：此描述精准提炼了核心组件 node tar 、影响范围 v3及旧版本 、漏洞原理 路径标准化绕过SymLink检查 、风险结果 任意文件操作 和修复方案 升级受影响版本 ，符合社区开发者快速定位问题的需求，未添加冗余解释。",
        "created_at": "2025-06-09T09:10:51+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:10:51+08:00"
    },
    {
        "id": 589,
        "source_id": "20785884",
        "title": "CVE-2022-25883",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-25883](https://nvd.nist.gov/vuln/detail/CVE-2022-25883)\n漏洞归属组件：semver\n漏洞归属的版本：6.3.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nVersions of the package semver before 7.5.2 are vulnerable to Regular Expression Denial of Service (ReDoS) via the function new Range, when untrusted user data is provided as a range.\r\r\r\n\n漏洞公开时间：2023-06-21 13:15:09\n漏洞创建时间：2025-06-09 09:11:02\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-25883\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIHO",
        "clean_data": "CVE 2022 25883：semver 6 3 1及之前版本在 new Range 函数处理用户输入范围时存在ReDoS漏洞，建议升级至7 5 2或更高版本修复。",
        "created_at": "2025-06-09T09:11:03+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:03+08:00"
    },
    {
        "id": 30,
        "source_id": "19936561",
        "title": "头文件按稳定度排序",
        "body": "![输入图片说明](https://foruda.gitee.com/images/1742546885966181147/478d2422_15112809.png \"屏幕截图\")\r\n\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBVB5D",
        "clean_data": "头文件按稳定度排序",
        "created_at": "2025-03-21T16:48:07+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-21T16:48:08+08:00"
    },
    {
        "id": 645,
        "source_id": "02108183690515604221",
        "title": "把onnx转换成om后，执行推理，图片分割结果不正确",
        "body": "<div class=\"cke-article\"><p>驱动：24.1.0.1  芯片： 310P3 CANN:8.0.0</p>  <p>1. <span><span><span><span><span>[代码段1] 以下是输入数据的准备（3输入），通过forward()传入，进行模型推理</span></span></span></span></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_3232.png\" src=\"cid:pic_0\"></span></p>  <p>2. <span><span><span><span><span>[代码段2] 以下是forward()函数，返回值ret均为0，代表执行成功</span></span></span></span></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_4380.png\" src=\"cid:pic_1\"></span></p>  <p>3.<span><span><span><span><span>[代码段3]  将拿到的outputs做以下后处理，但拿到的mask图像不是分割正确的图像</span></span></span></span></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_6111.png\" src=\"cid:pic_2\"></span></p>  <p>4.<span><span><span><span><span>例如对以下图片做分割</span></span></span></span></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_7578.png\" src=\"cid:pic_3\"></span></p>  <p>5.在昇腾上的结果是：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_30738.png\" src=\"cid:pic_4\" style=\"width: 105.0px;height: 105.0px;\"></span>  <span class=\"easyimage easyimage-full\"><img alt=\"cke_34761.png\" src=\"cid:pic_5\" style=\"width: 108.0px;height: 108.0px;\"></span>     <span class=\"easyimage easyimage-full\"><img alt=\"cke_36791.png\" src=\"cid:pic_6\" style=\"width: 117.0px;height: 117.0px;\"></span></p>  <p>6.在Nvidia上的推理结果是：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_43712.png\" src=\"cid:pic_7\" style=\"width: 422.0px;height: 198.0px;\"></span></p>  <p>7. 问题点：</p>  <p>按照昇腾推理，图片分割结果不正确</p>  <p>8.备注</p>  <p>代码文件链接：通过网盘分享的文件：infer.py</p>  <p>链接: https://pan.baidu.com/s/1x0o-1CL-Dfi4urI5ShdKOA 提取码: hxn5</p>  <p>输入图片文件：sekuai.png</p>  <p>链接: https://pan.baidu.com/s/1tQaxuPzC2LKc7dJkqVq3ug 提取码: 2p1t</p></div>",
        "url": "https://www.hiascend.com/forum/thread-02108183690515604221-1-1.html",
        "clean_data": "开发问题：使用ONNX转换的OM模型在昇腾310P3芯片上执行图像分割推理时输出结果异常，尽管forward函数返回成功，但生成的mask图像与NVIDIA平台推理结果存在明显差异。已验证环境配置 CANN8 0 0 驱动24 1 0 1 ，需排查模型转换参数适配性及多输入输出处理配置问题。",
        "created_at": "2025-05-27T01:08:36+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-10T06:19:27+08:00"
    },
    {
        "id": 118,
        "source_id": "20748919",
        "title": "[Question|问题咨询]: 关于报错：RuntimeError: Failed to find function HcclCommInitRootInfoConfig",
        "body": "### 问题描述\r\n\r\n在python中，使用accelerate库进行训练时，调用自定义算子报错如下：\r\n\r\nRuntimeError: Failed to find function HcclCommInitRootInfoConfig\r\n\r\n[ERROR] 2025-06-03-21:12:13 (PID:2139650, Device:0, RankID:0) ERR02008 DIST resource not found\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-hccl/issues/ICCPYV",
        "clean_data": "问题标题提炼：HcclCommInitRootInfoConfig缺失导致的分布式训练报错  问题描述精简：调用Ascend自定义算子时，accelerate init  触发 RuntimeError  HcclCommInitRootInfoConfig not found 及 ERR02008 DIST resource not found ，因未正确初始化NPU通信资源。需检查运行环境是否为多卡分布式场景，若开启Ascend多机多卡模式，需补充Hccl初始化参数或使用mp spawn等正确方式启动分布式进程。",
        "created_at": "2025-06-05T10:27:16+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T10:29:01+08:00"
    },
    {
        "id": 135,
        "source_id": "0201178956294531140",
        "title": "容器内安装torch_npu获取NPU资源不正确问题",
        "body": "<div class=\"cke-article\"><p><strong>宿主机环境</strong></p>  <p>驱动版本：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1409.png\" src=\"cid:pic_0\"></span></p>  <p>CANN版本：Ascend-cann-kernels-910b_8.0.RC3_linux-aarch64.run</p>  <p>torch版本：2.1.0</p>  <p>torch-npu版本：2.1.0.post8</p>  <p>运行python -c &quot;import torch; import torch_npu; print(torch.npu.device_count())&quot;能够正常获取NPU个数</p>  <p><strong>容器环境</strong></p>  <p>基础镜像版本：python:3.9.9-slim</p>  <p>CANN版本：Ascend-cann-kernels-910b_8.0.RC3_linux-aarch64.run</p>  <p>torch版本：2.1.0</p>  <p>torch-npu版本：2.1.0.post8</p>  <p>运行python -c &quot;import torch; import torch_npu; print(torch.npu.device_count())&quot;获取到的NPU个数一直为0，容器启动命令如下：docker run -it --device=/dev/davinci4 --device=/dev/davinci_manager --device=/dev/hisi_hdc --device=/dev/devmm_svm --net=host -v /usr/local/Ascend/driver:/usr/local/Ascend/driver -v /usr/local/dcmi:/usr/local/dcmi -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi -v /usr/local/sbin:/usr/local/sbin -v /usr/local/Ascend/driver/lib64:/usr/local/Ascend/driver/lib64 -v /etc/ascend_install.info:/etc/ascend_install.info -e ASCEND_RT_VISIBLE_DEVICES=4 -e ASCEND_VISIBLE_DEVICES=4 woodwind:04021154 /bin/bash</p>  <p>在容器中运行npu-smi info也可以正常看到4号卡，但是现在问题就是获取的NPU个数一直为0，请问还有什么更好的排查方向呢，谢谢</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0201178956294531140-1-1.html",
        "clean_data": "容器中获取NPU设备数为0  宿主与容器环境配置一致，npu smi可检测到4号卡，但torch device count  始终返回0。排查方向建议： 1  全量挂载Ascend驱动目录 2  检查容器权限组配置 davinci设备访问  3  验证npu模块动态链接库依赖是否完整 4  检查Ascend运行时初始化脚本是否在容器内生效",
        "created_at": "2025-04-02T06:04:55+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-02T07:24:04+08:00"
    },
    {
        "id": 94,
        "source_id": "20675620",
        "title": "[Documentation|文档反馈]: 建议添加对CANN版本的需求说明",
        "body": "### Document Link（文档链接）\r\n\r\nhttps://gitee.com/ascend/cann-ops/blob/master/QuickStart.md\r\n\r\n### Issues Section（问题文档片段）\r\n\r\n3.2 CANN开发套件包安装及路径信息\r\n\r\n### Existing Issues（存在的问题）\r\n\r\n在3.2章节中并没有明确给出对CANN的版本要求，但是实际编译时发现CANN8.0.RC3会编译失败，升级到CANN8.1.RC1才能正常编译，建议：明确各个分支或者Tag对应的CANN版本要求\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/ICB5ES",
        "clean_data": "Issue Summary  QuickStart md第3 2章应补充CANN版本需求说明：当前文档未明示CANN版本需求，导致CANN8 0 RC3编译失败。发现编译依赖需明确，建议各分支 Tag标注适配CANN版本，避免兼容性问题。",
        "created_at": "2025-05-28T15:17:56+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-28T15:17:56+08:00"
    },
    {
        "id": 138,
        "source_id": "0236176540727797023",
        "title": "[DSL]  from tbe import tvm 和 import tvm的区别",
        "body": "<div class=\"cke-article\"><p>两个tvm是存在区别的</p>  <p><strong>1. from tbe import tvm 指 TBE 内部的 <code style=\"\">tvm</code> 子模块</strong></p>  <blockquote> <p>华为的 <strong>TBE（Tensor Boost Engine）</strong> 在某些版本中可能将自身的部分模块命名为 <code style=\"\">tvm</code>，但它 <strong>并不是 Apache TVM</strong>。</p>  <p>当执行 <code style=\"\">from tbe import tvm</code> 时，实际导入的是 TBE 内部的一个子模块（或别名），而非官方的 Apache TVM。</p> </blockquote>  <p><strong>2.  import tvm指官方的 Apache TVM</strong></p>  <blockquote> <p>直接执行 <code style=\"\">import tvm</code> 报错，说明 Python 环境中未正确安装 Apache TVM，或安装路径未被识别。</p> </blockquote>  <p><span style=\"color: rgb(50,141,255);\">示例验证</span>：安装cann后下面的代码可以编译通过，但是如果额外加上 import tvm 时提示 <strong><code style=\"\">oduleNotFoundError: No module named 'tvm'</code></strong></p>  <blockquote> <p># import tvm </p>  <p>from tbe import tvm </p>  <p>from tbe import dsl </p>  <p> </p>  <p>shape = (280000,280000) </p>  <p>dtype = &quot;float16&quot; </p>  <p>data = tvm.placeholder(shape, name=&quot;data&quot;, dtype=dtype) </p>  <p> </p>  <p>with tvm.target.cce(): </p>  <p>    res = dsl.vabs(data) </p>  <p>    sch = dsl.auto_schedule(res) </p>  <p> </p>  <p>config = {  &quot;name&quot; : &quot;abs_28_28_float16&quot;,  &quot;tensor_list&quot; : [data,res]   } </p>  <p>dsl.build(sch, config) </p> </blockquote>  <p>参考：https://chat.deepseek.com/a/chat/s/20d86993-e564-4b81-af43-396a23b8c159</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0236176540727797023-1-1.html",
        "clean_data": "DSL  from tbe import tvm 与 import tvm 的区别      1    模块来源  ：         from tbe import tvm ：导入CANN中的TBE框架内置子模块，非Apache TVM框架。         import tvm ：试图导入独立的Apache TVM框架，需单独安装后才可用。    2    环境依赖  ：        TBE内置 tvm 已集成在CANN中，默认可用。         import tvm 报错表示未正确安装Apache TVM或环境未配置其路径。    3    功能适配  ：      TBE的 tvm 与Apache TVM接口兼容，但属于CANN定制版本，建议直接使用 from tbe import tvm 配合DSL开发。      参考示例  ：   安装CANN后示例代码可运行，若额外添加 import tvm 会报 ModuleNotFoundError ，证明TBE内的 tvm 未依赖独立TVN安装。",
        "created_at": "2025-03-05T07:05:28+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-05T07:05:28+08:00"
    },
    {
        "id": 566,
        "source_id": "20780847",
        "title": "CVE-2021-45115",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-45115](https://nvd.nist.gov/vuln/detail/CVE-2021-45115)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nAn issue was discovered in Django 2.2 before 2.2.26, 3.2 before 3.2.11, and 4.0 before 4.0.1. UserAttributeSimilarityValidator incurred significant overhead in evaluating a submitted password that was artificially large in relation to the comparison values. In a situation where access to user registration was unrestricted, this provided a potential vector for a denial-of-service attack.\n\n漏洞公开时间：2022-01-05 08:15:00\n漏洞创建时间：2025-06-08 00:20:18\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-45115\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDELR",
        "clean_data": "标准问题格式： Django 3 2 7版本的CVE 2021 45115漏洞如何修复？  问题描述： Django 3 2 7及以下版本在UserAttributeSimilarityValidator密码验证时因高时间复杂度执行存在DoS风险，建议如何修复？",
        "created_at": "2025-06-08T00:20:18+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:20:18+08:00"
    },
    {
        "id": 37,
        "source_id": "20160321",
        "title": "BatchNormV3,ClipByValue,LayerNormV4,SoftmaxV2算子",
        "body": "BatchNormV3,ClipByValue,LayerNormV4,SoftmaxV2算子",
        "url": "https://gitee.com/ascend/canndev/issues/IC03SX",
        "clean_data": "标题内容：BatchNormV3 ClipByValue LayerNormV4 SoftmaxV2算子",
        "created_at": "2025-04-10T16:50:45+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-10T16:54:42+08:00"
    },
    {
        "id": 141,
        "source_id": "02112175913669687146",
        "title": "求助！训练模型报错 RuntimeError: call aclnnForeachAddList failed, detail:EZ1001: Get path and read config failed.",
        "body": "<div class=\"cke-article\"><p>昇腾 300Tpro</p>  <p>CANN 7.0</p>  <p>pytorch 2.0.1</p>  <p>麒麟 V10 sp2 arm系统</p>  <p>运行训练代码，报错</p>  <p>/home/xxx/miniconda3/envs/py39/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.</p>  <p>  if not hasattr(tensorboard, &quot;__version__&quot;) or LooseVersion(</p>  <p>模型: resnet50   攻击方法: fgsm</p>  <p>原始样本准确率 0.702176517571885</p>  <p>  0%|                                              | 0/62500000 [00:00&lt;?, ?it/s]</p>  <p>Traceback (most recent call last):</p>  <p>  File &quot;/home/xxx/project/enhance/duikangyangben/enhance.py&quot;, line 398, in &lt;module&gt;</p>  <p>    record = training(</p>  <p>  File &quot;/home/xxx/project/enhance/duikangyangben/enhance.py&quot;, line 276, in training</p>  <p>    optimizer.step()</p>  <p>  File &quot;/home/xxx/miniconda3/envs/py39/lib/python3.9/site-packages/torch/optim/optimizer.py&quot;, line 280, in wrapper</p>  <p>    out = func(*args, **kwargs)</p>  <p>  File &quot;/home/xxx/miniconda3/envs/py39/lib/python3.9/site-packages/torch/optim/optimizer.py&quot;, line 33, in _use_grad</p>  <p>    ret = func(self, *args, **kwargs)</p>  <p>  File &quot;/home/xxx/miniconda3/envs/py39/lib/python3.9/site-packages/torch/optim/sgd.py&quot;, line 76, in step</p>  <p>    sgd(params_with_grad,</p>  <p>  File &quot;/home/xxx/miniconda3/envs/py39/lib/python3.9/site-packages/torch/optim/sgd.py&quot;, line 222, in sgd</p>  <p>    func(params,</p>  <p>  File &quot;/home/xxx/miniconda3/envs/py39/lib/python3.9/site-packages/torch/optim/sgd.py&quot;, line 325, in _multi_tensor_sgd</p>  <p>    torch._foreach_add_(device_params, device_grads, alpha=-lr)</p>  <p>RuntimeError: call aclnnForeachAddList failed, detail:EZ1001: Get path and read config failed.</p>  <p>        TraceBack (most recent call last):</p>  <p>        Check NnopbaseCollecterWork(binCollecter.get()) failed</p>  <p>        Assert ((NnopbaseInit()) == 0) failed</p>  <p>        Check NnopbaseCreateExecutorSpace(&amp;executorSpace) failed</p>  <p></p>  <p></p>  <p>我跑一些测试的代码是不报错的，能出结果， 但是这些加载模型训练就报错，求助各位大佬！！！</p></div>",
        "url": "https://www.hiascend.com/forum/thread-02112175913669687146-1-1.html",
        "clean_data": "issue描述   在昇腾300T pro设备运行resnet50模型训练时，调用torch  foreach add 触发aclnnForeachAddList接口失败，报 EZ1001  Get path and read config failed ，涉及路径 配置未正确定位。    关键点   1  环境组合：PyTorch 2 0 1   CANN 7 0   麒麟V10 SP2 ARM64 2  根因指向aclnn配置文件读取异常 非事件定义相关  3  测试代码正常，仅模型训练场景复现问题",
        "created_at": "2025-02-26T00:54:30+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-26T01:16:57+08:00"
    },
    {
        "id": 117,
        "source_id": "20744345",
        "title": "希望增加Nightly每日构建",
        "body": "一、需求场景&价值\r\n昇腾Triton开发团队，你们好：\r\n\r\n希望能够为昇腾Triton后端增加Nightly每日构建，并最终能包含以下几个关键分支：\r\n\r\n1. 针对当前PyTorch配套2.6版本的Triton分支的每日构建：\r\n    - 即每日构建与当前昇腾所支持的PyTorch稳定版对应的Triton后端代码。\r\n    - 这样做的好处是，使用PyTorch稳定版的用户也能及时用上针对这个版本最新的Triton后端优化和修复。\r\n2. 适配PyTorch Nightly版及Triton上游main分支的昇腾后端每日构建：\r\n背景： Triton上游的发布策略是cherry-pick，这意味着有些已合并到main分支的新特性、新语法或性能优化，并没有及时进入正式的release版。举个例子，tl.gather这个接口，2024年11月就引入main分支了，但到现在triton 3.3.0 的release版本里还没有。这种情况确实有些不方便。\r\n建议： 提供基于Triton上游main分支、并适配PyTorch Nightly版的昇腾后端每日构建。\r\n考虑： 这个需求可能对昇腾后端的适配工作要求比较高，因为它需要triton_npu包也能跟上PyTorch Nightly的节奏并及时发版。但这样做能让昇腾用户第一时间用到Triton的最新进展。\r\n\r\n希望昇腾Triton后端能为当前正在维护的分支提供Nightly每日构建包。\r\n主要原因是，很多用户的实际环境（尤其是各类Docker容器化环境）里，从源码完整编译Triton的条件并不成熟，缺少完整的编译链。如果能提供预编译好的Nightly包，会极大地方便大家在这些环境下的部署、测试和使用，降低门槛。\r\n\r\n二、需求建议实现的规格\r\n\r\n三、竞品比较（选填）\r\n可以看到，像Intel GPU的Triton后端 (intel/intel-xpu-backend-for-triton)，他们是直接在Triton的main分支上进行开发，并定期rebase。通过特定commit关联对应的PyTorch版本，以此来保证兼容性。\r\n虽然昇腾后端目前基于patch的方式有所不同，但还是期望昇腾后端未来能够逐步实现基于Triton main分支和配套PyTorch版本进行开发，以此来维护对PyTorch最新特性和Triton最新能力的兼容。\r\n\r\n\r\n谢谢！",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICCMFT",
        "clean_data": "希望增加昇腾Triton后端Nightly每日构建： 1  需要构建与昇腾PyTorch稳定版 2 6 同步的昇腾Triton后端每日包 2  需要适配PyTorch Nightly版和Triton main分支的每日构建 原因：Triton上游采用cherry pick发布策略导致新特性 如tl gather 无法及时进入稳定版，且用户容器化环境中缺乏完整编译链。",
        "created_at": "2025-06-04T19:06:34+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T21:29:20+08:00"
    },
    {
        "id": 111,
        "source_id": "20732622",
        "title": "全量测试用例日测试打通",
        "body": "",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICCDE6",
        "clean_data": "全量测试用例每日测试流程建立及执行",
        "created_at": "2025-06-04T09:48:02+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T09:48:03+08:00"
    },
    {
        "id": 24,
        "source_id": "19543817",
        "title": "全AIC的核间同步卡死问题",
        "body": "### 该问题是怎么引起的？\r\n在AIC代码中使用模式0的核间同步，程序执行卡死。\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/ascend-linear-algebra-ops/issues/IBMW3T",
        "clean_data": "全AIC核间同步卡死：启用模式0的核间同步时程序卡死，如何解决？",
        "created_at": "2025-02-17T20:21:09+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-17T20:21:09+08:00"
    },
    {
        "id": 82,
        "source_id": "20574068",
        "title": "目前canfuse，ascir中都有metadef里GetDumpGraphPrefix的逻辑，在metadef里需要把这个函数的逻辑抽取出来，作为一个独立函数对外提供",
        "body": "一、需求场景&价值\r\n在canfuse和ascir里目前获取dump目录前缀有相同的代码，代码冗余需要将这部分代码抽取出来，作为公共函数对外提供\r\n\r\n二、需求建议实现的规格\r\n\r\n三、竞品比较（选填）",
        "url": "https://gitee.com/ascend/metadef/issues/IC8Z1W",
        "clean_data": "提炼GetDumpGraphPrefix函数为独立公共函数以消除canfuse和ascir中的代码冗余   将标题中的核心要素 GetDumpGraphPrefix逻辑抽取 与正文 代码冗余需要公共化 的矛盾点直接关联，采用 问题定位 解决方式 结构，去除 对外提供 等非实质描述，保持技术动作的精准表达",
        "created_at": "2025-05-20T09:37:46+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-20T11:02:36+08:00"
    },
    {
        "id": 47,
        "source_id": "20336693",
        "title": "命名风格是小驼峰和下划线都可以吗，是否需要统一命名风格？",
        "body": "命名风格是小驼峰和下划线都可以吗，是否需要统一命名风格？\r\n\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IC3VW5",
        "clean_data": "问题：当前代码中是否允许混合使用小驼峰和下划线命名风格？是否需要统一至某一特定风格以增强代码一致性？",
        "created_at": "2025-04-25T11:46:21+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-25T11:46:21+08:00"
    },
    {
        "id": 98,
        "source_id": "20713964",
        "title": "请求支持 FLA 的持续集成或测试样例",
        "body": "尊敬的 Ascend/Triton-Ascend 团队：\n\n您好！\n\n我是 [flash-linear-attention (FLA)](https://github.com/fla-org/flash-linear-attention) 项目的成员。\nFLA 旨在为学术界和工业界提供一系列基于 Triton 的、针对目前主流的线性注意力和稀疏注意力模型的高效算子实现，涵盖了训练和推理过程。同时，我们还维护一个名为 [flame](https://github.com/fla-org/flame) 的分布式训练脚本库，以支持这些模型的高效训练。\n\n我们希望能为 FLA 项目申请在昇腾 (Ascend) 硬件上的 CI (持续集成) / 回归测试资源。或者希望能够得到 triton-ascend 在发布时测试 FLA 内核的开箱支持。\n\n一、需求场景&价值\n1.  **昇腾 Triton 编译器健壮性测试**：FLA 包含了大量复杂的 Triton Kernel 实现。通过在昇腾 CI 环境中运行我们的测试用例，可以帮助发现和定位昇腾 Triton 编译器在编译复杂算子时可能存在的 bug 或问题。\n2.  **兼容性验证**：确保 FLA 中实现的各种高效算子能够与昇腾 Triton 编译器良好兼容，从而使广大昇腾 NPU 用户能够无缝使用这些先进的注意力机制。\n3.  **生态贡献**：FLA 的目标是支持更广泛的硬件后端。获得昇腾的官方 CI 支持，将极大地推动 FLA 在昇腾平台上的适配和优化，丰富昇腾 AI 生态。\n**目前遇到的具体问题：**\n\n在尝试将 FLA 适配到昇腾硬件的过程中，我们遇到了关于设备属性查询的问题。具体来说，当我们调用 `triton.runtime.driver.active.utils.get_device_properties(0)` 时，返回的信息如下：\n\n```python\n{'max_shared_mem': 1, 'num_aicore': 24, 'num_vectorcore': 48}\n```\nFLA 中的部分 Kernel 实现依赖于 triton.runtime.driver.active.utils.get_device_properties(tensor_idx)['multiprocessor_count'] 和 max_shared_mem 这两个参数来动态判断和配置 MMA (Matrix Multiply-Accumulate) 操作的矩阵大小以及其他并行化策略。\n\n然而，昇腾 NPU 返回的 max_shared_mem 值为 1，这与我们通常在其他 GPGPU 平台上（如 NVIDIA, AMD, Intel GPU）获取到的实际共享内存大小（通常以 B 为单位）的语义不符。此外，我们未能找到 multiprocessor_count （通常指 SM 流处理器数量）直接对应且行为一致的接口。我个人猜测在大部分时刻可以等价于 num_vectorcore 来实现类似的访问，但我更希望直接有一个键值映射。\n如以下是 Intel N100 核显返回的内容：\n```\ntriton.runtime.driver.active.utils.get_device_properties(0)\n{'max_shared_mem': 65536, 'multiprocessor_count': 2, 'sm_clock_rate': 750, 'mem_clock_rate': 0, 'mem_bus_width': 64, 'max_work_group_size': 512, 'sub_group_sizes': (8, 16, 32)}\n```\n\n我们期望昇腾 Triton 能够提供更接近于通用 GPGPU 硬件特性描述的接口，或者提供明确的指导，说明如何在昇腾硬件上获取用于 Kernel 优化的等效参数。这对于保证 Kernel 的可移植性和性能至关重要。\n\n二、需求建议实现的规格\n\n1. 获得在昇腾硬件上的 CI 资源，以便我们可以定期运行测试，确保 FLA 的兼容性和稳定性。\n2. 如果可能，希望昇腾 Triton 团队能考虑提供与主流 GPGPU 更为一致的设备属性查询接口，或者提供关于如何利用现有接口参数进行高效 Kernel 设计的指导。\n\n三、竞品比较（选填）\n\n再次感谢昇腾编译器团队提供如此好的工具。希望能够得到相关的支持。",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICBYZW",
        "clean_data": "标题：请求支持 FLA 的持续集成或测试样例   内容：FLA项目需适配昇腾硬件，申请CI 回归测试资源支持及测试样例。   1    问题  ： get device properties 0  返回参数不兼容  max shared mem 1 异常， multiprocessor count 缺失 ，阻定了 MMA矩阵大小 和 并行策略 的动态配置。   2    需求  ：        提供 标准硬件特性查询接口  如 max shared mem 以B作单位、支持 active utils get device properties  multiprocessor count    。        明确 num vectorcore 是否等效代表 multiprocessor count 。        申请昇腾CI资源持续测试适配，确保FLA算子与编译器兼容性。   3    价值  ：推动FLA在昇腾平台可移植性优化，丰富NPU生态。     说明：原文冗余的竞品对比与项目背景已精简，保留核心问题与需求关联。未发现额外异常信息。",
        "created_at": "2025-06-02T22:30:22+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T16:07:12+08:00"
    },
    {
        "id": 137,
        "source_id": "02114177673210158008",
        "title": "【FAQ】升级CANN但不清楚驱动固件是否需要升级篇",
        "body": "<div class=\"cke-article\"><h1>目的：</h1>  <h3>为了解决开发者，在升级目标CANN的过程中是否需要升级固件和驱动及如何选择匹配的固件和驱动版本相关问题</h3>  <h1><br> 一、确认需要使用的目标CANN版本</h1>  <h3>Ⅰ：查看当前硬件环境CANN版本</h3>  <p>通过以下指令可以查看当前的CANN版本</p>  <p><span style=\"color: rgb(230,62,60);\"><strong>注意：</strong></span>自定义安装路径应需要将路径替换至自定义CANN安装路径</p>  <p>若非root用户安装CANN，查询指令</p>  <pre><br><code class=\"language-javascript\">cat /home/HwHiAiUser/Ascend/ascend-toolkit/latest/version.cfg</code></pre>  <p>若root用户安装CANN，查询指令</p>  <pre><br><code class=\"language-javascript\">cat /usr/local/Ascend/ascend-toolkit/latest/version.cfg</code></pre>  <p>从回显中得知当前CANN版本：7.0.0版本</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_5268.png\" src=\"cid:pic_1\"></span></p>  <h3>Ⅱ：现有环境CANN版本不满足，如何下载目标版本</h3>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-transform: none;vertical-align: baseline;white-space: normal;word-spacing: 0.0px;\">第一步：进入昇腾社区官网<strong><a href=\"cid:link_2\" rel=\"nofollow\" style=\"box-sizing: border-box;cursor: pointer;color: rgb(7,130,193);text-decoration: none;outline: none;background: 0.0px 0.0px transparent;padding: 0.0px;vertical-align: baseline;\" target=\"_blank\">资源下载中心</a></strong>页面</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">第二步：选择自己的硬件及需要使用的框架等</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">​第三步：点击查找配套资源，根据自己想要使用的CANN包进行下载</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><span style=\"color: rgb(230,62,60);\"><strong>注意：</strong></span>需要注意自己硬件的系统架构，可使用linux指令  uname-m 查询 </p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">以下载8.0.0.alpha001目标CANN版本及arm平台举例，则需要下载 Ascend-cann-toolkit_8.0.0.alpha001_linux-aarch64.run</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">第四步：根据昇腾社区官方文档指导进行<a href=\"https://www.hiascend.com/document/detail/zh/canncommercial/800/softwareinst/instg/instg_0008.html?Mode=PmIns&amp;OS=Ubuntu&amp;Software=cannToolKit\" rel=\"nofollow\" target=\"_blank\">安装CANN软件包</a></p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><span><span><img src=\"cid:pic_2\"></span><span>​</span></span></p>  <h1>三、确认当前驱动与固件版本</h1>  <p>可以通过linux指令进行查询当前硬件上安装的驱动固件版本号</p>  <pre><br><code class=\"language-javascript\">npu-smi info</code></pre>  <p>从回显上可以看到：驱动23.0.0版本</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_32159.png\" src=\"cid:pic_3\"></span></p>  <p><span style=\"color: rgb(230,62,60);\">注意：</span>固件版本查看路径，根据安装方式不同更换自定义安装路径</p>  <pre><br><code class=\"language-javascript\">cat /usr/local/Ascend/firmware/version.info</code></pre>  <p>从回显上可以看到：固件7.1.0.3.220版本</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_167570.png\" src=\"cid:pic_4\"></span></p>  <h1>四、确认目标CANN版本匹配的驱动与固件版本范围</h1>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">Ⅰ：在资源下载中心选择目标CANN版本的页面，点击左下角关联资源中固件与驱动链接</h3>  <h3><span><span><img src=\"cid:pic_5\">Ⅱ：点击固件与驱动选择版本，可查看当前目标CANN所匹配的固件与驱动版本及兼容的其他版本，例如图一中8.0.0.alpha001可使用24.1rc2版本的驱动和7.3.0.231版本固件，图二中8.0.0beta1可兼容多个驱动固件版本</span></span></h3>  <p><span style=\"color: rgb(230,62,60);\">注意：</span>由于当前社区CANN版本发布较快于固件与驱动页面更新，可能会遇到目标CANN不在CANN版本范围中</p>  <p><span><span>这种情况下，可以参考目标CANN版本较近发布的CANN版本，或者使用社区alpha版本对应的beta版本的驱动固件配套关系</span></span></p>  <p><span><span>例如： </span></span>8.0.0.alpha003（2024/12/31）可参考使用<span><span>  </span></span>8.0.0.alpha002（2024/11/29<span><span> ）的驱动固件配套范围<br>            8.0.0.alpha003 可参考使用  8.0.0.beta1  的驱动固件配套范围</span></span></p>  <p style=\"text-align: center;\"><span class=\"easyimage easyimage-full\"><img alt=\"cke_796428.png\" src=\"cid:pic_6\"></span><br>  图一</p>  <h1><span class=\"easyimage easyimage-full\"><img alt=\"cke_1426.png\" src=\"cid:pic_0\"></span></h1>  <p style=\"text-align: center;\">图二</p>  <h1><span><span>五</span></span>、确认是否需要升级驱动和固件</h1>  <p>Ⅰ：若当前环境查询到的驱动与固件版本在目标CANN匹配的固件与驱动版本范围内，<strong>则不需要升级</strong></p>  <p>Ⅱ：若当前环境查询到的驱动与固件版本不在目标CANN匹配的固件与驱动版本范围内，<strong>则需要升级</strong>，<strong>且建议更新当前最新适配的版本</strong></p>  <p>Ⅲ：根据昇腾社区官方文档指导进行<a href=\"https://www.hiascend.com/document/detail/zh/canncommercial/800/softwareinst/instg/instg_0005.html?Mode=PmIns&amp;OS=Ubuntu&amp;Software=cannToolKit\" rel=\"nofollow\" target=\"_blank\">安装NPU驱动和固件</a></p>  <h3>若遇到相关问题依旧无法解决可在<a href=\"cid:link_4\" rel=\"nofollow\" target=\"_blank\">昇腾论坛</a>及<a href=\"cid:link_3\" rel=\"nofollow\" target=\"_blank\">技术工单</a>进行提单咨询</h3></div>",
        "url": "https://www.hiascend.com/forum/thread-02114177673210158008-1-1.html",
        "clean_data": "FAQ 升级CANN是否需要升级驱动固件   1  查询当前CANN版本：非root用户检查  home HwHiAiUser Ascend ascend toolkit latest version cfg ，root用户检查  usr local Ascend ascend toolkit latest version cfg 。   2  下载目标CANN版本：通过昇腾社区 资源下载中心  cid link 2 匹配硬件架构 通过 uname  m 查询 ，下载对应工具包 如 Ascend cann toolkit 8 0 0 alpha001 linux aarch64 run  ，参考 安装文档  https   www hiascend com document detail zh canncommercial 800 softwareinst instg instg 0008 html 。   3  查询驱动固件版本：驱动版本通过 npu smi info 获取，固件版本通过 cat  usr local Ascend firmware version info  根据安装路径调整 。   4  确认兼容性：在资源下载中心点击目标CANN版本的驱动 固件链接查看兼容范围；若目标CANN版本未更新，可参考相近版本 如alpha转beta 或最新适配版本。   5  升级决策：若现有驱动 固件版本符合目标CANN支持范围则无需升级；否则需升级为最新适配版本 参考 升级指南  https   www hiascend com document detail zh canncommercial 800 softwareinst instg instg 0005 html  。   6  问题反馈：若无法匹配，提交 昇腾技术工单  cid link 3 或访问 昇腾论坛  cid link 4 求助。",
        "created_at": "2025-03-19T01:47:55+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-19T01:48:00+08:00"
    },
    {
        "id": 162,
        "source_id": "0279183623027187069",
        "title": "Matmul作算子融合后报错 Warning: NPU warning, error code is 507015[Error]:",
        "body": "<p>[W compiler_depend.ts:409] Warning: NPU warning, error code is 507015[Error]:  [Error]: The aicore execution is abnormal.          Rectify the fault based on the error information in the ascend log. EH9999: Inner Error!         rtDeviceSynchronize execute failed, reason=[aicore exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53] EH9999: [PID: 2965] 2025-05-26-12:33:49.873.460 wait for compute device to finish failed, runtime result = 507015.[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]         TraceBack (most recent call last):  (function npuSynchronizeUsedDevices) [W compiler_depend.ts:392] Warning: NPU warning, error code is 507015[Error]:  [Error]: The aicore execution is abnormal.          Rectify the fault based on the error information in the ascend log. EH9999: Inner Error!         rtDeviceSynchronize execute failed, reason=[aicore exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53] EH9999: [PID: 2965] 2025-05-26-12:33:49.881.805 wait for compute device to finish failed, runtime result = 507015.[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]         TraceBack (most recent call last):</p> ",
        "url": "https://www.hiascend.com/forum/thread-0279183623027187069-1-1.html",
        "clean_data": "Matmul算子融合触发NPU异常错误507015，需检查AI Core执行及设备同步配置     Matmul算子融合后报错507015，提示AI Core执行异常 The aicore execution is abnormal 及rtDeviceSynchronize同步失败，建议通过Ascend日志排查算子融合逻辑或资源冲突问题。",
        "created_at": "2025-05-26T06:23:47+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T01:41:56+08:00"
    },
    {
        "id": 104,
        "source_id": "20727421",
        "title": "用例名称建议与CompiledModelCache关联",
        "body": "一、问题现象（附报错日志上下文）：\r\n用例名称建议与CompiledModelCache关联\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICC9DP",
        "clean_data": "用例名称与模型缓存 CompiledModelCache 关联问题：需补充用例命名规则或缓存配置的具体异常表现、测试步骤及日志，以便分析。",
        "created_at": "2025-06-03T17:28:24+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T17:28:31+08:00"
    },
    {
        "id": 143,
        "source_id": "0292175252902563080",
        "title": "cann8.0.0使用300I Duo卡，安装Qwen2-VL-7B-Instruct模型，运行时报错",
        "body": "<div class=\"cke-article\"><p>部署流程按照，800I的流程走的，目前没有找到300IDuo的文档</p>  <p>https://www.hiascend.com/software/modelzoo/models/detail/f2fdfa4188184630a246e0468692612a，</p>  <p>npu-smi info正常显示，启动报错</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_4221.jpeg\" src=\"cid:pic_0\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0292175252902563080-1-1.html",
        "clean_data": "使用300I Duo卡部署Qwen2 VL 7B Instruct模型时启动报错   用户在未找到300I Duo卡专用部署文档的情况下，沿用800I流程安装Qwen2 VL 7B Instruct模型，尽管硬件检测 npu smi info 正常，但模型启动时发生运行时错误，需确认CANN 8 0 0与300I Duo卡的兼容性及模型部署配置适配性。",
        "created_at": "2025-02-18T09:21:43+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-18T09:21:43+08:00"
    },
    {
        "id": 116,
        "source_id": "20742827",
        "title": "RuntimeError: call aclnnAdd failed, detail:EZ9999: Inner Error!",
        "body": "【环境】\r\nubuntu：Linux ubuntu 5.15.0-97-generic，aarch64\r\nNPU：910B3\r\nCANN：Ascend-cann-toolkit_8.2.RC1.alpha002_linux-aarch64.run\r\n下面的命令都安装成功了：\r\npip install torch_npu==2.6.0rc1\r\npip install attrs==24.2.0 numpy==1.26.4 scipy==1.13.1 decorator==5.1.1 psutil==6.0.0 pytest==8.3.2 pytest-xdist==3.6.1 pyyaml\r\nsource ~/Ascend/ascend-toolkit/set_env.sh\r\n\r\n【报错】\r\nPython wheel 安装 Triton-Ascend，运行到python3 ./triton-ascend/ascend/examples/tutorials/01-vector-add.py，报如下错误：\r\n\r\n$ python3 ./triton-ascend/ascend/examples/tutorials/01-vector-add.py\r\nTraceback (most recent call last):\r\n  File \"~/src/./triton-ascend/ascend/examples/tutorials/01-vector-add.py\", line 74, in <module>\r\n    output_torch = x + y\r\nRuntimeError: call aclnnAdd failed, detail:EZ9999: Inner Error!\r\nEZ9999: [PID: 2565186] 2025-06-04-17:12:20.462.485 Parse dynamic kernel config fail.\r\n        TraceBack (most recent call last):\r\n       AclOpKernelInit failed opType\r\n       AddAiCore ADD_TO_LAUNCHER_LIST_AICORE failed.\r\n\r\n[ERROR] 2025-06-04-17:12:20 (PID:2565186, Device:0, RankID:-1) ERR01100 OPS call acl api failed\r\n\r\n【问题】\r\n请问：RuntimeError: call aclnnAdd failed, detail:EZ9999: Inner Error!\r\n需要安装其他的库或者更新哪些库来解决吗？谢谢",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICCL9N",
        "clean_data": "问题描述精简  ：在aarch64架构下运行Triton Ascend示例01 vector add py时报错 RuntimeError  call aclnnAdd failed  detail EZ9999  Inner Error  ，提示 Parse dynamic kernel config fail 及 AddAiCore ADD TO LAUNCHER LIST AICORE failed ，需排查是否由CANN版本兼容性、依赖库缺失或算子使能异常导致。",
        "created_at": "2025-06-04T17:21:28+08:00",
        "topic_summary": "开发者安装配置是漏装必要软件包，导致运行失败",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T09:19:02+08:00"
    },
    {
        "id": 567,
        "source_id": "20780848",
        "title": "CVE-2021-45452",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-45452](https://nvd.nist.gov/vuln/detail/CVE-2021-45452)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nStorage.save in Django 2.2 before 2.2.26, 3.2 before 3.2.11, and 4.0 before 4.0.1 allows directory traversal if crafted filenames are directly passed to it.\n\n漏洞公开时间：2022-01-05 08:15:00\n漏洞创建时间：2025-06-08 00:20:20\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-45452\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDELS",
        "clean_data": "CVE 2021 45452：Django 3 2 7中Storage save存在目录遍历漏洞，影响2 2 before 2 2 26、3 2 before 3 2 11、4 0 before 4 0 1版本。攻击者通过构造filename可实现目录遍历，建议升级至3 2 11及更高版本修复。",
        "created_at": "2025-06-08T00:20:20+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:20:20+08:00"
    },
    {
        "id": 108,
        "source_id": "20731120",
        "title": "注释掉的代码可以删除。",
        "body": "",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICCC8G",
        "clean_data": "注释掉的未启用代码建议删除，以保持代码库整洁并减少冗余。",
        "created_at": "2025-06-04T08:19:30+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T08:54:42+08:00"
    },
    {
        "id": 13,
        "source_id": "19209027",
        "title": "【lowering、codegen】后端codegen时cast的dtype不对",
        "body": "一、问题现象（附报错日志上下文）：\r\ncast在后端InferOutput时拿了算子属性做inferdtype推导。\r\n但是前端lowering时将ge_node转asc_node时，属性丢了，同时InferOutput没有校验属性未获取到。\r\n\r\n1. 前端lowering需要将cast的属性传下来。--代荣\r\n2. 后端需要校验属性未获取到  --徐睿\r\n3. 需要前后对齐下是否还存在遗漏场景。 --代荣，徐睿\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFPS3",
        "clean_data": "lowering、codegen 后端代码生成阶段cast数据类型推导错误问题：   前端lowering将ge node转asc node时未正确传递cast操作属性，导致后端InferOutput使用缺失属性进行输出类型推导 建议前端补充属性传递 代荣，后端增加属性校验 徐睿 。需排查其他属性丢失场景并确认对齐性。     问题核心：属性传递缺失 dtype推导异常；解决方案方向：前端属性传递 后端校验；关键关联人分工标记",
        "created_at": "2025-01-05T10:30:06+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-05T10:30:06+08:00"
    },
    {
        "id": 150,
        "source_id": "0215172745978133265",
        "title": "静态和动态模型输入，都是如何给模型创建需要的输入？",
        "body": "<div class=\"cke-article\"><p><strong>静态模型输入：</strong></p>  <p>aclmdlDataset * inputDataset_ = aclmdlCreateDataset();</p>  <p>// 动态输入，可以通过aclmdlGetInputSizeByIndex获取模型第1个输入的大小</p>  <p>size_t inputIndex = 0;</p>  <p>size_t inputBufferSize_ = aclmdlGetInputSizeByIndex(modelDesc_, inputIndex);  </p>  <p>void * inputBuffer_;</p>  <p>aclrtMalloc(&amp;inputBuffer_, inputBufferSize_, ACL_MEM_MALLOC_HUGE_FIRST);</p>  <p>aclDataBuffer * inputData = aclCreateDataBuffer(inputBuffer_, inputBufferSize_);</p>  <p>aclmdlAddDatasetBuffer(inputDataset_, inputData);</p>  <p></p>  <p>aclmdlExecute(modelId_, inputDataset_, outputDataset_);</p>  <p></p>  <p><strong>动态模型输入：</strong></p>  <p>aclmdlDataset * inputDataset_ = aclmdlCreateDataset();</p>  <p>int64_t shapes[] = { 16, 128 };</p>  <p>aclTensorDesc * inputDesc0 = aclCreateTensorDesc(ACL_INT64, 2, shapes, ACL_FORMAT_ND); </p>  <p>aclmdlSetDatasetTensorDesc(inputDataset_, inputDesc0, 0); </p>  <p>// 动态输入，可以通过传入的数据获取大小</p>  <p>size_t inputBufferSize_ = sizeof(int64_t ) * 16 * 128;</p>  <p>void * inputBuffer_;</p>  <p>aclrtMalloc(&amp;inputBuffer_, inputBufferSize_, ACL_MEM_MALLOC_HUGE_FIRST);</p>  <p>aclDataBuffer * inputData = aclCreateDataBuffer(inputBuffer_, inputBufferSize_);</p>  <p>aclmdlAddDatasetBuffer(inputDataset_, inputData);</p>  <p></p>  <p>aclmdlExecute(modelId_, inputDataset_, outputDataset_);</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0215172745978133265-1-1.html",
        "clean_data": "问题描述：模型输入创建方式差异解析：静态模型通过aclmdlGetInputSizeByIndex获取输入大小，动态模型需显式定义shapes数组并调用aclCreateTensorDesc创建张量描述，二者均需使用aclrtMalloc分配内存，通过aclCreateDataBuffer aclmdlAddDatasetBuffer封装数据后调用aclmdlExecute执行推理。",
        "created_at": "2025-01-20T08:59:38+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-20T08:59:38+08:00"
    },
    {
        "id": 49,
        "source_id": "20370434",
        "title": "[Question|问题咨询]: cann-ops是否能够像cutlass或者flashinfer一样当库在生产环境集成使用吗？",
        "body": "### 问题描述\n\n请问下cann-ops是否能够像nvidai cutlass或者flashinfer一样，被上层库（比如vLLM、transformers等）[调用](https://github.com/flashinfer-ai/flashinfer?tab=readme-ov-file#trying-it-out)或者[集成](https://github.com/flashinfer-ai/flashinfer?tab=readme-ov-file#adoption)吗？\n\n还是仅是一个AscendC实现的算子代码参考？\n\n[1] https://github.com/NVIDIA/cutlass/blob/main/media/docs/cpp/quickstart.md#launching-a-gemm-kernel-in-cuda\n[2] https://github.com/flashinfer-ai/flashinfer?tab=readme-ov-file#trying-it-out\n\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/IC4LXE",
        "clean_data": "问题     CANN ops能否作为生产环境的库集成到开发者框架中？    解答     CANN ops为AscendC算子实现示例 参考文档源码结构与开发指南 ，需开发者基于AscendC框架自行编译集成，不具备类似CUDA库的独立调用接口 如Cutlass的GEMM接口 。当前无官方生产级库集成方式，详情可见社区算子开发文档。     注：补偿说明需确认AscendC是否支持共享库导出，若支持则需明确位置，如未提供则需提示文档待完善",
        "created_at": "2025-04-28T14:24:35+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-28T14:26:24+08:00"
    },
    {
        "id": 92,
        "source_id": "20658165",
        "title": "[Question|问题咨询]: conv3d_backprop_input.h",
        "body": "### 问题描述\r\n\r\nconv3d_backprop_input.h 中的头文件找不到 cube/algorithm/hash/tiling_cache.h\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/ICARXX",
        "clean_data": "标题：conv3d backprop input h 头文件缺失依赖路径  描述：编译包含 conv3d backprop input h 的代码时报错，提示路径 cube algorithm hash tiling cache h 不存在或未找到该头文件。需确认头文件依赖路径是否正确配置，或检查 CANN 安装是否包含该模块。",
        "created_at": "2025-05-27T11:22:56+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-27T11:22:56+08:00"
    },
    {
        "id": 29,
        "source_id": "19936514",
        "title": "变量名格式保持一致",
        "body": "![输入图片说明](https://foruda.gitee.com/images/1742546708849852281/01245767_15112809.png \"屏幕截图\")",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBVB42",
        "clean_data": "描述：请求指导在代码 配置中保持变量命名格式一致性方法，或指出存在命名规范混用问题。",
        "created_at": "2025-03-21T16:45:12+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-21T16:45:12+08:00"
    },
    {
        "id": 91,
        "source_id": "20649733",
        "title": "PtrAnalysis&MaskAnalysis&UseAnalysis 支持 BlockArgument 场景",
        "body": "一、问题现象（附报错日志上下文）：\n\ntriton-adapter-opt 报错如下并崩溃退出\n\n```\n<block argument> of type 'tensor<1x1024xi64>' at index: 3\n```\n\n二、软件版本:\n\n- triton-ascend commit `36f3e30eeeffa522bdf2b79ceaf7ff3c43e9fa88`\n\n三、测试步骤：\n\n```\ntriton-adapter-opt --triton-to-linalg=\"global-kernel=false named-ops=true\" triton_kernel.ttir\n```\n\n四、日志信息:\n\n```\nmodule {\n  tt.func public @triton_kernel(%arg0: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: i32, %arg4: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {\n    %cst = arith.constant dense<0.000000e+00> : tensor<1x1024xf32>\n    %c1_i32 = arith.constant 1 : i32\n    %c0_i32 = arith.constant 0 : i32\n    %cst_0 = arith.constant dense<0> : tensor<1xi32>\n    %cst_1 = arith.constant dense<1> : tensor<1xi32>\n    %c1024_i64 = arith.constant 1024 : i64\n    %0 = tt.get_program_id x : i32\n    %1 = arith.extsi %0 : i32 to i64\n    %2 = tt.get_program_id y : i32\n    %3 = arith.extsi %2 : i32 to i64\n    %4 = arith.muli %3, %c1024_i64 : i64\n    %5 = tt.make_range {end = 1024 : i32, start = 0 : i32} : tensor<1024xi32>\n    %6 = arith.extsi %5 : tensor<1024xi32> to tensor<1024xi64>\n    %7 = tt.splat %4 : i64 -> tensor<1024xi64>\n    %8 = arith.addi %7, %6 : tensor<1024xi64>\n    %9 = arith.extsi %arg3 : i32 to i64\n    %10 = arith.muli %1, %9 : i64\n    %11 = arith.extsi %arg4 : i32 to i64\n    %12 = arith.muli %10, %11 : i64\n    %13 = tt.expand_dims %8 {axis = 0 : i32} : tensor<1024xi64> -> tensor<1x1024xi64>\n    %14 = tt.splat %12 : i64 -> tensor<1x1024xi64>\n    %15 = arith.addi %14, %13 : tensor<1x1024xi64>\n    %16 = tt.splat %arg3 : i32 -> tensor<1xi32>\n    %17 = tt.splat %11 : i64 -> tensor<1024xi64>\n    %18 = arith.cmpi slt, %8, %17 : tensor<1024xi64>\n    %19 = tt.expand_dims %18 {axis = 0 : i32} : tensor<1024xi1> -> tensor<1x1024xi1>\n    %20 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<1x1024x!tt.ptr<f16>>\n    %21 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<1x1024x!tt.ptr<f16>>\n    %22 = tt.splat %11 : i64 -> tensor<1x1024xi64>\n    %23:3 = scf.for %arg5 = %c0_i32 to %arg3 step %c1_i32 iter_args(%arg6 = %cst, %arg7 = %cst_0, %arg8 = %15) -> (tensor<1x1024xf32>, tensor<1xi32>, tensor<1x1024xi64>)  : i32 {\n      %35 = arith.cmpi slt, %arg7, %16 : tensor<1xi32>\n      %36 = tt.expand_dims %35 {axis = 1 : i32} : tensor<1xi1> -> tensor<1x1xi1>\n      %37 = tt.broadcast %36 : tensor<1x1xi1> -> tensor<1x1024xi1>\n      %38 = arith.andi %37, %19 : tensor<1x1024xi1>\n      %39 = tt.addptr %20, %arg8 : tensor<1x1024x!tt.ptr<f16>>, tensor<1x1024xi64>\n      %40 = tt.load %39, %38 : tensor<1x1024x!tt.ptr<f16>>\n      %41 = tt.addptr %21, %arg8 : tensor<1x1024x!tt.ptr<f16>>, tensor<1x1024xi64>\n      %42 = tt.load %41, %38 : tensor<1x1024x!tt.ptr<f16>>\n      %43 = arith.mulf %40, %42 : tensor<1x1024xf16>\n      %44 = arith.extf %43 : tensor<1x1024xf16> to tensor<1x1024xf32>\n      %45 = arith.addf %arg6, %44 : tensor<1x1024xf32>\n      %46 = arith.addi %arg7, %cst_1 : tensor<1xi32>\n      %47 = arith.addi %arg8, %22 : tensor<1x1024xi64>\n      scf.yield %45, %46, %47 : tensor<1x1024xf32>, tensor<1xi32>, tensor<1x1024xi64>\n    }\n    %24 = \"tt.reduce\"(%23#0) <{axis = 0 : i32}> ({\n    ^bb0(%arg5: f32, %arg6: f32):\n      %35 = arith.addf %arg5, %arg6 : f32\n      tt.reduce.return %35 : f32\n    }) : (tensor<1x1024xf32>) -> tensor<1024xf32>\n    %25 = tt.splat %arg3 : i32 -> tensor<1xi32>\n    %26 = tt.splat %11 : i64 -> tensor<1024xi64>\n    %27 = arith.cmpi slt, %8, %26 : tensor<1024xi64>\n    %28 = tt.expand_dims %27 {axis = 0 : i32} : tensor<1024xi1> -> tensor<1x1024xi1>\n    %29 = tt.splat %arg0 : !tt.ptr<f16> -> tensor<1x1024x!tt.ptr<f16>>\n    %30 = tt.splat %arg1 : !tt.ptr<f16> -> tensor<1x1024x!tt.ptr<f16>>\n    %31 = tt.expand_dims %24 {axis = 0 : i32} : tensor<1024xf32> -> tensor<1x1024xf32>\n    %32 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<1x1024x!tt.ptr<f16>>\n    %33 = tt.splat %11 : i64 -> tensor<1x1024xi64>\n    %34:2 = scf.for %arg5 = %c0_i32 to %arg3 step %c1_i32 iter_args(%arg6 = %cst_0, %arg7 = %15) -> (tensor<1xi32>, tensor<1x1024xi64>)  : i32 {\n      %35 = arith.cmpi slt, %arg6, %25 : tensor<1xi32>\n      %36 = tt.expand_dims %35 {axis = 1 : i32} : tensor<1xi1> -> tensor<1x1xi1>\n      %37 = tt.broadcast %36 : tensor<1x1xi1> -> tensor<1x1024xi1>\n      %38 = arith.andi %37, %28 : tensor<1x1024xi1>\n      %39 = tt.addptr %29, %arg7 : tensor<1x1024x!tt.ptr<f16>>, tensor<1x1024xi64>\n      %40 = tt.load %39, %38 : tensor<1x1024x!tt.ptr<f16>>\n      %41 = tt.addptr %30, %arg7 : tensor<1x1024x!tt.ptr<f16>>, tensor<1x1024xi64>\n      %42 = tt.load %41, %38 : tensor<1x1024x!tt.ptr<f16>>\n      %43 = arith.extf %42 : tensor<1x1024xf16> to tensor<1x1024xf32>\n      %44 = arith.subf %43, %31 : tensor<1x1024xf32>\n      %45 = arith.extf %40 : tensor<1x1024xf16> to tensor<1x1024xf32>\n      %46 = arith.mulf %45, %44 : tensor<1x1024xf32>\n      %47 = tt.addptr %32, %arg7 : tensor<1x1024x!tt.ptr<f16>>, tensor<1x1024xi64>\n      %48 = arith.truncf %46 : tensor<1x1024xf32> to tensor<1x1024xf16>\n      tt.store %47, %48, %38 : tensor<1x1024x!tt.ptr<f16>>\n      %49 = arith.addi %arg6, %cst_1 : tensor<1xi32>\n      %50 = arith.addi %arg7, %33 : tensor<1x1024xi64>\n      scf.yield %49, %50 : tensor<1xi32>, tensor<1x1024xi64>\n    }\n    tt.return\n  }\n}\n```\n\n五、初版 PR：\n\n见[PR 16](https://e.gitee.com/HUAWEI-ASCEND/repos/ascend/triton-ascend/pulls/16)\n",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICALFP",
        "clean_data": "问题总结  ：当前Ptr Mask UseAnalysis未支持BlockArgument场景，执行 triton adapter opt 转换时识别到块参数 block argument 类型 tensor 导致工具崩溃退出。需在三个分析中扩展对BlockArgument的处理逻辑，确保在IR转换过程中兼容块参数场景并避免程序异常退出。相关尝试见PR 16。   去除报错上下文细节与IR代码示例，聚焦问题核心：分析未覆盖BlockArgument导致triton adapter opt崩溃，并关联标题中三个分析模块与场景需求",
        "created_at": "2025-05-26T16:36:52+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T16:58:32+08:00"
    },
    {
        "id": 87,
        "source_id": "20648944",
        "title": "MakeTensorPtrCanonicalizer 补齐功能：补全 User 为 tl.advance 的功能和测试用例",
        "body": "",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICAKTS",
        "clean_data": "Describe  MakeTensorPtrCanonicalizer需完善User为tl advance的实现及测试用例",
        "created_at": "2025-05-26T16:02:23+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T16:02:23+08:00"
    },
    {
        "id": 124,
        "source_id": "0248184333059079052",
        "title": "vdec视频解码",
        "body": "<p style=\"margin-top: 0;margin-bottom: 0;\"><span style=\"color: rgb(0,0,0);\"> </span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">atlas</span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"> </span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">2</span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">0</span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">0</span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">i</span></span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"> </span></span></span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">dk</span></span></span></span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"> </span></span></span></span></span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">a</span></span></span></span></span></span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">2</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">开发者套件</span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\"><span style=\"color: rgb(0,0,0);\">，</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"color: rgb(0,0,0);\">使用官方给的VDEC视频解码的例程，最后把H.265视频解码出来为啥是一堆文本文件（而且是乱码），为什么不是yuv420sp格式的图片文件</span></p> ",
        "url": "https://www.hiascend.com/forum/thread-0248184333059079052-1-1.html",
        "clean_data": "标题：vdec视频解码输出乱码 描述：开发者套件使用官方VDEC例程解码H 265视频时，输出结果为乱码文本文件而非预期的YUV420SP格式图像文件。",
        "created_at": "2025-06-03T11:37:39+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T08:23:07+08:00"
    },
    {
        "id": 17,
        "source_id": "19209121",
        "title": "libatt路径找不到",
        "body": "一、问题现象（附报错日志上下文）：\r\nxxxx\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFPUP",
        "clean_data": "libatt路径找不到：需确认libatt库安装路径是否正确配置，检查CANN版本及环境变量设置，并补充具体报错日志与测试步骤以进一步定位问题。",
        "created_at": "2025-01-05T11:03:46+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-05T11:08:22+08:00"
    },
    {
        "id": 53,
        "source_id": "20397638",
        "title": "AttributeError: 'LinearAllreduce' object has no attribute 'hcomm_info'",
        "body": "一、问题现象（附报错日志上下文）：\n  根据 https://gitee.com/ascend/torchair/blob/master/npu_tuned_model/llm/llama/README.md 适配修改deepspeed/module_inject/layers.py的LinearAllreduce后执行单算子出错\n   ```\n   2025-04-30 15:41:18,951 - INFO - [LLM](utils.py:2368): Start to run model in eager(HOST API) mode\nTraceback (most recent call last):\n  File \"/home/ma-user/work/zhongyunde/test/llama149/torchair/npu_tuned_model/llm/llama/benchmark/deepspeed/benchmark_llama.py\", line 152, in <module>\n    run_llama(args.model_path, **config)\n  File \"/home/ma-user/work/zhongyunde/test/llama149/torchair/npu_tuned_model/llm/llama/benchmark/deepspeed/benchmark_llama.py\", line 139, in run_llama\n    model_runner.model_generate(_PROMPTS, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/test/llama149/torchair/npu_tuned_model/llm/llama/benchmark/deepspeed/benchmark_llama.py\", line 81, in model_generate\n    generate_ids = self.model.generate(**kwargs_params)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1541, in generate\n    return self.greedy_search(\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2387, in greedy_search\n    outputs = self(\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/test/llama149/torchair/npu_tuned_model/llm/llama/modeling_llama.py\", line 1322, in forward\n    outputs = self.model(\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/test/llama149/torchair/npu_tuned_model/llm/llama/modeling_llama.py\", line 1092, in forward\n    layer_outputs = decoder_layer(\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/test/llama149/torchair/npu_tuned_model/llm/llama/modeling_llama.py\", line 625, in forward\n    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/test/llama149/torchair/npu_tuned_model/llm/llama/modeling_llama.py\", line 523, in forward\n    attn_output = self.o_proj(attn_output)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/deepspeed/module_inject/layers.py\", line 39, in forward\n    self.hcomm_info)\n  File \"/home/ma-user/work/zhongyunde/source/backup/venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1695, in __getattr__\n    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\nAttributeError: 'LinearAllreduce' object has no attribute 'hcomm_info'\n[ERROR] 2025-04-30-15:41:21 (PID:817589, Device:0, RankID:-1) ERR99999 UNKNOWN application exception\n   ```\n软件版本: （46，30188） \n```\n-- CANN 版本: 8.0.RC3 \n-- transformers           4.31.0  --> 适配llame v2\n-- Tensorflow/Pytorch/MindSpore 版本: torch 2.1.0/torch-npu 2.1.0  \n-- Python 版本 ：Python 3.10.10  （source /home/ma-user/work/zhongyunde/source/backup/venv/bin/activate）\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)): NA \n-- 操作系统版本 (e.g., Ubuntu 18.04): Linux version 4.19.90-vhulk2211.3.0.h1543.eulerosv2r10.aarch64 (cat /proc/version)\n```\n\n三、测试步骤：执行llama v2 单算子模式\n > deepspeed --num_gpus=1 torchair/npu_tuned_model/llm/llama/benchmark/deepspeed/benchmark_llama.py --model_path=llama-70b_qkv --execute_mode=eager\n\nPS: 撤销相应的修改时能正常执行\n![输入图片说明](https://foruda.gitee.com/images/1745999835127936957/dd44cce9_11650004.png \"屏幕截图\")\n\n四、日志信息:\nxxxx\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\n\n日志提供方式:\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\n\n获取方法请参考wiki：\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/torchair/issues/IC56X2",
        "clean_data": "系统改造导致LinearAllreduce算子缺失hcomm info属性：CANN8 0 RC3环境下，根据 npu tuned model官方文档  https   gitee com ascend torchair blob master npu tuned model llm llama README md 修改Deepspeed layers py实现后，执行 deepspeed   num gpus 1 benchmark llama py 单算子测试时出现AttributeError。问题源于自定义LinearAllreduce类未正确继承或实现 hcomm info 属性 错误出现在 modeling llama py 第625行 self o proj 调用链中 。   说明：该描述聚焦于标题中的核心问题本质，精简了版本依赖关系和错误定位路径，保留关键调试线索。无法进一步精简包管理路径和代码行号等关键定位信息",
        "created_at": "2025-04-30T15:47:50+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-30T15:58:02+08:00"
    },
    {
        "id": 594,
        "source_id": "20785905",
        "title": "CVE-2024-1135",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-1135](https://nvd.nist.gov/vuln/detail/CVE-2024-1135)\n漏洞归属组件：gunicorn\n漏洞归属的版本：20.1.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nGunicorn fails to properly validate Transfer-Encoding headers, leading to HTTP Request Smuggling (HRS) vulnerabilities. By crafting requests with conflicting Transfer-Encoding headers, attackers can bypass security restrictions and access restricted endpoints. This issue is due to Gunicorn_x27;s handling of Transfer-Encoding headers, where it incorrectly processes requests with multiple, conflicting Transfer-Encoding headers, treating them as chunked regardless of the final encoding specified. This vulnerability allows for a range of attacks including cache poisoning, session manipulation, and data exposure.\n\n漏洞公开时间：2024-04-16 08:15:07\n漏洞创建时间：2025-06-09 09:11:24\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-1135\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDII9",
        "clean_data": "CVE 2024 1135：Gunicorn 20 1 0处理Transfer Encoding头时误识别冲突请求 如多重编码参数 ，导致HTTP请求走私漏洞，允许攻击者绕过安全机制访问受限接口并引发缓存污染 会话劫持等风险。",
        "created_at": "2025-06-09T09:11:24+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:25+08:00"
    },
    {
        "id": 102,
        "source_id": "20723042",
        "title": "FlowModelCache中静态方法封装错误",
        "body": "针对新增图编译缓存CompiledModelCache中无法调用FlowModelCache的非静态类方法的问题，当前在FlowModelCache中封装静态方法，封装方式有误。需要在FlowModelBuilder中新增静态类方法，将FlowModelCache对象的定义、Init和TryLoad方法调用封装进该方法中，最终对CompiledModelCache只暴露其返回的FlowModel中的ComputedGraphPtr（CompiledModelCache中只需要该指针），不要向CompiledModelCache暴露任何FlowModelCache的细节。\r\n\r\n需要配套修改CompiledModelCache中的调用代码。",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICC602",
        "clean_data": "FlowModelCache静态方法封装错误：需在FlowModelBuilder中封装FlowModelCache对象定义及Init TryLoad方法调用，向CompiledModelCache仅暴露ComputedGraphPtr返回，避免依赖关系外泄。需同步修正CompiledModelCache的调用方式。",
        "created_at": "2025-06-03T14:47:30+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T17:29:01+08:00"
    },
    {
        "id": 25,
        "source_id": "19609811",
        "title": "torch.compile还不支持torch.all_to_all算子以及torch.all_gather算子",
        "body": "torch.compile还不支持torch.all_to_all算子以及torch.all_gather算子",
        "url": "https://gitee.com/ascend/torchair/issues/IBOB0Z",
        "clean_data": "当前torch compile不支持分布式通信算子all to all与all gather",
        "created_at": "2025-02-24T10:30:27+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-24T10:30:27+08:00"
    },
    {
        "id": 64,
        "source_id": "20536518",
        "title": "CVE-2025-47279",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-47279](https://nvd.nist.gov/vuln/detail/CVE-2025-47279)\n漏洞归属组件：undici\n漏洞归属的版本：6.21.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nA vulnerability was found in nodejs undici up to 5.28.x/6.21.1/7.4.x. It has been rated as problematic. This issue affects an unknown function. Upgrading to version 5.29.0, 6.21.2 or 7.5.0 eliminates this vulnerability. Applying a patch is able to eliminate this problem. The bugfix is ready for download at github.com. The best possible mitigation is suggested to be upgrading to the latest version.\n\n漏洞公开时间：2025-05-16 03:07:18\n漏洞创建时间：2025-05-16 04:40:05\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-47279\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/IC862U",
        "clean_data": "CVE 2025 47279  ：Node js undici组件6 21 1版本存在漏洞，建议升级至5 29 0 6 21 2 7 5 0或应用GitHub补丁修复。详情参考NVD链接。",
        "created_at": "2025-05-16T04:40:05+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-16T04:40:06+08:00"
    },
    {
        "id": 32,
        "source_id": "19937958",
        "title": "[Bug-Report|缺陷反馈]: 调ffnV3得到的output会出现inf、-inf",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\n在特定的输入数据下，调ffnV3得到的output会出现inf、-inf\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\n按文档\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n按照doc编译调用步骤\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\n预期结果不出现inf\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\n无\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n### 所属算子\r\n\r\nFFN\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops-adv/issues/IBVC86",
        "clean_data": "核心问题：FFN算子v3在特定输入下输出含inf  inf  简化描述：调用FFNv3算子时，部分输入数据导致输出结果出现无穷大值 inf  inf ，不符合预期无异常值的输出要求。问题可复现性已在文档标准环境下验证，需排查输入数据有效性或算子实现安全性。",
        "created_at": "2025-03-21T17:49:53+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-21T22:01:37+08:00"
    },
    {
        "id": 51,
        "source_id": "20391810",
        "title": "[版本匹配] 现在Llama2是不是可以使用新的transformers==4.44.2",
        "body": "在 https://gitee.com/ascend/torchair/blob/master/npu_tuned_model/llm/llama/README.md#llama2llama3 中看到 Llama2匹配transformers==4.31.0，请问如何才能确认当前是否匹配 ？\r\n我已经能够跑非图模式，是否就已经代表环境是没有问题了？(基于torchair跑图模式有点问题，还在确认是本身的测试脚本问题，还是其它环境问题)\r\n\r\n\r\n软件版本: （46，30188） \r\n```\r\n-- CANN 版本: 8.0.RC3 \r\n-- Tensorflow/Pytorch/MindSpore 版本: torch 2.1.0/torch-npu 2.1.0  \r\n-- Python 版本 ：Python 3.10.10  （source /home/ma-user/work/zhongyunde/source/backup/venv/bin/activate）\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)): NA \r\n-- 操作系统版本 (e.g., Ubuntu 18.04): Linux version 4.19.90-vhulk2211.3.0.h1543.eulerosv2r10.aarch64 (cat /proc/version)\r\n```\r\n\r\n参考 https://gitee.com/ascend/modelzoo/issues/IC4W6L?from=project-issue",
        "url": "https://gitee.com/ascend/torchair/issues/IC52F6",
        "clean_data": "Llama2版本兼容transformers 4 44 2需确认：   1  通过官方文档链接 gitee com ascend torchair 中llm llama目录的README md检查版本要求   2  非图模式运行正常仅代表环境基础可用，图模式异常需排查测试脚本或驱动适配问题   3  文档当前记录为transformers  4 31 0，新版本4 44 2可能存在兼容性差异，建议参考模型zoo issue页面更新说明     根据提供的技术栈信息：CANN 8 0 RC3   PyTorch 2 1 0   Python 3 10，需注意4 31 0至4 44 2版本间的API变更",
        "created_at": "2025-04-30T09:45:03+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-30T09:45:03+08:00"
    },
    {
        "id": 72,
        "source_id": "20553077",
        "title": "[Bug-Report|缺陷反馈]: isamax算子在香橙派 Ascend310b 大部分样例结果错误 ",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\n算子名称：isamax\r\n算子链接：https://gitee.com/ascend/cann-ops/tree/master/src/math/isamax\r\n\r\n大部分样例结果错误，还有部分超时，仅有下面三个样例顺利通过\r\n\r\n============test 1=============\r\n1\r\n{'id': 1, 'shape': [1], 'n': 1, 'incx': 1, 'dtype': 'fp32'}\r\n\r\n============test 2=============\r\n2\r\n{'id': 2, 'shape': [7], 'n': 7, 'incx': 1, 'dtype': 'fp32'}\r\n\r\n============test 11=============\r\n11\r\n{'id': 11, 'shape': [9], 'n': 9, 'incx': 1, 'dtype': 'fp32'}\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\n香橙派AIPro\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n算子增加.AddConfig后在香橙派AIPro测试\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\n测试case均通过\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\n![输入图片说明](https://foruda.gitee.com/images/1747479209073860852/8f05bab2_12901623.png \"屏幕截图 2025-05-17 184756.png\")\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/IC8IUT",
        "clean_data": "isamax算子在Ascend310b平台多数测试用例报错 超时缺陷    核心问题描述：isamax算子在香橙派AIPro设备执行时，绝大多数测试案例出现计算结果错误或超时异常，仅3个样例通过 id 1 2 11，n 1 9，步长 1，数据类型均为FP32 。    关联信息：   1  环境：Ascend310b 香橙派AIPro    2  触发方式：AddConfig新增配置后测试   3  影响范围：非特定单一场景，需排查通用配置异常或实现缺陷",
        "created_at": "2025-05-17T18:54:29+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-17T18:54:29+08:00"
    },
    {
        "id": 568,
        "source_id": "20780850",
        "title": "CVE-2022-0329",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-0329](https://nvd.nist.gov/vuln/detail/CVE-2022-0329)\n漏洞归属组件：loguru\n漏洞归属的版本：0.5.3\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\n** REJECT ** DO NOT USE THIS CANDIDATE NUMBER. Reason: This CVE has been rejected as it was incorrectly assigned. All references and descriptions in this candidate have been removed to prevent accidental usage.\n\n漏洞公开时间：2022-01-22 00:15:00\n漏洞创建时间：2025-06-08 00:20:27\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-0329\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDELU",
        "clean_data": "CVE 2022 0329  loguru 0 5 3  已被NVD拒绝，编号不可用，描述内容无效或错误分配。",
        "created_at": "2025-06-08T00:20:27+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:20:27+08:00"
    },
    {
        "id": 156,
        "source_id": "0248184409371838065",
        "title": "在python的accelerate库中，调用自定义算子训练时报错",
        "body": "<div class=\"cke-article\"><p style=\"background-color: rgb(255,255,255);letter-spacing: normal;text-transform: none;white-space: normal;word-spacing: 0.0px;\">在python中，调用自定义算子进行训练时，报错如下：</p>  <p style=\"background-color: rgb(255,255,255);letter-spacing: normal;text-transform: none;white-space: normal;word-spacing: 0.0px;\"><em>RuntimeError: Failed to find function HcclCommInitRootInfoConfig</em></p>  <p style=\"background-color: rgb(255,255,255);letter-spacing: normal;text-transform: none;white-space: normal;word-spacing: 0.0px;\"><em>[ERROR] 2025-06-03-21:12:13 (PID:2139650, Device:0, RankID:0) ERR02008 DIST resource not found</em></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184409371838065-1-1.html",
        "clean_data": "在使用昇腾自定义算子时，调用HcclCommInitRootInfoConfig函数导致ERR02008分布式资源加载失败。   问题表现为自定义算子训练时出现HCCL通信初始化异常，关联hccl工具配置缺失或rank表参数错误。",
        "created_at": "2025-06-04T08:49:32+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T01:10:52+08:00"
    },
    {
        "id": 603,
        "source_id": "20786772",
        "title": "CVE-2022-28346",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-28346](https://nvd.nist.gov/vuln/detail/CVE-2022-28346)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nAn issue was discovered in Django 2.2 before 2.2.28, 3.2 before 3.2.13, and 4.0 before 4.0.4. QuerySet.annotate(), aggregate(), and extra() methods are subject to SQL injection in column aliases via a crafted dictionary (with dictionary expansion) as the passed **kwargs.\n\n漏洞公开时间：2022-04-12 13:15:00\n漏洞创建时间：2025-06-09 09:41:16\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-28346\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDJ6C",
        "clean_data": "CVE 2022 28346：Django 3 2 7版本中，QuerySet的annotate  、aggregate  和extra  方法存在SQL注入漏洞，攻击者可通过恶意字典参数 含字典展开 注入列别名。建议升级至3 2 13、4 0 4以上版本或2 2 28以上版本以修复。",
        "created_at": "2025-06-09T09:41:16+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:41:16+08:00"
    },
    {
        "id": 147,
        "source_id": "02108173815438515275",
        "title": "sensevoice推理报错",
        "body": "<div class=\"cke-article\"><p>参考昇腾仓库<a href=\"cid:link_0\" rel=\"nofollow\" target=\"_blank\">ACL_PyTorch/built-in/audio/SenseVoice · Ascend/ModelZoo-PyTorch - 码云 - 开源中国</a></p>  <p>在香橙派AI PRO上部署sensevoice发生错误</p>  <p>1、出现问题时，您做了哪些操作？</p>  <p>答复：执行推理代码</p>  <p>python3 infer_onnx.py --model_path=SenseVoiceSmall --om_path=model_linux_aarch64.om --device=0 --input=&quot;./SenseVoiceSmall/example/zh.mp3&quot;</p>  <p>2、在哪个步骤出现了问题？</p>  <p>答复：acl.init失败</p>  <p>3、您希望得到什么结果？</p>  <p>答复：成功执行推理代码</p>  <p>4、您实际得到什么结果？</p>  <p>答复：</p>  <p>5、请附上您出现问题页面的整屏截图或者日志信息;</p>  <p>日志信息如下</p>  <p>答复：</p>  <p>(base) HwHiAiUser@orangepiaipro-20t:~/ModelZoo-PyTorch/ACL_PyTorch/built-in/audio/SenseVoice/SenseVoice$ python3 infer_onnx.py --model_path=SenseVoiceSmall --om_path=SenseVoice_linux_aarch64.om --device=0 --input=&quot;./SenseVoiceSmall/example/zh.mp3&quot; --perform=True --loop=20 /home/HwHiAiUser/.local/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:301: ImportWarning: ************************************************************************************************************* The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now.. The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now.. The backend in torch.distributed.init_process_group set to hccl now.. The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now.. The device parameters have been replaced with npu in the function below: torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.set_default_device, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty ************************************************************************************************************* warnings.warn(msg, ImportWarning) /home/HwHiAiUser/.local/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu. warnings.warn(msg, RuntimeWarning) Loading remote code successfully: model [ERROR] acl init failed [INFO] open device 0 success [ERROR] load model from file failed, model file is SenseVoice_linux_aarch64.om [WARN] Check failed:processModel-&gt;LoadModelFromFile(modelPath), ret:1 [WARN] no model had been loaded, unload failed Traceback (most recent call last): File &quot;/home/HwHiAiUser/ModelZoo-PyTorch/ACL_PyTorch/built-in/audio/SenseVoice/SenseVoice/infer_onnx.py&quot;, line 113, in &lt;module&gt; om_sess = InferSession(args.device, args.om_path) File &quot;/usr/local/miniconda3/lib/python3.9/site-packages/ais_bench/infer/interface.py&quot;, line 26, in __init__ self.session = aclruntime.InferenceSession(self.model_path, self.device_id, options) RuntimeError: [1][ACL: invalid parameter] [W compiler_depend.ts:305] Warning: NPU warning, error code is 107003[Error]: [Error]: The stream is not in the current context. Check whether the context where the stream is located is the same as the current context. EE9999: Inner Error! EE9999: [PID: 39861] 2025-02-02-01:20:12.009.649 Stream destroy failed, stream is not in current ctx, stream_id=1.[FUNC:StreamDestroy][FILE:api_impl.cc][LINE:1096] TraceBack (most recent call last): rtStreamDestroyForce execute failed, reason=[stream not in current context][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53] destroy stream force failed, runtime result = 107003[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161] (function operator()) [ERROR] 2025-02-02-01:20:14 (PID:39861, Device:0, RankID:-1) ERR99999 UNKNOWN application exception</p>  <pre><br><br></pre></div>",
        "url": "https://www.hiascend.com/forum/thread-02108173815438515275-1-1.html",
        "clean_data": "问题标题：sensevoice推理报错   问题描述：在香橙派AI PRO设备执行 python3 infer onnx py 进行sensevoice推理时出现 acl init failed 错误 错误码107003 ，提示 stream not in current context ，确认模型路径和上下文是否配置正确，需检查ACL运行时环境初始化步骤。",
        "created_at": "2025-02-01T18:03:59+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-11T12:57:48+08:00"
    },
    {
        "id": 58,
        "source_id": "20435196",
        "title": "[Requirement|需求建议]:  QuantBatchMatmulV3性能优化",
        "body": "### Backgroud（背景信息）\r\n\r\n一下场景为 deepseek-r1 模型：\r\n\r\n该场景下，cube利用率较低，需要优化：\r\n\r\naclnnQuantMatmulV4_QuantBatchMatmulV3_QuantBatchMatmulV3,\r\nInput Shapes： \"1,7168;256,7168;256;1\" INT8;INT8;FLOAT;FLOAT\r\nOutput Shape：\"1,256\" FLOAT16\r\ncube_utilization(%)：13.6%\r\n\r\n该场景下，cube利用率较高，\r\n\r\naclnnQuantMatmulV4_QuantBatchMatmulV3_QuantBatchMatmulV3,\r\nInput Shapes： \"1,128;7168,128;7168;1\" INT8;INT8;FLOAT;FLOAT\r\nOutput Shape：\"1,7168\" FLOAT16\r\ncube_utilization(%)：75%\r\n\r\n### Origin（信息来源）\r\n\r\ntele\r\n\r\n### Benefit / Necessity （价值/作用）\r\n\r\n提升 deepseek-r1 模型运行效率\r\n\r\n### Design（设计方案）\r\n\r\n争对性优化 Input Shapes： \"1,7168;256,7168;256;1\" 输入场景下的性能\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/IC5ZWC",
        "clean_data": "标题：QuantBatchMatmulV3性能优化建议 描述：针对deepseek r1模型中 1 7168 256 7168 256 1 输入场景 INT8 INT8 FLOAT FLOAT 提出QuantBatchMatmulV3算子优化需求，当前cube利用率仅13 6 ，需提升至更高效率水平。",
        "created_at": "2025-05-07T15:04:06+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-07T15:04:06+08:00"
    },
    {
        "id": 70,
        "source_id": "20552948",
        "title": "[Bug-Report|缺陷反馈]: sasum在香橙派 Ascend310b 大部分样例结果错误",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\n1.sasum算子添加Ascend910b平台，编译期间报错，将op_kernel/sasum_aiv.h:182中，PIPE_V调整为PIPE_ALL\r\n编译通过。\r\n![输入图片说明](https://foruda.gitee.com/images/1747476819869699553/85910cb7_9064116.png \"屏幕截图\")\r\n2. case50样例测试，\r\n[test pass]:47\r\n![输入图片说明](https://foruda.gitee.com/images/1747477064623774948/7b8fd360_9064116.png \"屏幕截图\")\r\n[result error]:0-45\r\n![输入图片说明](https://foruda.gitee.com/images/1747477048914771081/009d565e_9064116.png \"屏幕截图\")\r\n[run case timeout]:46,48\r\n![输入图片说明](https://foruda.gitee.com/images/1747477077271513650/f12139d3_9064116.png \"屏幕截图\")\r\n[generate input failed]:49\r\n![输入图片说明](https://foruda.gitee.com/images/1747477090462585713/31541eb4_9064116.png \"屏幕截图\")\r\n\r\n\r\n\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\nos:Ubuntu 22.04.3 LTS\r\nAscend310b\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n1. cann-ops-master/src/math/sasum/op_host/sasum.cpp 142:增加AddConfig(\"ascend310b\")\r\n2. cann-ops-master/下：bash build.sh -n sasum\r\n3. cann-ops-master/build-out/下：./CANN-custom_ops--linux.aarch64.run\r\n4. case_50/sasum/AclNNInvocation_test50下：./run_all.sh\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\n1. 算子编译通过\r\n2. 算子部署成功\r\n3. case50全部通过\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\n![输入图片说明](https://foruda.gitee.com/images/1747477421038236278/e4e2757f_9064116.png \"屏幕截图\")\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/IC8IR8",
        "clean_data": "sasum算子移植Ascend310b后大部分测试样例结果错误：47测试通过 run all sh ，0 45结果错误，46 48测试超时，49生成输入失败。",
        "created_at": "2025-05-17T18:23:50+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-17T18:23:50+08:00"
    },
    {
        "id": 109,
        "source_id": "20731222",
        "title": "回合代码版本有误",
        "body": "一、问题现象（附报错日志上下文）：\r\nxxxx\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICCCBA",
        "clean_data": "标题：回合代码版本有误 描述：代码版本兼容性异常，请补充CANN 框架 Python版本等关键信息及日志附件，并参考wiki规范提交问题： 日志获取指引  https   gitee com ascend modelzoo wikis  E5 A6 82 E4 BD 95 E8 8E B7 E5 8F 96 E6 97 A5 E5 BF 97 E5 92 8C E8 AE A1 E7 AE 97 E5 9B BE sort id 4097825",
        "created_at": "2025-06-04T08:43:40+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T08:43:44+08:00"
    },
    {
        "id": 62,
        "source_id": "20506066",
        "title": "cann7.1又支持的torchair版本吗",
        "body": "cann7.1又支持的torchair版本吗",
        "url": "https://gitee.com/ascend/torchair/issues/IC7IKY",
        "clean_data": "标题：cann7 1支持的TorchAir版本 回复：CANN7 1未明确列出TorchAir兼容性，建议查阅昇腾官方发布的兼容性文档或联系技术支持确认当前支持范围。",
        "created_at": "2025-05-13T17:39:11+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-13T17:39:11+08:00"
    },
    {
        "id": 54,
        "source_id": "20398246",
        "title": "CVE-2025-32428",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-32428](https://nvd.nist.gov/vuln/detail/CVE-2025-32428)\n漏洞归属组件：jupyter\n漏洞归属的版本：1.0.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nJupyter Remote Desktop Proxy allows you to run a Linux Desktop on a JupyterHub. jupyter-remote-desktop-proxy was meant to rely on UNIX sockets readable only by the current user since version 3.0.0, but when used with TigerVNC, the VNC server started by jupyter-remote-desktop-proxy were still accessible via the network. This vulnerability does not affect users having TurboVNC as the vncserver executable. This issue is fixed in 3.0.1.\n\n漏洞公开时间：2025-04-15 08:15:14\n漏洞创建时间：2025-04-30 16:13:32\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-32428\n",
        "url": "https://gitee.com/ascend/modelzoo-TensorFlow-bak/issues/IC57DY",
        "clean_data": "标题：CVE 2025 32428  Jupyter Remote Desktop Proxy v3 0 0使用TigerVNC时，其启动的VNC服务未限制为仅UNIX套接字访问导致暴露于网络，TurboVNC用户不受影响。该漏洞已在3 0 1版本修复。   参考链接：https   nvd nist gov vuln detail CVE 2025 32428",
        "created_at": "2025-04-30T16:13:32+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-30T16:13:32+08:00"
    },
    {
        "id": 101,
        "source_id": "20721615",
        "title": "FlowModelCache实例需要deployer::VarDescInfo::VarDescInfo(google::protobuf::Arena*)符号，libge_runner.so无法冲libge_compiler.so找到该符号，导致运行报错。",
        "body": "一、问题现象（附报错日志上下文）：\r\nFlowModelCache实例需要deployer::VarDescInfo::VarDescInfo(google::protobuf::Arena*)符号，libge_runner.so无法冲libge_compiler.so找到该符号，导致运行报错。\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (e.g., Python 3.7.5):\r\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\r\n--操作系统版本 (e.g., Ubuntu 18.04):\r\n\r\n三、测试步骤：\r\nxxxx\r\n\r\n\r\n四、日志信息:\r\nxxxx\r\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\r\n\r\n日志提供方式:\r\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\r\n\r\n获取方法请参考wiki：\r\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/ICC4WF",
        "clean_data": "FlowModelCache实例运行需依赖libge compiler so导出的deployer  VarDescInfo google  protobuf  Arena  构造函数符号，但实际因libge runner so未定位到该符号导致错误。",
        "created_at": "2025-06-03T13:58:55+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-03T17:29:15+08:00"
    },
    {
        "id": 110,
        "source_id": "20732407",
        "title": "简化CI测试的UT用例数量",
        "body": "",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICCD87",
        "clean_data": "简化CI测试的UT用例数量：通过参数化测试覆盖多场景、合并冗余用例、代码重构提升复用率、移除无效测试及优化逻辑减少重复。",
        "created_at": "2025-06-04T09:40:44+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T09:40:45+08:00"
    },
    {
        "id": 67,
        "source_id": "20552664",
        "title": "[Bug-Report|缺陷反馈]: scasum在Atlas 200I DK A2测试泛化性不足，部分shape运行结果精度异常",
        "body": "### Describe the current behavior / 问题描述 (Mandatory / 必填)\r\n\r\n1. （在仅保留src中common以及math下scasum算子的前提下），算子编译报错：\r\n/home/trybest/cann-ops/build/binary/ascend310b/src/scasum/scasum_aiv.h:165:18: error: the ranges of 1st parameter must be [2,6],[10, 10]: pipe barrier(PIPE V),\r\n1 error generated.\r\n\r\n2. (以下结果均为将PIPE_V修改为PIPE_ALL的前提下）：\r\ntest 17，41，42，43，44，45，46，47通过（且通过精度测试），\r\ntest 48，49报错信息如下：\r\n============test 48=============\r\n48\r\n{'id': 48, 'shape': [64328047], 'n': 64328047, 'incx': 1, 'dtype': 'complex64'}\r\nrun_all.sh: line 67: 111280 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 111287 Killed                  timeout 15 ./execute_scasum_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/scasum/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/scasum/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_48 : 2025-05-17 17:32:54\r\n\r\n============test 49=============\r\n49\r\n{'id': 49, 'shape': [91789870], 'n': 91789870, 'incx': 1, 'dtype': 'complex64'}\r\nrun_all.sh: line 67: 111686 Killed                  python3 gen_data.py $i\r\nERROR: generate input data failed!\r\nrun_all.sh: line 44: return: can only `return' from a function or sourced script\r\nINFO: generate input data success!\r\n[ERROR]  failed to get file ../input/input_x.bin\r\n[INFO]  Set input success\r\nrun_all.sh: line 67: 111693 Killed                  timeout 15 ./execute_scasum_op $i\r\nTraceback (most recent call last):\r\n  File \"/root/case_50/scasum/AclNNInvocation_test50/verify_result.py\", line 35, in <module>\r\n    verify_result(sys.argv[1],sys.argv[2])\r\n  File \"/root/case_50/scasum/AclNNInvocation_test50/verify_result.py\", line 20, in verify_result\r\n    real_result = np.fromfile(real_result, dtype=dtype) # 从bin文件读取实际运算结果\r\nFileNotFoundError: [Errno 2] No such file or directory: 'output/output_z.bin'\r\n\r\ncase_49 : 2025-05-17 17:33:25\r\n\r\n其余test均报错：\r\nINFO: generate input data success!\r\n[INFO]  Set input success\r\n[INFO]  Write output success\r\n[ERROR] result error\r\n\r\n### Environment / 环境信息 (Mandatory / 必填)\r\n\r\nAtlas 200I DK A2\r\n\r\n### Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)\r\n\r\n1. 算子增加.AddConfig后在Atlas 200I DK A2测试；\r\n2. 仅保留src中common以及math下scasum算子目录，其余算子目录均删除。\r\n3. 因为编译报错，后续测试结果将PIPE_V修改为PIPE_ALL，重新编译运行。\r\n\r\n### Describe the expected behavior / 预期结果 (Mandatory / 必填)\r\n\r\n测试case均通过\r\n\r\n### Related log / screenshot / 日志 / 截图 (Mandatory / 必填)\r\n\r\n![编译报错](https://foruda.gitee.com/images/1747474728576915324/2f913f3c_11921186.png \"1.png\")\r\n\r\n![大部分样例报错](https://foruda.gitee.com/images/1747474793340722631/e68f8ca5_11921186.png \"2.png\")\r\n\r\n![测试结果与最后两个样例报错](https://foruda.gitee.com/images/1747474826171104412/64f153af_11921186.png \"3.png\")\r\n\r\n\r\n### Special notes for this issue/备注 (Optional / 选填)\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops/issues/IC8IJC",
        "clean_data": "scasum算子在Atlas 200I A2设备上泛化测试异常     1  用户保留 scasum 算子目录后编译报错：提到 pipe barrier PIPE V  的参数范围限制需满足  2 6   10 10  ，修改为 PIPE ALL 后部分测试通过。   2    测试case 48 49  执行时因数据生成  gen data py  或模型运行被强制终止  Killed  ，且无法读取输出文件 output z bin   FileNotFoundError  。   3    其余测试  均报 result error 异常。      缺少的依赖或配置问题  ：     删除其他算子目录可能导致编译依赖缺失或资源配置异常 如VDCN DCU参数未正确扩展 。      scasum 未适配大维度数据 如 shape  64328047   91789870   dtype complex64  的内存或执行超时。      解决方向  ：     检查编译参数范围限制是否与CANN版本兼容 建议升级版本或手动扩展支持范围 。     分析 Killed 原因 内存占用、超时限制 并增加资源分配或调整测试超时时间  timeout 15  。     验证输出文件缺失是否因内部错误未提前终止，需补充完整日志或添加错误异常捕获逻辑。     注：用户未提供自定义 AddConfig内容，可能影响问题定位精细度。",
        "created_at": "2025-05-17T17:41:20+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T17:20:41+08:00"
    },
    {
        "id": 144,
        "source_id": "02113175152884692058",
        "title": "om推理报错",
        "body": "<div class=\"cke-article\"><p>我在910机器转换模型生成om。部署到200l A2,推理报错。<br> <span class=\"easyimage easyimage-full\"><img alt=\"cke_1716.png\" src=\"cid:pic_0\"></span></p>  <p></p>  <p>我知道是芯片型号不匹配，之前使用atlas300VP转出的模型，在200la2 上可以正常使用。<br> atlas300Vp的soc_version是310P3  ,意思是310p3是是可以在310b1上使用？目前300vP价格太贵，比较便宜的型号(atlas300v )转出的模型，能否部署在atlas200l a2上？  或者您这边能告诉下 哪些设备转出的模型可以成功部署在200la2上吗？ <br> 由于设备下单就无法退换，我们想确定一个可用的型号能转模型，并转出的模型可以部署在200la2上</p></div>",
        "url": "https://www.hiascend.com/forum/thread-02113175152884692058-1-1.html",
        "clean_data": "昇腾设备模型转换与200L A2兼容性问题 使用Ascend 910转换的OM模型部署到200L A2时推理失败。已验证Ascend 300VP 对应soc version 310P3 可以兼容310B1机型使用。现需确认Ascend 300V 310V 是否能正常转换并部署在200LA2，以及具体哪些型号设备转出的模型可支持该平台，避免设备采购后失效。",
        "created_at": "2025-02-17T05:34:45+08:00",
        "topic_summary": "开发者在模型转换OM格式时在转换过程和推理时经常遇到报错，需要寻求支持",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-17T07:49:25+08:00"
    },
    {
        "id": 153,
        "source_id": "0284179983532114019",
        "title": "【Ascend C标准算子编译报错问题解决方案(持续更新)】",
        "body": "<div class=\"cke-article\"><p>持续更新中。</p>  <p>案例1：<span><span>CANN</span></span><span><span>包安装路径填写错误</span></span></p>  <p style=\"text-align: justify;\"><span><span>报错截图：</span></span></p>  <p style=\"text-align: justify;\"><span class=\"easyimage easyimage-full\"><img alt=\"cke_823.png\" src=\"cid:pic_0\"></span></p>  <p style=\"text-align: justify;\"><span><span>关键信息：fatal error: register/tilingdata_base.h: No such file or directory</span></span></p>  <p style=\"text-align: justify;\"><span><span>解决方案：修改CMakePresets.json中ASCEND_CANN_PACKAGE_PATH路径为CANN包安装路径</span></span></p>  <p style=\"text-align: justify;\"></p>  <p style=\"text-align: justify;\">案例2：<span><span>在算子工程中添加了API不支持的</span></span>产品系列</p>  <p style=\"text-align: justify;\"><span><span>报错截图：</span></span></p>  <p style=\"text-align: justify;\"><span class=\"easyimage easyimage-full\"><img alt=\"cke_28899.png\" src=\"cid:pic_1\"></span></p>  <p style=\"text-align: justify;\"><span><span>关键信息：no member named 'Cos' in namespace 'AscendC'</span></span></p>  <p style=\"text-align: justify;\"><span><span>解决方案：用支持此</span></span>产品系列<span><span>的API完成算子功能</span></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0284179983532114019-1-1.html",
        "clean_data": "Ascend C标准算子编译报错解决方案汇总2例：1  CANN安装路径错误：编译时提示 register tilingdata base h不存在 ，需修正CMakePresets json中ASCEND CANN PACKAGE PATH路径2  调用未支持API：报错 no member named  Cos  in namespace  AscendC  ，应使用API兼容的产品系列实现算子",
        "created_at": "2025-04-14T03:25:32+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-21T08:33:22+08:00"
    },
    {
        "id": 609,
        "source_id": "20789334",
        "title": "CVE-2025-23815",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-23815](https://nvd.nist.gov/vuln/detail/CVE-2025-23815)\n漏洞归属组件：cookie\n漏洞归属的版本：0.7.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nCross-Site Request Forgery (CSRF) vulnerability in linickx root Cookie allows Cross Site Request Forgery. This issue affects root Cookie: from n/a through 1.6.\n\n漏洞公开时间：2025-01-17 05:15:22\n漏洞创建时间：2025-06-09 11:11:02\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-23815\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDL5I",
        "clean_data": "CVE 2025 23815：linickx root Cookie组件在0 7 1至1 6版本存在CSRF跨站请求伪造漏洞，已公开 2025 01 17 。",
        "created_at": "2025-06-09T11:11:02+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T11:11:02+08:00"
    },
    {
        "id": 610,
        "source_id": "20790488",
        "title": "CVE-2020-36242",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2020-36242](https://nvd.nist.gov/vuln/detail/CVE-2020-36242)\n漏洞归属组件：cryptography\n漏洞归属的版本：2.1.4\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn the cryptography package before 3.3.2 for Python, certain sequences of update calls to symmetrically encrypt multi-GB values could result in an integer overflow and buffer overflow, as demonstrated by the Fernet class.\n\n漏洞公开时间：2021-02-08 04:15:12\n漏洞创建时间：2025-06-09 11:50:31\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2020-36242\n",
        "url": "https://gitee.com/ascend/modelzoo-TensorFlow-bak/issues/ICDM1K",
        "clean_data": "CVE 2020 36242  cryptography 2 1 4及以下版本在使用对称加密处理多GB数据时，多次调用update  方法可能发生整数溢出 缓冲区溢出问题。建议升级至3 3 2及以上版本。参考链接：https   nvd nist gov vuln detail CVE 2020 36242",
        "created_at": "2025-06-09T11:50:31+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T11:50:31+08:00"
    },
    {
        "id": 11,
        "source_id": "19208991",
        "title": " 【Codegen、ATT】符号常量后端生成代码时直接使用字面值，无需GetName",
        "body": "一、问题现象（附报错日志上下文）：\nxxxx\n\n对于符号常量，例如auto symbol = Symbol(5)\nsymbol->Str()方法返回的是一个字面值\"5\"。\n对于符号变量，auto symbol = symbol(\"s0\")\nsymbol->Str()方法返回的是\"s0\"\n\n后端codegen时对于符号都是处理类似于\ntiling_data中：\nTILING_DATA_DEF(xxx_name, symbol->Str())\n\ntiling func中：\nauto symbol->Str() = XXX。\n\n此时如果是常量符号，codegen出来的代码可能是无法直接进行c++编译的。\n当前后端都是按照动态shape处理的，需要处理一下常量符号场景。\n\n\n\n二、软件版本:\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  \n--Tensorflow/Pytorch/MindSpore 版本:\n--Python 版本 (e.g., Python 3.7.5):\n-- MindStudio版本 (e.g., MindStudio 2.0.0 (beta3)):\n--操作系统版本 (e.g., Ubuntu 18.04):\n\n三、测试步骤：\nxxxx\n\n\n四、日志信息:\nxxxx\n请根据自己的运行环境参考以下方式搜集日志信息，如果涉及到算子开发相关的问题，建议也提供UT/ST测试和单算子集成测试相关的日志。\n\n日志提供方式:\n将日志打包后作为附件上传。若日志大小超出附件限制，则可上传至外部网盘后提供链接。\n\n获取方法请参考wiki：\nhttps://gitee.com/ascend/modelzoo/wikis/%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E5%92%8C%E8%AE%A1%E7%AE%97%E5%9B%BE?sort_id=4097825",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFPR3",
        "clean_data": "Codegen、ATT 符号常量处理导致代码生成失败：后端在生成代码时对常量符号 如Symbol 5  和变量符号 如symbol  s0   均使用symbol  Str  获取名称，而常量符号的实际字面值  5  可能不满足C  编译要求。建议优化codegen逻辑，区分符号类型，在常量场景直接使用字面值，变量场景保留符号名，确保动态shape与常量处理兼容。",
        "created_at": "2025-01-05T10:20:14+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-05T10:24:00+08:00"
    },
    {
        "id": 767,
        "source_id": "20607629",
        "title": "w-为什么显示resizexxV2D算子不支持",
        "body": "300IDUO  机器\r\ncann8.0.RC2配套：\r\n\r\n文档资料只显示需要>=5.0.4 ，但是atc转换失败，搞不懂咋回事，理论上应该支持的\r\n转换报错：\r\n![](https://foruda.gitee.com/images/1747895962239617794/9b3f1b6e_1215735.png \"屏幕截图\")\r\n参考链接：\r\nhttps://gitee.com/ascend/samples/tree/master/cplusplus/level2_simple_inference/n_performance/1_multi_process_thread/deeplabv3_multi_thread_one_device ",
        "url": "https://gitee.com/ascend/samples/issues/IC9OY5",
        "clean_data": "resizexxV2D算子在CANN 8 0 RC2环境中ATC转换失败 报错500002 ，但官方文档标注需  5 0 4。需确认当前ATC版本与CANN配套要求是否匹配，且该算子在8 0 RC2的实际支持状态。建议提供具体模型输入参数和环境版本信息以排查兼容性或转换配置问题。",
        "created_at": "2025-05-22T14:40:22+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-10T15:06:20+08:00"
    },
    {
        "id": 168,
        "source_id": "0292180172684622045",
        "title": "版本报错",
        "body": "<div class=\"cke-article\"><p>版本报错，问题和解决方法如下：<span class=\"easyimage easyimage-full\"><img alt=\"cke_443.png\" src=\"cid:pic_0\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0292180172684622045-1-1.html",
        "clean_data": "社区issue报告版本报错问题，用户尝试在vendor event def json配置自定义事件未实现告警事件，求解决方案。原帖包含截图 需结合上下文查看 。",
        "created_at": "2025-04-16T07:58:05+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-16T07:58:05+08:00"
    },
    {
        "id": 1,
        "source_id": "19188364",
        "title": "测试deepseekv3，手动切分与调整权重时出错。 ",
        "body": "按照README，手动切分与调整权重时出错\n\npython3 scripts/split_weight.py --model-path /home/yhui/llm/DeepSeek-V3 --output-path /home/yhui/llm/DeepSeek-V3-tp --world-size 8\n\nTraceback (most recent call last):\n  File \"/home/yhui/torchair/npu_tuned_model/llm/deepseek_v3/scripts/split_weight.py\", line 193, in <module>\n    origin_model = AutoModelForCausalLM.from_pretrained(args.model_path,\n  File \"/home/yhui/anaconda3/envs/deepseek_v3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 553, in from_pretrained\n    model_class = get_class_from_dynamic_module(\n  File \"/home/yhui/anaconda3/envs/deepseek_v3/lib/python3.10/site-packages/transformers/dynamic_module_utils.py\", line 488, in get_class_from_dynamic_module\n    final_module = get_cached_module_file(\n  File \"/home/yhui/anaconda3/envs/deepseek_v3/lib/python3.10/site-packages/transformers/dynamic_module_utils.py\", line 315, in get_cached_module_file\n    modules_needed = check_imports(resolved_module_file)\n  File \"/home/yhui/anaconda3/envs/deepseek_v3/lib/python3.10/site-packages/transformers/dynamic_module_utils.py\", line 180, in check_imports\n    raise ImportError(\nImportError: This modeling file requires the following packages that were not found in your environment: flash_attn. Run `pip install flash_attn`\n[ERROR] 2025-01-02-17:21:09 (PID:828812, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception\n\nnpu下找不到flash_attn，这个怎么解决",
        "url": "https://gitee.com/ascend/torchair/issues/IBF9U4",
        "clean_data": "DeepSeek V3手动切分权重时因NPU环境缺少flash attn依赖导致错误500002。履行 split weight py 提示ImportError需安装flash attn，并需确认NPU版本兼容性及后续处理逻辑是否适配。  注：500002错误码为NPU通用错误，核心问题是torchair框架对flash attn的依赖检测失败，建议根据社区文档补充GPU专用依赖包，或确认是否触发了NPU模型加载的兼容校验机制。",
        "created_at": "2025-01-02T17:22:23+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-13T21:19:12+08:00"
    },
    {
        "id": 76,
        "source_id": "20560811",
        "title": "w-盒子200DK报错peripheral_api.h",
        "body": "连接摄像头报错：\r\n![输入图片说明](https://foruda.gitee.com/images/1747623214100100359/88e284ec_1215735.png \"屏幕截图\")\r\ncann版本：6.0RC3",
        "url": "https://gitee.com/ascend/samples/issues/IC8OTN",
        "clean_data": "w 盒子200DK调用peripheral api h连接摄像头失败  。   关键信息包括：   1  使用 peripheral api h 涉及的API可能存在调用错误 如初始化或参数配置异常 。   2  设备端SDK需确认与CANN 6 0RC3版本匹配 建议检查固件及驱动兼容性 。",
        "created_at": "2025-05-19T10:53:50+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-22T15:05:20+08:00"
    },
    {
        "id": 612,
        "source_id": "20790927",
        "title": "CVE-2023-36053",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-36053](https://nvd.nist.gov/vuln/detail/CVE-2023-36053)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn Django 3.2 before 3.2.20, 4 before 4.1.10, and 4.2 before 4.2.3, EmailValidator and URLValidator are subject to a potential ReDoS (regular expression denial of service) attack via a very large number of domain name labels of emails and URLs.\n\n漏洞公开时间：2023-07-03 21:15:09\n漏洞创建时间：2025-06-09 12:40:53\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-36053\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDMDR",
        "clean_data": "CVE 2023 36053：Django 3 2 7及之前3 2 x版本、4 x系列在4 1 10和4 2 3之前，因EmailValidator和URLValidator处理大量邮件及URL域名标签存在ReDoS漏洞。",
        "created_at": "2025-06-09T12:40:53+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T12:40:54+08:00"
    },
    {
        "id": 96,
        "source_id": "20692452",
        "title": "补充msprof仿真器抓取triton算子流水图的使用说明",
        "body": "",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICBIEC",
        "clean_data": "msprof仿真器补充说明：如何捕获triton算子流水图并生成性能报告",
        "created_at": "2025-05-29T20:38:09+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-29T20:38:10+08:00"
    },
    {
        "id": 614,
        "source_id": "20790931",
        "title": "CVE-2022-48303",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-48303](https://nvd.nist.gov/vuln/detail/CVE-2022-48303)\n漏洞归属组件：tar\n漏洞归属的版本：7.4.3\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nGNU Tar through 1.34 has a one-byte out-of-bounds read that results in use of uninitialized memory for a conditional jump. Exploitation to change the flow of control has not been demonstrated. The issue occurs in from_header in list.c via a V7 archive in which mtime has approximately 11 whitespace characters.\n\n漏洞公开时间：2023-01-30 12:15:08\n漏洞创建时间：2025-06-09 12:41:01\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-48303\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDMDV",
        "clean_data": "CVE 2022 48303：GNU Tar 7 4 3 存在一个一字节越界读取漏洞，由V7格式归档文件的mtime字段含11个空格触发，可能导致未初始化内存用于条件跳转。详情及修复建议见 NVD漏洞库  https   nvd nist gov vuln detail CVE 2022 48303 。",
        "created_at": "2025-06-09T12:41:01+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T12:41:01+08:00"
    },
    {
        "id": 129,
        "source_id": "02102183375078257181",
        "title": "对 onnxruntime-cann 的一些想法",
        "body": "<p>众所周知 onnx 是一个比较通用的模型，并且运行的时候也比 torch 之类的模型对环境的要求更低。</p> <p>一般的机器运行 onnx 的时候都会求助于 Microsoft 开发的 onnxruntime，并且在 github 上有仓库。</p> <p>在配置 onnxruntime 的时候，有一个参数叫做 <code>Provider</code>，这个有几个取值，其中一个比较基础的就是 CPUExecutionProvider，可能也会有 CUDAExecutionProvide？但是我没用过。本次要说的重点是，我发现 CANN 和 onnxruntime 合作，还提供了一个 onnxruntime-cann。</p> <p>如果我们下载的是 <code>onnxruntime-cann</code>（pip 中 <code>onnxruntime-cann</code> 和 <code>onnxruntime</code> 不能共存），之后 python 语法中还是 <code>import onnxruntime</code>，但是在 <code>Provider</code> 中就可以看到一个 <code>CANNExecutionProvider</code>。</p> <p>所以推理的脚本，和原本 onnx 模型的推理脚本基本是一样的，不一样的只不过是 Provider 中选择 CANN 的 Provider。</p> ",
        "url": "https://www.hiascend.com/forum/thread-02102183375078257181-1-1.html",
        "clean_data": "标题：onnxruntime cann 的 CANNExecutionProvider 配置问题   内容：发现 pip 安装 onnxruntime cann 后需通过 import onnxruntime 方式使用，但其与标准 onnxruntime 包不兼容。需在 Provider 参数中明确指定 CANNExecutionProvider 以启用昇腾后端加速。",
        "created_at": "2025-05-23T09:31:18+08:00",
        "topic_summary": "坛帖和issue无回复，回复无有效信息或者无进一步跟踪",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-23T09:41:05+08:00"
    },
    {
        "id": 45,
        "source_id": "20328902",
        "title": "map下标索引有风险（可能导致意外插入默认值），建议用find或者at",
        "body": "map下标索引有风险（可能导致意外插入默认值），建议用find或者at\r\n\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IC3PVQ",
        "clean_data": "map下标索引可能意外插入默认值，建议改用find或at方法进行访问",
        "created_at": "2025-04-24T17:18:17+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-24T17:18:18+08:00"
    },
    {
        "id": 615,
        "source_id": "20794113",
        "title": "[Question|问题咨询]: AIV实现有计划开源吗",
        "body": "### 问题描述\n\naiv通信kernel实现隐藏在hccl_aiv_op_ascend910B.o，看不到具体实现；有计划开源吗\n\n",
        "url": "https://gitee.com/ascend/cann-hccl/issues/ICDOU9",
        "clean_data": "AIV通信kernel是否开源：当前代码封装在hccl aiv op ascend910B o中未开源，询问是否有计划公开实现",
        "created_at": "2025-06-09T15:25:06+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T22:28:47+08:00"
    },
    {
        "id": 66,
        "source_id": "20545960",
        "title": "Clarify tensor variable names in MLA epilogue",
        "body": "In [block_epilogue_mla_softmax.hpp](https://gitee.com/ascend/ascendc-templates/blob/master/include/act/epilogue/block/block_epilogue_mla_softmax.hpp) and [block_epilogue_mla_rescal_o.hpp](https://gitee.com/ascend/ascendc-templates/blob/master/include/act/epilogue/block/block_epilogue_mla_rescal_o.hpp) there are a bunch of `UbTensor` named `tv`, `lp`, `ls`, `lm`, `hm`, `gm`, `dm`, `ll`, without any comments:\r\n\r\n```cpp\r\n        tvUbTensor16 = resource.ubBuf.template GetBufferByByte<ElementOutput>(LP_UB_TENSOR_OFFSET);\r\n        lpUbTensor32 = resource.ubBuf.template GetBufferByByte<float>(LP_UB_TENSOR_OFFSET);\r\n        lsUbTensor = resource.ubBuf.template GetBufferByByte<float>(LS_UB_TENSOR_OFFSET);\r\n        lmUbTensor = resource.ubBuf.template GetBufferByByte<float>(LM_UB_TENSOR_OFFSET);\r\n        hmUbTensor = resource.ubBuf.template GetBufferByByte<float>(HM_UB_TENSOR_OFFSET);\r\n        gmUbTensor = resource.ubBuf.template GetBufferByByte<float>(GM_UB_TENSOR_OFFSET);\r\n        dmUbTensor = resource.ubBuf.template GetBufferByByte<float>(DM_UB_TENSOR_OFFSET);\r\n        llUbTensor = resource.ubBuf.template GetBufferByByte<float>(LL_UB_TENSOR_OFFSET);\r\n        tvUbTensor = resource.ubBuf.template GetBufferByByte<float>(TV_UB_TENSOR_OFFSET);\r\n```\r\n\r\nand also `lo`, `gl`, `go`, ...\r\n\r\n```cpp\r\n        loUbTensor = resource.ubBuf.template GetBufferByByte<float>(LO_UB_TENSOR_OFFSET);\r\n        dmUbTensor = resource.ubBuf.template GetBufferByByte<float>(DM_UB_TENSOR_OFFSET);\r\n        llUbTensor = resource.ubBuf.template GetBufferByByte<float>(LL_UB_TENSOR_OFFSET);\r\n        glUbTensor = resource.ubBuf.template GetBufferByByte<float>(GL_UB_TENSOR_OFFSET);\r\n        tvUbTensor = resource.ubBuf.template GetBufferByByte<float>(TV_UB_TENSOR_OFFSET);\r\n        goUbTensor32 = resource.ubBuf.template GetBufferByByte<float>(GO_UB_TENSOR_OFFSET);\r\n        goUbTensor16 = resource.ubBuf.template GetBufferByByte<ElementOutput>(GO_UB_TENSOR_OFFSET);\r\n        hmUbTensor = resource.ubBuf.template GetBufferByByte<float>(HM_UB_TENSOR_OFFSET);\r\n        gmUbTensor = resource.ubBuf.template GetBufferByByte<float>(GM_UB_TENSOR_OFFSET);\r\n```\r\n\r\nIt will be very helpful to provide the full names of these variables, and how they map to the FlashAttention formula.\r\n",
        "url": "https://gitee.com/ascend/catlass/issues/IC8DD4",
        "clean_data": "Clarify MLA epilogue tensor abbreviations and FlashAttention formula mapping     Variables in  block epilogue mla softmax hpp  and  block epilogue mla rescal o hpp   e g    tv    lp    ls    lm    hm    gm    dm    ll    lo    gl    go   lack full name explanations and their correspondence to FlashAttention formula symbols  Clarify their semantic mapping to the algorithm s key terms  e g    M    L    O    T    S   and add comments in the code",
        "created_at": "2025-05-16T17:20:11+08:00",
        "topic_summary": "开发者在开发中对API使用，数据类型支持，参数格式等方面要求以及复现样例时对样例的适用范围和环境要求不清晰",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-27T20:37:26+08:00"
    },
    {
        "id": 33,
        "source_id": "19989560",
        "title": "[Question|问题咨询]: 根目录下的cmakelists不是很懂怎么加-g，用msprof工具时无法显示源码，求助",
        "body": "### 问题描述\r\n\r\n 根目录下的cmakelists不是很懂怎么加-g，用msprof工具时无法显示源码，求助\r\n\r\n### 所属算子\r\n\r\nFFN\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-ops-adv/issues/IBWG1K",
        "clean_data": "如何在根目录CMakeLists添加 g调试选项使msprof显示FFN算子源码？  核心矛盾：   未正确添加 g编译选项导致调试信息缺失   msprof无法定位算子对应源代码文件   FFN算子调试过程中缺乏符号信息  操作建议： 1  在顶层CMakeLists txt添加  set CMAKE BUILD TYPE Debug   2  或通过命令行设置  cmake  DCMAKE BUILD TYPE Debug     3  针对特定target添加  set target properties target name PROPERTIES COMPILE FLAGS   g",
        "created_at": "2025-03-26T15:08:28+08:00",
        "topic_summary": "开发者在开发中对API使用，数据类型支持，参数格式等方面要求以及复现样例时对样例的适用范围和环境要求不清晰",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-24T17:01:00+08:00"
    },
    {
        "id": 765,
        "source_id": "20251638",
        "title": "YOLOV5MultiInput里面使用的模型怎么才能通过yolov5训练得到",
        "body": "YOLOV5MultiInput里面使用的模型怎么才能通过yolov5训练得到，通过官方训练的模型通过netron查看，跟YOLOV5MultiInput里面的模型多了一个nms，我如何才能通过训练出相同的模型",
        "url": "https://gitee.com/ascend/EdgeAndRobotics/issues/IC229I",
        "clean_data": "YOLOv5官方训练模型在导出ONNX时自动添加NMS层，而YOLOV5MultiInput模块需要原始无NMS结构的模型。通过训练YOLOv5v7 0版本模型时，在导出ONNX前需修改detect py中的 export onnx   函数，注释掉 self model   torch nn SyncBatchNorm convert sync batchnorm model  和移除 self model   model eval   后导出。最终通过   simplify 参数自定义导出脚本，并在ATC转换时使用   no fusion 选项保留原始结构。",
        "created_at": "2025-04-18T08:58:38+08:00",
        "topic_summary": "开发者在开发中对API使用，数据类型支持，参数格式等方面要求以及复现样例时对样例的适用范围和环境要求不清晰",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-11T10:10:44+08:00"
    },
    {
        "id": 46,
        "source_id": "20329224",
        "title": "int64_t 转换为size_t有截断风险，考虑是否增加校验",
        "body": "int64_t 转换为size_t有截断风险，考虑是否增加校验\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IC3Q4O",
        "clean_data": "int64 t隐式转换size t存在数值溢出风险：当int64 t数值超过size t表示范围时可能引发截断，请确认是否需在向size t转换时添加上界校验，建议提供代码场景或检查使用std  numeric limits  max  进行显式边界判断。",
        "created_at": "2025-04-24T17:31:34+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-24T17:31:34+08:00"
    },
    {
        "id": 618,
        "source_id": "20796222",
        "title": "CVE-2025-5889",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-5889](https://nvd.nist.gov/vuln/detail/CVE-2025-5889)\n漏洞归属组件：brace-expansion\n漏洞归属的版本：1.1.11\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nA vulnerability was found in juliangruber brace-expansion up to 1.1.11. It has been rated as problematic. Affected by this issue is the function expand of the file index.js. Applying the patch a5b98a4f30d7813266b221435e1eaaf25a1b0ac5 is able to eliminate this problem. The bugfix is ready for download at github.com.\n\n漏洞公开时间：2025-06-09 14:24:28\n漏洞创建时间：2025-06-09 16:40:07\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-5889\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDQGU",
        "clean_data": "问题：CVE 2025 5889：brace expansion 1 1 11组件存在漏洞，建议升级或应用修补提交a5b98a4 详情参考链接",
        "created_at": "2025-06-09T16:40:08+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T16:40:08+08:00"
    },
    {
        "id": 619,
        "source_id": "20797292",
        "title": "智算维护工具集目录创建&rank_number智算小工具提交",
        "body": "一、需求场景&价值\r\n在客户现场进行智算训练和问题定位，需要开发智算维护小工具提升维护效率\r\n二、需求建议实现的规格\r\n在开源项目中创建智算维护工具目录，各战队可以在生态环境中孵化智算维护小工具，评价比较好的价值工具收编到智算维护工具链中\r\n",
        "url": "https://gitee.com/ascend/tools/issues/ICDRAK",
        "clean_data": "智算维护工具目录创建与rank number工具提交：为提升智算训练与问题定位维护效率，建议在开源项目中创建专用工具目录，各团队可开发精选维护工具并提交至生态，经评估后优质工具将被整合进智算维护工具链。",
        "created_at": "2025-06-09T17:28:11+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T17:29:50+08:00"
    },
    {
        "id": 628,
        "source_id": "0248185077883805119",
        "title": "【ATC转换模型onnx->om】如何为动态shape维指定输入shape ? ",
        "body": "<div class=\"cke-article\"><p>假如存在如下的一个 脚本导出onnx图，由于<span style=\"color: rgb(255,171,64);\">dynamic_axes={&quot;input&quot;: {0: &quot;batch_size&quot;}, &quot;output&quot;: {0: &quot;batch_size&quot;}} </span>指定存在动态轴，因此如果输入不知道shape时出错，因此当前的问题是如何指定相应的输入 ？</p>  <blockquote> <p> </p>  <p>import torch </p>  <p>import torch.nn as nn </p>  <p>import torch.onnx </p>    <p>class MultiLayerNet(nn.Module): </p>  <p>    def __init__(self): </p>  <p>        super().__init__() </p>  <p>        self.linear1 = nn.Linear(100, 64) </p>  <p>        self.relu1 = nn.ReLU() </p>  <p>        self.linear2 = nn.Linear(64, 32) </p>  <p>        self.relu2 = nn.ReLU() </p>  <p>        self.linear3 = nn.Linear(32, 10) </p>    <p>    def forward(self, x): </p>  <p>        x = self.linear1(x) </p>  <p>        x = self.relu1(x) </p>  <p>        x = self.linear2(x) </p>  <p>        x = self.relu2(x) </p>  <p>        x = self.linear3(x) </p>  <p>        return x </p>    <p># 佈~[建模佞~K孾^佾K </p>  <p>model = MultiLayerNet() </p>  <p>model.eval()  # 设D估模廾O </p>    <p># 彞~D轀|  dummy 轾S佅¥廼 轇~O (batch_size=1, input_size=100) </p>  <p>dummy_input = torch.randn(1, 100) </p>    <p># 导佇º为 ONNX </p>  <p>torch.onnx.export( </p>  <p>    model, </p>  <p>    dummy_input, </p>  <p>    &quot;multilayer_net.onnx&quot;, </p>  <p>    input_names=[&quot;input&quot;], </p>  <p>    output_names=[&quot;output&quot;], </p>  <p>    dynamic_axes={&quot;input&quot;: {0: &quot;batch_size&quot;}, &quot;output&quot;: {0: &quot;batch_size&quot;}}, </p>  <p>    opset_version=13, </p>  <p>    do_constant_folding=True </p>  <p>) </p>    <p>print(&quot;὜~E 模佞~K彈~P佊~_导佇º佈° multilayer_net.onnx&quot;) </p> </blockquote>  <p>当前尝试使用 atc --model=multilayer_net.onnx --framework=5 --output=tdd_mu --soc_version=Ascend310P3 转换时出错提示</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_17878.png\" src=\"cid:pic_0\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248185077883805119-1-1.html",
        "clean_data": "核心问题：ATC转换ONNX模型到OM时，如何为携带动态axis的输入指定具体shape？  解决方案：使用ATC的   input format 和   input shape 参数显式定义输入节点的格式及具体shape。例如：  atc   input shape  input 1 100    input format  NHWC     需对非动态轴维度进行显式赋值，动态轴 如batch 保留占位符处理。",
        "created_at": "2025-06-12T02:31:24+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-12T02:59:08+08:00"
    },
    {
        "id": 23,
        "source_id": "19525390",
        "title": "【ZJ】 autofuse_op_kernel so path 没有获取到",
        "body": "获取属性的名字需要从 _autofuse_infershape_func_so_path 修改成 _infer_symbol_shape_so_path",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBMHVY",
        "clean_data": "解决autofuse op kernel缺失so路径问题：将属性名由 autofuse infershape func so path修改为 infer symbol shape so path以正确获取路径。",
        "created_at": "2025-02-15T16:58:04+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-15T16:58:04+08:00"
    },
    {
        "id": 630,
        "source_id": "0248184996614417113",
        "title": "CANN安装后，ASCEND_OPP_PATH是否可以修改？",
        "body": "<div class=\"cke-article\"><p>CANN工具包安装好后，会自动生成ASCEND_OPP_PATH环境变量值。</p>  <p>我在使用ms的开发环境，里面是root用户已安装好的CANN环境。</p>  <p>而我的环境是mindspore用户，只是普通用户权限，这样导致安装算子时报错，因为没有目录权限：<br> [ops_custom] [2025-06-11 02:53:51] [WARNING] The directory /usr/local/Ascend/ascend-toolkit/latest/opp does not have sufficient permissions.</p>  <p>于是我将环境变量修改为家目录下面，可以安装成功了：</p>  <p>export ASCEND_OPP_PATH=/home/mindspore/Ascend/ascend-toolkit/latest/opp</p>  <p>但是想问一个问题，就是这样修改后，会影响后续的使用吗？比如说对算子进行调用？</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184996614417113-1-1.html",
        "clean_data": "问题标题：   CANN安装后ASCEND OPP PATH能否修改路径？    问题精简描述：   CANN安装后的ASCEND OPP PATH默认指向根目录  usr local Ascend ，但因mindspore用户权限不足无法写入该路径，导致算子安装报错。用户改为指向本地路径  home mindspore Ascend ，安装成功，但担忧该修改是否会影响算子调用。",
        "created_at": "2025-06-11T03:56:54+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T08:36:49+08:00"
    },
    {
        "id": 631,
        "source_id": "0226184931827635090",
        "title": "yolov8模型在200I DK A2上使用atc对ONNX转换失败",
        "body": "<div class=\"cke-article\"><p>yolov8的onnx文件在200I DK A2上使用atc对ONNX转换失败。该模型在310pro上表现良好。<br> 测试代码来自于https://gitee.com/cumt/ascend-yolov8-sample，在310pro上，device name为310p3上可以成功运行，但是我在200I DK A2上使用<br> atc --framework=5 \\<br> --model=./resource/huawei/model/yolov8n.onnx \\<br> --input_format=NCHW \\<br> --input_shape=&quot;images:1,3,640,640&quot; \\<br> --output_type=FP16 \\<br> --output=./resource/huawei/model/yolov8n_200idka2.om \\<br> --log=error \\<br> --soc_version=Ascend310B4</p>  <p>尝试对onnx进行转换，但是出现下列错误<br> ATC start working now, please wait for a moment.</p>  <p>...........................................................................................................................................................................................................Exception in thread Thread-1:</p>  <p>Traceback (most recent call last):</p>  <p>  File &quot;/usr/local/miniconda3/lib/python3.9/threading.py&quot;, line 954, in _bootstrap_inner</p>  <p>    self.run()</p>  <p>  File &quot;/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py&quot;, line 91, in run</p>  <p>    key, func, args, kwargs = self.task_q.get(timeout=TIMEOUT)</p>  <p>  File &quot;&lt;string&gt;&quot;, line 2, in get</p>  <p>  File &quot;/usr/local/miniconda3/lib/python3.9/multiprocessing/managers.py&quot;, line 809, in _callmethod</p>  <p>    kind, result = conn.recv()</p>  <p>  File &quot;/usr/local/miniconda3/lib/python3.9/multiprocessing/connection.py&quot;, line 255, in recv</p>  <p>    buf = self._recv_bytes()</p>  <p>  File &quot;/usr/local/miniconda3/lib/python3.9/multiprocessing/connection.py&quot;, line 419, in _recv_bytes</p>  <p>    buf = self._recv(4)</p>  <p>  File &quot;/usr/local/miniconda3/lib/python3.9/multiprocessing/connection.py&quot;, line 388, in _recv</p>  <p>    raise EOFError</p>  <p>EOFError</p>  <p>[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!</p>  <p>[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!</p>  <p>[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!<br> <br> 后续我省略了很多报错信息，如果需要我可以再贴上来</p>  <p>其他：</p>  <p>模型转换的命令来源于https://gitee.com/ascend/modelzoo-GPL/tree/master/built-in/ACL_Pytorch/Yolov8_for_PyTorch#/ascend/modelzoo-GPL/blob/master/built-in/ACL_Pytorch/Yolov8_for_PyTorch/%E6%96%87%E6%A1%A3%E8%BF%9B%E8%A1%8CYolov8%E6%9D%BF%E7%AB%AF%E9%83%A8%E7%BD%B2</p>  <p>为什么发在这里：https://www.hiascend.com/forum/thread-0261153129638107014-1-1.html</p>  <p>前置问题：https://www.hiascend.com/forum/thread-0205184578735671065-1-1.html</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0226184931827635090-1-1.html",
        "clean_data": "问题：Yolov8 ONNX模型在200I DK A2设备上转换失败 关键信息：使用ATC工具转换时出现 TBE Subprocess task distribute  raise error main process disappeared  错误，且Verified可成功转换 操作建议：检查soc version参数与目标设备的对应关系，确认atc工具适配版本，排查硬件资源占用问题",
        "created_at": "2025-06-10T09:57:08+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T03:37:02+08:00"
    },
    {
        "id": 632,
        "source_id": "0226184843290623080",
        "title": "安装驱动源码编译所需依赖执行不成功",
        "body": "<div class=\"cke-article\"><p>使用 uname -r 查询到内核版本是5.10.0+</p>  <p>使用apt-get install -y linux-headers-$(uname -r)提示无法定位到软件包，有什么解决办法？</p>  <p></p>  <p></p>  <p><span class=\"easyimage easyimage-align-center\"><img alt=\"e81ab74ae92d21a45aa35d6784219e9.jpg\" src=\"cid:pic_0\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0226184843290623080-1-1.html",
        "clean_data": "安装驱动源码编译依赖失败：内核版本为5 10 0 ，执行 apt get install  y linux headers   uname  r  时报 无法定位软件包 。  解决步骤： 1  检查 etc apt sources list源配置是否完整 需启用main universe   2  执行 apt update 更新软件源缓存 3  使用 dpkg  l   grep linux headers 确认Headers版本号格式 可能含具体build号  4  手动指定版本号安装 如 sudo apt install  y linux headers 5 10 0 XX generic",
        "created_at": "2025-06-09T09:21:31+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-10T08:51:29+08:00"
    },
    {
        "id": 633,
        "source_id": "0226184821552536077",
        "title": "如何使用npu对rtsp视频流进行直接解码，不使用cpu做解码工作",
        "body": "<div class=\"cke-article\">由于CPU做解码工作比较耗费资源，而npu的资源剩余过多，想将解码工作搬到npu上面进行，请问有什么比较好的参考样例么</div>",
        "url": "https://www.hiascend.com/forum/thread-0226184821552536077-1-1.html",
        "clean_data": "标题：NPU直接解码RTSP流方案 内容：咨询能否通过CANN框架直接由NPU处理RTSP视频流解码 非CPU解码 ，请求提供NPU解码能力支持流程或示例代码，重点关注编码格式兼容性及AscendCL MOCV接口适配方案。",
        "created_at": "2025-06-09T03:19:13+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T03:45:29+08:00"
    },
    {
        "id": 634,
        "source_id": "0248184586997562089",
        "title": "【模型推理】模型推理 aclmdlExecute() 阻塞问题。",
        "body": "<div class=\"cke-article\"><p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">【问题详细描述】</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">- 报错截图（包含输入命令到最后的错误输出截图）</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"><span class=\"easyimage easyimage-full\"><img alt=\"cke_489.png\" src=\"cid:pic_0\"></span></p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">- 文字描述（描述当前出错的场景，步骤，报错现象）<br> * 特征点匹配模型重复执行推理一段时间后(每次推理都是同一张图)，最终总会陷入到 aclmdlExecute() 中无法退出，导致推理线程一直处于阻塞状态（必现）。刚开始卡住时，加速卡利用率会保持100%，随后加速卡利用率降低为0，但推理线程依然阻塞在aclmdlExecute()。<br> * 使用的C++推理。</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">【问题相关文件】：无</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">【昇腾产品型号】：Atlas 300v Pro推理卡</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">【版本信息】：</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">- CANN版本：8.0.RC2.alpha002</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">- 系统版本：ubuntu22.04</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">【用户类型】：企业</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184586997562089-1-1.html",
        "clean_data": "模型推理中特征点匹配模型重复执行同一图像时，aclmdlExecute  函数长期阻塞且推理线程无法退出 Atlas 300v Pro推理卡，CANN 8 0 RC2 alpha002，企业用户 。加速卡利用率先100 后降为0，但线程仍卡在执行接口内。",
        "created_at": "2025-06-06T10:09:58+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-10T03:26:26+08:00"
    },
    {
        "id": 83,
        "source_id": "20614732",
        "title": "[Documentation|文档反馈]: 无法理解算子入图后，对device流的占用逻辑",
        "body": "### Document Link（文档链接）\r\n\r\n无此类文档\r\n\r\n### Issues Section（问题文档片段）\r\n\r\nNA\r\n\r\n### Existing Issues（存在的问题）\r\n\r\n1. 什么时候算子入图要占用Device流\r\n2. 如何估算算子入图后Device流的占用情况\r\n3. 如何查看确认算子如图后实际的Device流占用情况\r\n4. 哪些配置项可以调整Device流的占用策略\r\n\r\n### 所属算子\r\n\r\n其他\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine/issues/IC9UFG",
        "clean_data": "Documentation   算子入图后Device流占用逻辑模糊需补充说明 问题：现有文档缺乏算子入图时Device流占用手册，需明确以下要点： 1  算子入图触发Device流占用的条件  2  Device流占用量的计算方法  3  验证占用效果的工具 途径  4  可配置的Device流优化参数  关联点：四个问题均围绕算子与Device流关系展开",
        "created_at": "2025-05-22T18:35:37+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-22T18:35:37+08:00"
    },
    {
        "id": 165,
        "source_id": "0292180879231870125",
        "title": "解决方案】【FAQ】使用aclSetAclOpExecutorRepeatable后结果全为0",
        "body": "<div class=\"cke-article\"><h1 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-transform: none;vertical-align: baseline;white-space: normal;word-spacing: 0.0px;\">问题前奏：</h1>  <p>使用aclSetAclOpExecutorRepeatable</p>  <pre style=\"background-color: rgb(248,248,248);color: rgb(56,56,56);font-size: 14.0px;font-style: normal;font-weight: 400;letter-spacing: normal;overflow: visible;padding: 0.0px;text-transform: none;word-spacing: 0.0px;\">\naclnnInplaceCopy(tensorList, tensor3, output, &amp;workspace_size, &amp;executor);</pre>  <pre style=\"background-color: rgb(248,248,248);color: rgb(56,56,56);font-size: 14.0px;font-style: normal;font-weight: 400;letter-spacing: normal;overflow: visible;padding: 0.0px;text-transform: none;word-spacing: 0.0px;\">\naclSetAclOpExecutorRepeatable(executor);  \nvoid *addr;\naclSetDynamicInputTensorAddr(executor, 0, 0, tensorList, addr);   // 刷新输入tensorlist中第1个aclTensor的device地址\naclSetDynamicInputTensorAddr(executor, 0, 1, tensorList, addr);  // 刷新输入tensorlist中第2个aclTensor的device地址</pre>  <h1 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-transform: none;vertical-align: baseline;white-space: normal;word-spacing: 0.0px;\">问题原因：</h1>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">aclnnInplaceCopy不支持aclOpExecutor复用</p>  <h1 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-transform: none;vertical-align: baseline;white-space: normal;word-spacing: 0.0px;\">解决方案：</h1>  <p>通过返回值判断是否aclOpExecutor可复用</p>  <pre style=\"background-color: rgb(248,248,248);color: rgb(56,56,56);font-size: 14.0px;font-style: normal;font-weight: 400;letter-spacing: normal;overflow: visible;padding: 0.0px;text-transform: none;word-spacing: 0.0px;\">\n<code class=\"language-javascript\" style=\"color: inherit;font-size: 14.0px;padding: 0.0px;\">ret = aclSetAclOpExecutorRepeatable(executor);  \nCHECK_RET(ret == ACL_SUCCESS, LOG_PRINT(&quot;aclSetAclOpExecutorRepeatablefailed. ERROR: %d\\n&quot;, ret); return ret);</code></pre></div>",
        "url": "https://www.hiascend.com/forum/thread-0292180879231870125-1-1.html",
        "clean_data": "使用aclSetAclOpExecutorRepeatable后结果为0的问题：由于aclnnInplaceCopy操作不支持aclOpExecutor复用，即使调用aclSetAclOpExecutorRepeatable也需通过返回值判断设置有效性。需添加对ret   ACL SUCCESS的检查确认复用配置是否生效。",
        "created_at": "2025-04-24T12:13:52+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-24T12:13:52+08:00"
    },
    {
        "id": 9,
        "source_id": "19200236",
        "title": "支持dump，可以将自动融合重要阶段结果dump出来，最好dump出来的结果是可执行的",
        "body": "一、需求场景&价值\r\n\r\n二、需求建议实现的规格\r\n\r\n三、竞品比较（选填）",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBFIZW",
        "clean_data": "建议实现自动融合阶段中间结果Dump及可执行导出功能",
        "created_at": "2025-01-03T16:51:37+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-03T16:51:37+08:00"
    },
    {
        "id": 31,
        "source_id": "19936586",
        "title": "头文件include之间加空格",
        "body": "![输入图片说明](https://foruda.gitee.com/images/1742547001610851978/3423a78d_15112809.png \"屏幕截图\")\r\n\r\n\r\n\r\n\r\n",
        "url": "https://gitee.com/ascend/cann-graph-engine-dev/issues/IBVB62",
        "clean_data": "解决方案：头文件include之间不应存在空格，正确语法应为连续写作  include  header h  ，无需添加额外空格以避免编译异常。",
        "created_at": "2025-03-21T16:50:03+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-21T16:50:03+08:00"
    },
    {
        "id": 635,
        "source_id": "0248184571241996086",
        "title": "耗时太长了",
        "body": "<div class=\"cke-article\"><span class=\"easyimage easyimage-full\"><img alt=\"%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_17491790464949.png\" src=\"cid:pic_0\"></span>这个使用profiling跑的结果，中间有个Concat_40耗时很长，怀疑是中间过程float16和float32相互转化导致的  怎么解决</div>",
        "url": "https://www.hiascend.com/forum/thread-0248184571241996086-1-1.html",
        "clean_data": "Concat 40节点高耗时问题，疑似因float16 float32数据类型转换引发。建议检查输入输出张量精度是否匹配，通过以下方式验证和优化：1  统一操作数数据类型 如强制转换为float16 ；2  使用算子融合消除隐式类型转换；3  调整显存布局优化访存效率。 问题标题：耗时太长了",
        "created_at": "2025-06-06T05:47:22+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T06:54:25+08:00"
    },
    {
        "id": 636,
        "source_id": "0248184569808776085",
        "title": "香橙派kunpeng pro开发板安装acllite库时遇到的问题和报错",
        "body": "<div class=\"cke-article\"><p>安装时大致步骤参照该链接 https://gitee.com/ascend/samples/blob/master/cplusplus/environment/catenation_environmental_guidance_CN.md</p>  <p>1. 在使用香橙派kunpeng pro开发板自带的openEuler系统时，没有香橙派ai pro自带的conda环境，该环境中是否存在已经配置好但未说明的依赖？</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_2303.png\" src=\"cid:pic_0\" style=\"width: 319.0px;height: 23.0px;\"></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_2623.png\" src=\"cid:pic_1\"></span></p>  <p>2.香橙派kunpeng pro开发板的openEuler系统内没有香橙派ai pro的ubuntu系统内自带的该文件夹</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_9145.png\" src=\"cid:pic_2\" style=\"width: 818.0px;height: 25.0px;\"></span></p>  <p>3.openEuler系统无法使用apt，所以使用的是sudo yum install opencv安装，与sudo apt-get install libopencv-dev安装的是否有版本差异而会导致后续可能存在的问题？</p>  <p>4.在安装acllite库这一步时发生错误</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1164.png\" src=\"cid:pic_3\" style=\"width: 745.0px;height: 452.0px;\"></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_2312.png\" src=\"cid:pic_4\" style=\"width: 735.0px;height: 164.0px;\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184569808776085-1-1.html",
        "clean_data": "问题梳理：香橙派Kunpeng Pro开发板在安装ACL Lite库时出现依赖项配置错误 openEuler与Ubuntu环境差异导致路径缺失 。具体表现为：  1  安装指南未明确说明openEuler系统与Ubuntu系统的依赖配置差异； 2  原指南依赖路径  usr local Ascend acllib 在openEuler环境中缺失； 3  opencv通过yum安装而非apt，可能存在版本兼容性问题； 4  执行安装时提示未定义的依赖项错误 console输出日志可见 。  该问题涉及不同Linux发行版下的依赖适配要求，需重点关注ASCEND VERSION环境变量配置和Ascend工具链路径一致性。",
        "created_at": "2025-06-06T05:23:29+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T06:21:26+08:00"
    },
    {
        "id": 637,
        "source_id": "0248184559314734081",
        "title": "微调后模型迁移",
        "body": "<div class=\"cke-article\"><p>请问在N卡下微调过后模型，能不能迁移到我们npu卡下运行？</p>  <p></p>  <p>还是一定得用910B的服务器来做微调？</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184559314734081-1-1.html",
        "clean_data": "标题：微调后模型迁移   内容：在NVIDIA GPU微调的模型能否迁移到昇腾NPU运行？是否必须使用Ascend 910B服务器进行微调。      结论  ：模型可在N卡微调后迁移到NPU运行，需通过CANN提供的工具完成格式转换与验证。建议遵循社区统一架构文档，保持微调与运行环境算子兼容性。",
        "created_at": "2025-06-06T02:28:35+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T06:45:16+08:00"
    },
    {
        "id": 119,
        "source_id": "0248184478197515072",
        "title": "模型执行失败，返回507011",
        "body": "<div class=\"cke-article\"><p>推理Yolov5m模型，onnx格式模型能运行，om模型转换成功。但在推理时返回507011，如下图：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1573.png\" src=\"cid:pic_0\"></span></p>  <p>日志在附件中。推理yolov5s模型是ok的</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184478197515072-1-1.html",
        "clean_data": "问题摘要  ：   Yolov5m模型推理时返回507011错误，OM模型转换成功但执行失败；而同架构Yolov5s模型推理正常，ONNX版本无问题。需排查设备兼容性、ACL库配置或模型转换参数异常。",
        "created_at": "2025-06-05T03:56:38+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": [
            "[]"
        ],
        "source_closed": false,
        "updated_at": "2025-06-11T08:03:19+08:00"
    },
    {
        "id": 122,
        "source_id": "02115184387680687043",
        "title": "Conv3dv2 only support static shape",
        "body": "<div class=\"cke-article\"><p>atlas 800T a2跑通义万相2.1-文生视频-14B模型报错，<span class=\"easyimage easyimage-full\"><img alt=\"cke_780.png\" src=\"cid:pic_0\"></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1616.png\" src=\"cid:pic_1\"></span><span class=\"easyimage easyimage-full\"><img alt=\"cke_1976.png\" src=\"cid:pic_2\"></span><br> <br> 这种如何做迁移</p></div>",
        "url": "https://www.hiascend.com/forum/thread-02115184387680687043-1-1.html",
        "clean_data": "问题核心：Conv3dv2操作仅支持静态形状，在Atlas 800T A2部署文生视频14B模型时因输入形状动态化导致迁移失败  关键解决步骤： 1  强制模型输入预测阶段为静态维度 如ONNX导出时指定fixed input shape  2  检查CANN 6 0 版本中Conv3dv2算子兼容的输入维度规范 非必须项  3  执行atc工具转换时添加  input shape参数显式定义 1 C D H W 为固定值 4  模型精简处理：如使用PyTorch导出ONNX需设置dynamic axes False 5  验证模型框架版本是否与CANN算子实现同步升级 算子行为可能有版本差异",
        "created_at": "2025-06-04T02:48:01+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-06T01:20:15+08:00"
    },
    {
        "id": 125,
        "source_id": "0248184302927172046",
        "title": "加载模型推理成功，然后卸载模型，再加载模型推理报错：aclmdlExecute failed",
        "body": "<div class=\"cke-article\"><p>机器信息如下：</p>  <p>+--------------------------------------------------------------------------------------------------------+ </p>  <p>| npu-smi 24.1.rc2.3                               Version: 24.1.rc2.3                                   | </p>  <p>+-------------------------------+-----------------+------------------------------------------------------+ </p>  <p>| NPU     Name                  | Health          | Power(W)     Temp(C)           Hugepages-Usage(page) | </p>  <p>| Chip    Device                | Bus-Id          | AICore(%)    Memory-Usage(MB)                        | </p>  <p>+===============================+=================+======================================================+ </p>  <p>| 11      310P3                 | OK              | NA           58                0     / 0             | </p>  <p>| 0       0                     | 0000:05:00.0    | 0            1561 / 44280                            | </p>  <p>+-------------------------------+-----------------+------------------------------------------------------+ </p>  <p>| 11      310P3                 | OK              | NA           58                0     / 0             | </p>  <p>| 1       1                     | 0000:05:00.0    | 0            1293 / 43693                            | </p>  <p>+===============================+=================+======================================================+ </p>  <p>| 12      310P3                 | OK              | NA           56                0     / 0             | </p>  <p>| 0       2                     | 0000:06:00.0    | 0            1458 / 44280                            | </p>  <p>+-------------------------------+-----------------+------------------------------------------------------+ </p>  <p>| 12      310P3                 | OK              | NA           54                0     / 0             | </p>  <p>| 1       3                     | 0000:06:00.0    | 0            1392 / 43693                            | </p>  <p>+===============================+=================+======================================================+ </p>  <p>| 13      310P3                 | OK              | NA           56                0     / 0             | </p>  <p>| 0       4                     | 0000:07:00.0    | 0            1557 / 44280                            | </p>  <p>+-------------------------------+-----------------+------------------------------------------------------+ </p>  <p>| 13      310P3                 | OK              | NA           57                0     / 0             | </p>  <p>| 1       5                     | 0000:07:00.0    | 0            1297 / 43693                            | </p>  <p>+===============================+=================+======================================================+ </p>  <p>| 14      310P3                 | OK              | NA           55                0     / 0             | </p>  <p>| 0       6                     | 0000:08:00.0    | 0            1565 / 44280                            | </p>  <p>+-------------------------------+-----------------+------------------------------------------------------+ </p>  <p>| 14      310P3                 | OK              | NA           52                0     / 0             | </p>  <p>| 1       7                     | 0000:08:00.0    | 0            1287 / 43693                            | </p>  <p>+===============================+=================+======================================================+</p>  <p>cann版本信息：8.0.RC2.alpha002</p>  <p>ERROR 日志如下：</p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.686.495 [engine.cc:1514]195250 ReportExceptProc:[EXEC][DEFAULT]Task exception! device_id=0, stream_id=10, task_id=21, type=1(KERNEL_AICPU), failuremode =0, retCode=0x2a, [aicpu exception] </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.686.880 [task_info.cc:1780]195250 PreCheckTaskErr:[EXEC][DEFAULT]report error module_type=5, module_name=EZ9999 </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.686.923 [task_info.cc:1780]195250 PreCheckTaskErr:[EXEC][DEFAULT]Kernel task happen error, retCode=0x2a, [aicpu exception]. </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.023 [task_info.cc:1583]195250 PrintAicpuErrorInfo:[EXEC][DEFAULT]report error module_type=0, module_name=E39999 </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.043 [task_info.cc:1583]195250 PrintAicpuErrorInfo:[EXEC][DEFAULT]Aicpu kernel execute failed, device_id=0, stream_id=10, task_id=21, errorCode=2a. </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.083 [task_info.cc:1593]195250 PrintAicpuErrorInfo:[EXEC][DEFAULT]Aicpu kernel execute failed, device_id=0, stream_id=10, task_id=21, fault op_name= </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.237 [stream.cc:1499]195250 GetError:[EXEC][DEFAULT]Stream Synchronize failed, stream_id=10, retCode=0x2a, [aicpu exception]. </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.261 [stream.cc:1502]195250 GetError:[EXEC][DEFAULT]report error module_type=0, module_name=E39999 </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.278 [stream.cc:1502]195250 GetError:[EXEC][DEFAULT]Aicpu kernel execute failed, device_id=0, stream_id=10, task_id=21, fault op_name= </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.317 [logger.cc:498]195250 StreamSynchronize:[EXEC][DEFAULT]Stream synchronize failed, stream_id=10 </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.343 [api_c.cc:827]195250 rtStreamSynchronizeWithTimeout:[EXEC][DEFAULT]ErrCode=507018, desc=[aicpu exception], InnerCode=0x715002a </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.357 [error_message_manage.cc:53]195250 FuncErrorReason:[EXEC][DEFAULT]report error module_type=3, module_name=EE8888 </p>  <p>[ERROR] RUNTIME(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.365 [error_message_manage.cc:53]195250 FuncErrorReason:[EXEC][DEFAULT]rtStreamSynchronizeWithTimeout execute failed, reason=[aicpu exception] </p>  <p>[ERROR] GE(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.407 [utils.cc:52]195250 DoRtStreamSyncWithTimeout: ErrorNo: 4294967295(failed) [EXEC][DEFAULT]Assert ((rt_ret) == 0) failed </p>  <p>[ERROR] ASCENDCL(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.426 [model.cpp:742]195250 RuntimeV2ModelExecute: [EXEC][DEFAULT][Exec][Model]Execute model failed, ge result[1343225857], modelId[2147483654] </p>  <p>[ERROR] ASCENDCL(195250,VaDecoderStream2D):2025-06-03-02:11:16.687.460 [model.cpp:1846]195250 aclmdlExecuteAsync: [EXEC][DEFAULT][Exec][Model]aclmdlExecuteAsync failed, result[500002], modelId[2147483654] </p>  <p>aclmdlExecute failed, model id 2147483654</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184302927172046-1-1.html",
        "clean_data": "CANN 8 0 RC2 alpha002版本中，卸载模型后再次加载同模型modelId 2147483654 时aclmdlExecute失败，报AICPU异常 0x2a 500002 。问题表现为模型首次加载推理正常，卸载后重复加载导致Kernel执行异常，需排查模型卸载流程是否充分释放资源及版本兼容性。",
        "created_at": "2025-06-03T03:20:42+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-06T07:43:24+08:00"
    },
    {
        "id": 128,
        "source_id": "0226183880845246025",
        "title": "Mul算子跑在CPU上，如何让Mul算子跑到NPU上？",
        "body": "<div class=\"cke-article\">onnx模型转成om模型后，Mul算子变成BinaryMath算子，但为何有的BinaryMath算子跑在NPU上，有的BinaryMath算子跑在CPU上，如何让BinaryMath算子跑到NPU上？</div>",
        "url": "https://www.hiascend.com/forum/thread-0226183880845246025-1-1.html",
        "clean_data": "问题核心：如何配置BinaryMath算子 源自Mul算子 在NPU执行？  原因分析：ONNX转OM时，算子实际执行设备由CANN的算子实现兼容性及配置决定。当算子存在CPU NPU多版本实现时，调度决策依赖于： 1  vendor event def json中算子属性配置 2  aarch64 meta dvpp插件是否注入NPU支持 3  ACL编译参数 如  enable lambdasubgraph 是否启用  关键操作步骤： 1  检查vendor目录下event def json的BinaryMath算子目标平台配置 2  在 acl home mpi conf platform conf指定 need npu binary math true  3  使用atc工具时添加  target npu参数强制指定 4  验证aarch64 meta dvpp插件是否已正确安装  验证方法：使用hiainfer profiling查看binary math kernel算子执行时的Device字段是否为ascend。若仍无法迁移，需通过  query info参数检查具体算子限制条件。",
        "created_at": "2025-05-29T06:00:45+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T12:03:40+08:00"
    },
    {
        "id": 160,
        "source_id": "0248184311278605047",
        "title": "链接库问题循环报错",
        "body": "<div class=\"cke-article\">现在这个代码的问题是这样的  <p>如果按照文档中写的，在link_directories中增加libcust_opapi.so所在目录，那么就会报找不到ascendcl/nnopbase等链接库的错误</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_310.png\" src=\"cid:pic_0\"></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_613.png\" src=\"cid:pic_1\"></span></p>  <p> </p>  <p>然后我如果将报错中找不到的链接库的so文件路径加到link_directories中的话，又会报之前bbopbase链接库未定义的问题。 </p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1187.png\" src=\"cid:pic_2\"></span></p>  <p>CMakeLists中include_directories和link_directories部分的内容是下图这样的 </p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1982.png\" src=\"cid:pic_3\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248184311278605047-1-1.html",
        "clean_data": "在CMakeLists中按文档添加libcust opapi so链接目录后，出现ascendcl nnopbase等依赖库未找到的报错；尝试添加这些依赖库的链接路径后，又报cust opapi库未定义，形成循环链接缺失。",
        "created_at": "2025-06-03T05:34:39+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-05T02:01:51+08:00"
    },
    {
        "id": 647,
        "source_id": "0261155890271039277",
        "title": "[GroundingDINO]ONNX模型转OM模型过程中遇到input shape dim未对齐问题",
        "body": "<div class=\"cke-article\"><p>设备：华为Atlas 200I DK A2开发者套件<br> CANN版本：7.0.RC1<br> 报错似乎是Concat算子的输入维度没有对齐<br> 静态输入，模型转换过程及报错如下：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"2.png\" src=\"cid:pic_0\"></span></p>  <p>转换好的onnx模型是动态输入的，这里onnx转om是静态的</p>  <p>尝试设置--dynamic_dims，但报错也是concat算子输入维度对齐问题，报错如下：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"3.png\" src=\"cid:pic_1\"></span></p>  <p>onnx模型输入如下图：<br> <strong><span><span><img src=\"cid:pic_2\"></span><span>​</span></span></strong></p>  <p>大佬们帮忙看看问题出在哪里，是--input_shape设置得有问题吗？</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0261155890271039277-1-1.html",
        "clean_data": "使用Atlas 200I DK A2套件 CANN 7 0 RC1 将动态输入ONNX模型转为OM模型时，Concat算子因输入维度未对齐报错。静态转换指定输入形状后同样失败，动态转换启用  dynamic dims参数后仍存在相同问题。需确认模型中Concat节点的拼接轴维度是否一致 除拼接轴外其余维度必须严格对齐 ，并检查模型转换流程是否符合CANN要求的输入格式约束。",
        "created_at": "2024-07-09T06:51:11+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T01:20:11+08:00"
    },
    {
        "id": 753,
        "source_id": "0248185079383515120",
        "title": "使用默认部署方式部署的算子如何移除部署？",
        "body": "<div class=\"cke-article\">在使用工程化开发算子时，存在默认部署和自定义部署两种方式，使用默认部署的方式部署好的算子，可能会对他人产生影响，那么该如何移除已经默认部署的算子，直接删除对应的文件夹可以吗？</div>",
        "url": "https://www.hiascend.com/forum/thread-0248185079383515120-1-1.html",
        "clean_data": "问题标题：如何卸载默认部署的算子？ 描述：如何正确移除通过默认部署方式安装的算子？是否可直接删除 CANN INSTALL PATH目录下的算子文件夹？需注意默认部署路径可能与其他用户共享，直接删除可能影响他人使用的解决方案。",
        "created_at": "2025-06-12T02:56:24+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-12T02:56:24+08:00"
    },
    {
        "id": 648,
        "source_id": "0226185011273581096",
        "title": "【Ascend C】算子开发小白一周目（以ThreeNN为例）",
        "body": "<div class=\"cke-article\"><p><span style=\"font-size: 18.0px;\"><strong>试验环境</strong></span></p>  <p><span style=\"font-size: 16.0px;\">使用小腾作为实验环境，具体版本参数如下表：</span></p>  <table align=\"center\" style=\"font-size: 13.0px;text-align: justify;\">  <tbody>   <tr>    <td style=\"padding: 0.0px 7.0px 0.0px 7.0px;width: 126.0px;\">    <p><span><span>OS版本</span></span></p>    </td>    <td style=\"padding: 0.0px 7.0px 0.0px 7.0px;width: 193.0px;\">    <p><span><span>Ubuntu 22.04 LTS Arm64</span></span></p>    </td>   </tr>   <tr>    <td style=\"padding: 0.0px 7.0px 0.0px 7.0px;width: 126.0px;\">    <p><span><span>固件与驱动版本</span></span></p>    </td>    <td style=\"padding: 0.0px 7.0px 0.0px 7.0px;width: 193.0px;\">    <p><span><span>23.0.RC3</span></span></p>    </td>   </tr>   <tr>    <td style=\"padding: 0.0px 7.0px 0.0px 7.0px;width: 126.0px;\">    <p><span><span>CANN版本</span></span></p>    </td>    <td style=\"padding: 0.0px 7.0px 0.0px 7.0px;width: 193.0px;\">    <p><span><span>8.0.RC2.alpha003</span></span></p>    </td>   </tr>  </tbody> </table>  <p></p>  <p><span style=\"font-size: 18.0px;\"><strong>一、算子分析</strong></span></p>  <p>ThreeNN算子是用于寻找三个最近邻（NearestNeighbors）的算子，在机器学习和深度学习中，最近邻搜索是一种常用的技术，用于在给定的数据集中找到与查询点最接近的k个点。ThreeNN算子则专门用于这种情况下的k为3的场景。 算子功能即对于目标点集中的每个点，找到比较点集中距离其最近的3个点的距离、坐标，返回的三个点按照距离平方升序。ThreeNN算子的输入输出格式及含义如下所示。</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_6003.png\" src=\"cid:pic_2\" style=\"width: 727.0px;height: 335.0px;\"></span></p>  <p>ThreeNN的实现算法主要有暴力搜索和分治法。暴力搜索算法简单直观，通过枚举所有可能的结果来找到最优解，但计算复杂度较高，适用于小规模问题。分治法则是通过递归来得到最终解，这种方法能够显著降低计算复杂度，是一种高效的问题解决策略算法，核心思想是将一个复杂的大问题分解为若干个结构相同、相互独立的子问题，递归地求解这些子问题，最后将子问题的解合并以得到原问题的解。</p>  <p>考虑到需要基于AscendC 编程语言实现算子并执行在昇腾软硬件平台上，故优先使用多层循环的暴力搜索法作为算子的实现算法，先打通算子在昇腾平台的适配，后续在算子调优阶段再考虑各种层面上的性能优化调优。</p>  <p></p>  <p><span style=\"font-size: 18.0px;\"><strong>二、算子实现</strong></span></p>  <p>核函数是AscendC算子计算功能实现的入口，在昇腾算子开发流程中，规定使用核函数这种C/C++函数的语法扩展来管理搭载昇腾处理器的设备端的运 行代码，在核函数中进行算子类对象的创建和其成员函数的调用，由此实现算子的所有功能。</p>  <p>核函数需要定义一个KernelThreeNN的类，其中包括Init和Process两种方法，在Init 方法中进行输入数据的初始化，在Porcess 方法中需要实现计算数据的流通，数据流通过程可以分为三个基 本任务：CopyIn任务，Compute任务和CopyOut任务。</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_19000.png\" src=\"cid:pic_3\" style=\"width: 828.0px;height: 304.0px;\"></span></p>  <p>核函数 中ThreeNN算子功能的关键实现如下图所示。</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_24501.png\" src=\"cid:pic_4\"></span></p>  <p></p>  <p><span style=\"font-size: 18.0px;\"><strong>三、算子调优</strong></span></p>  <p>在进行性能优化之前，我们需要获取ThreeNN算子性能数据，拿到准确的性能数据，了解性能现状，快速定位软、硬件性能瓶颈，根据算子性能现状分析下一步的优化方向。昇腾CANN软件栈针对算子开发提供了多种工具。其中CANN软件栈提供了性能调优工具msprof来采集和分析运行在昇腾处理器上的人工智能任务的各个运行阶段的关键性能指标。</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_35843.png\" src=\"cid:pic_5\"></span></p>  <p>msprof性能调优工具在算子开发领域具有msprof op和msprof op simulator两种使用方式。可以获取到算子运行时昇腾硬件各个部件的运行数据并导出成csv文件。</p>  <p>在原始的代码实现中，ThreeNN算子的计算逻辑为依次计算目标点集xyz1中的每一个点与比较点集xyz2中的每一个点的距离，然后根据比较结果相应地更新三个候选的邻近点。比较点集xyz2中的数据为每个点的x、y、z坐标值交替出现的流式数据，不难发现，此时两点之间的距离计算实际为标量计算，这个过程仅仅只涉及了昇腾硬件中的Scalar标量计算单元。通过一种改进的方式，可以将原本的计算过程转变成一种新的形式，通过将算子计算过程修改为目标点集 xyz1中的点与一个batch的xyz2的点之间进行运算，得到x，y和z各自的差值向量，再对这三个向量进行求平方和得到最终距离。通过这种优化方式，能够提高各种硬部件的使用效率，减少算子的执行时间，并且显著调升了算子的整体性能。</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_51349.png\" src=\"cid:pic_6\"></span></p>  <p>Ascend C提供了能够从源操作数中选取元素写入目的操作数中的 GatherMask函数，使用GatherMask函数处理比较点集xyz2，提取比较点集xyz2的数据。由于该函数内置的固定模式没有提供可行的提取方法，所以需要自定义提取方法，按比特位进行提取。最终将x、y、z坐标值交替出现的流式数据转换成全为x、全为y和全为z的张量并修改代码实现中的计算逻辑。关键代码如下：</p>  <pre><br><code class=\"language-cpp\">// 按比特位提取<br>auto maskX = maskLocalX.Get&lt;uint32_t&gt;();<br>auto maskY = maskLocalY.Get&lt;uint32_t&gt;();<br>auto maskZ = maskLocalZ.Get&lt;uint32_t&gt;();<br>// 设置mask值<br>for (int32_t i = 0; i &lt; this-&gt;tmpLen; i ++)<br>{<br>    if (i % 3 == 0)<br>    {<br>        maskX.SetValue(i, 1227133513); //010010010<br>        maskY.SetValue(i, 2454267026); //100100100<br>        maskZ.SetValue(i, 613566756); //001001001<br>    }<br>    else if (i % 3 == 1)<br>    {<br>        maskX.SetValue(i, 2454267026);<br>        maskY.SetValue(i, 613566756);<br>        maskZ.SetValue(i, 1227133513);<br>    }<br>    else if (i % 3 == 2)<br>    {<br>        maskX.SetValue(i, 613566756);<br>        maskY.SetValue(i, 1227133513);<br>        maskZ.SetValue(i, 2454267026);<br>    }<br>}</code></pre>  <p></p>  <pre><br><code class=\"language-cpp\">//提取x，y，z<br>GatherMask(xLocal, xyz2Local, maskX, true, mask, {1, 1, 8, 8}, rsvdCnt); //rsvdCnt=0<br>GatherMask(yLocal, xyz2Local, maskY, true, mask, {1, 1, 8, 8}, rsvdCnt);<br>GatherMask(zLocal, xyz2Local, maskZ, true, mask, {1, 1, 8, 8}, rsvdCnt);</code></pre>  <p></p>  <pre><br><code class=\"language-cpp\">// 计算距离平方<br>Adds(tmp1Local, xLocal, x, onetime);<br>Adds(tmp2Local, yLocal, y, onetime);<br>Adds(tmp3Local, zLocal, z, onetime);<br>Mul(tmp1Local, tmp1Local, tmp1Local, onetime);<br>Mul(tmp2Local, tmp2Local, tmp2Local, onetime);<br>Mul(tmp3Local, tmp3Local, tmp3Local, onetime);<br>Add(tmp2Local, tmp2Local, tmp1Local, onetime);<br>Add(tmp3Local, tmp2Local, tmp3Local, onetime);<br><br>// 取min<br>ReduceMin&lt;float&gt;(tmp1Local, tmp3Local, tmp2Local, processnum, true); <br>float min1 = tmp1Local.GetValue(0);<br>auto idx_tmp = tmp1Local.ReinterpretCast&lt;int32_t&gt;();<br>int32_t idx1 = idx_tmp.GetValue(1);<br>tmp3Local.SetValue(idx1, 3.402823466e+38F);<br>ReduceMin&lt;float&gt;(tmp1Local, tmp3Local, tmp2Local, processnum, true); <br>float min2 = tmp1Local.GetValue(0);<br>int32_t idx2 = idx_tmp.GetValue(1);<br>tmp3Local.SetValue(idx2, 3.402823466e+38F);<br>ReduceMin&lt;float&gt;(tmp1Local, tmp3Local, tmp2Local, processnum, true); <br>float min3 = tmp1Local.GetValue(0);<br>int32_t idx3 = idx_tmp.GetValue(1);</code></pre>  <p>优化前算子指令流水图如下：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_3276.png\" src=\"cid:pic_0\"></span></p>  <p>优化后算子指令流水图如下：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_6854.png\" src=\"cid:pic_1\"></span></p>  <p style=\"text-align: justify;\"><span><span><span><span><span>优化计算逻辑后算子的主要计算指令由标量计算指令转变为向量计算指令，增加了硬部件之间的并行度。针对同一测试数据，算子的运行时间从86.27μs下降至59.11μs，性能表现出一定幅度的增强。</span></span></span></span></span></p>  <p style=\"text-align: justify;\"></p>  <p style=\"text-align: justify;\"><span style=\"font-size: 18.0px;\"><strong>四、展望</strong></span></p>  <p style=\"text-align: justify;\"><span><span><span><span><span>未来可探索</span></span><span><span>基于</span></span><span><span>分治法</span></span><span><span>实现ThreeNN算子的方法</span></span><span><span>，结合昇腾硬件的并行计算能力，</span></span><span><span>使用昇腾Cube单元的矩阵加速，</span></span><span><span>进一步</span></span><span><span>提高计算速度和并行度</span></span><span><span>，实现更高效的近邻搜索。</span></span></span></span></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0226185011273581096-1-1.html",
        "clean_data": "Ascend C ThreeNN算子开发适配与性能调优指南  技术要点： 1  环境要求：Ubuntu22 04 LTS Arm64  昇腾CANN8 0 RC2 platform 驱动23 0 RC3  2  算法实现：   基于Ascend C创建核函数KernelThreeNN   暴力搜索法适配优先级高于分治法   通过标量计算确定每个目标点最近3个邻近点   采用 x y z 间隔排列的数据流处理方式  性能优化方案： 3  硬件利用率提升：      使用msprof工具采集昇腾硬件各部件性能指标      将标量X Y Z差值计算转为向量计算      通过GatherMask函数按bit位提取坐标张量      关键代码：maskX Y Z动态配置及 1 1 8 8 维度处理  4  性能数据：    指令流水优化后，算子执行时间从86 27 s优化至59 11 s      标量计算 向量计算      保留最低性能调优方法：三次ReduceMin循环排除已取最小值  5  优化建议：    探索分治法架构    利用Cube单元实现矩阵加速    进一步提升硬件并行计算能力",
        "created_at": "2025-06-11T10:28:55+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T08:01:14+08:00"
    },
    {
        "id": 649,
        "source_id": "0205185018208447096",
        "title": "yolov8  模型推理过程中报错",
        "body": "<div class=\"cke-article\"><p>Create input failed for wrong input nums</p>  <p></p>  <p>使用yolov3 的模型不报错，使用yolov8 报错</p>  <p></p>  <p>使用的是官方的源码</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_2074.png\" src=\"cid:pic_0\"></span></p>  <p></p>  <p></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_5520.png\" src=\"cid:pic_1\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0205185018208447096-1-1.html",
        "clean_data": "yolov8 模型封装输入参数数量不匹配问题     使用官方源码加载 yolov8 模型时触发未知输入参数数量异常，v3 版本无此问题。需检查模型输入层定义或推理接口配置的输入张量数量是否偏离预期值。",
        "created_at": "2025-06-11T09:56:48+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-12T02:03:19+08:00"
    },
    {
        "id": 651,
        "source_id": "0226184919687654087",
        "title": "Ascend C算子如何放到模型或者大模型中",
        "body": "<div class=\"cke-article\"><p>老师，您好。目前正在进行硕士论文的基于昇腾AI处理器的毕业课题的思路梳理，我想知道几点：</p>  <p>1、已经在Atlas 200I DK A2 开发板 上实现的基本算子，是否可以迁移到Atlas A2 训练系列产品，需要做什么修改和同步呢？这个过程有没有相关教程指导呢？</p>  <p>2、在Atlas 200I DK A2 开发板 上实现的基本算子，可以放到某个模型或者算法中，然后把模型进行部署并进行应用么，这个过程有没有教程指导呢？</p>  <p>3、如何知道Atlas 200I DK A2 开发板 上实现的基本算子是否足够接近理论的性能最优值呢，要借助什么工具进行实现呢？迁移到Atlas A2 训练系列产品，是否会有更优秀的性能表现呢？</p>  <p>4、算子融合的一般步骤是什么呢，是不是需要基于特定模型然后再分析考虑呢，这个过程有没有教程指导呢？</p>  <p>5、我的毕设思路是，某个常见算子的算子实现，算子优化，算子融合，然后部署到模型中，去进行对比，请问昇腾社区目前是否有这方面的示例算子的总体流程实现以及相关教程呢？这个思路是否合理呢，工作量是否足够呢，还有什么其他可以做的内容么？</p>  <p>感谢老师看到这里，目前确实对毕业课题焦头烂额，只能来论坛这边向老师求助了，烦请老师百忙之中能点拨一下，谢谢老师！！！</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0226184919687654087-1-1.html",
        "clean_data": "1  开发板算子迁移到Atlas A2训练系列需同步修改核张量核函数定义？可参考CANN文档中的跨平台迁移指南；   2  如何将开发板算子部署到模型并应用？需通过自定义MindSpore算子接口集成并导出ONNX模型供ATC转换；   3  验证算子性能是否满足理论最优值应使用Ascend Profiler分析，训练系列产品因硬件架构差异可能性能更优；   4  算子融合步骤是否依赖特定模型？需先分析计算图热点再使用ComputeGraphCompaction进行融合；   5  社区是否有算子开发 优化 融合 部署全链路示例？可查阅官方 Ascend C算子开发实践 文档及MindSpore自定义算子案例。   论文思路可行，建议补充异构计算分析和功耗评估以增强深度。",
        "created_at": "2025-06-10T06:34:48+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T06:56:04+08:00"
    },
    {
        "id": 761,
        "source_id": "0205183873747834019",
        "title": "vector的读写指令每拍的长度到底是多少",
        "body": "<div class=\"cke-article\"><p><a href=\"cid:link_0\">Ascend C最佳实践-CANN社区版8.2.RC1.alpha002-昇腾社区</a></p>  <p>在上面这篇文档中提到，每拍可以读写16个block。</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1228.png\" src=\"cid:pic_0\"></span></p>  <p>但在下面介绍读写冲突的情况时，又出现了：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_12707.png\" src=\"cid:pic_1\"></span><span class=\"easyimage easyimage-full\"><img alt=\"cke_13097.png\" src=\"cid:pic_2\"></span></p>  <p>所以到底每拍可以读写多少数据呢？</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0205183873747834019-1-1.html",
        "clean_data": "问题：Ascend C中vector读写指令每拍的数据块数量存在描述冲突。 最佳实践 文档明确指出每拍可读写16个block，但另一部分提及读写冲突的说明中未直接体现此数值。需确认文档是否存在版本差异或上下文条件，并明确vector每拍读写长度的准确配置值。",
        "created_at": "2025-05-29T04:02:28+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-12T02:53:05+08:00"
    },
    {
        "id": 762,
        "source_id": "0248183782318346003",
        "title": "GlobalTensor无法通过DumpTensor api输出",
        "body": "<div class=\"cke-article\">参考了<a href=\"cid:link_1\">DumpTensor未打印内容_Ascend C_昇腾论坛</a>这篇帖子，使用了<a href=\"cid:link_0\">Ascend C算子开发接口-CANN商用版8.1.RC1-昇腾社区</a>里的这个API <pre style=\"background-color: rgb(248,248,248);color: rgb(56,56,56);font-size: 12.0px;font-style: normal;font-weight: 400;letter-spacing: normal;overflow: visible;padding: 0.0px;text-transform: none;word-spacing: 0.0px;\">\nAscendC::DataSyncBarrier&lt;MemDsbT::ALL&gt;();</pre>  <p>但是发现，通过DumpTensor打印GM的行为仍然无效</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0248183782318346003-1-1.html",
        "clean_data": "问题  ：在Ascend C算子开发中，使用DumpTensor API无法输出GlobalTensor GM 的内存数据。已参考社区相关文档并尝试添加数据同步屏障 AscendC  DataSyncBarrier ，但未生效。",
        "created_at": "2025-05-28T02:38:38+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-12T02:53:54+08:00"
    },
    {
        "id": 655,
        "source_id": "0255146200919945019",
        "title": "如何在启智平台搭建Ascend C开发环境",
        "body": "<div class=\"cke-article\"><p><span style=\"font-size: 20.0px;\"><strong>第一步: 登录平台，获取算力积分</strong></span></p>  <p>平台链接：<a href=\"cid:link_1\" rel=\"nofollow\" target=\"_blank\">cloudbrains - OpenI - 启智AI开源社区提供普惠算力！ (pcl.ac.cn)</a> 。需要用户注册账号</p>  <p>在右上角点开个人信息和配置，选择设置，如图</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_2640.png\" src=\"cid:pic_1\"></span></p>  <p>滑动到最底部，绑定微信账号，即可获得50算力积分（仅对新注册用户第一次绑定有积分）</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_4957.png\" src=\"cid:pic_2\"></span></p>  <p></p>  <p><span style=\"font-size: 20.0px;\"><strong>第二步：创建项目</strong></span></p>  <p>点击右上角＋，并选择创建项目</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_8808.png\" src=\"cid:pic_3\"></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_11654.png\" src=\"cid:pic_4\"></span></p>  <p>填入项目名并勾选同意后点击创建项目即可</p>  <p></p>  <p><span style=\"font-size: 20.0px;\"><strong>第三步：创建调试任务</strong></span></p>  <p>在看板里找到自己刚刚创建的项目。看板链接：<a href=\"cid:link_2\" rel=\"nofollow\" target=\"_blank\">cid:link_2</a></p>  <p>点击刚创建的项目</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_14326.png\" src=\"cid:pic_5\"></span></p>  <p>进入项目面板后创建调试任务</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_18834.png\" src=\"cid:pic_6\"></span></p>  <p></p>  <p>注意选择NPU，和镜像</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_78232.png\" src=\"cid:pic_7\"></span></p>  <p>点击新建任务后，稍等片刻，待到任务状态为RUNNING时即可点击调试按钮进入云环境。(<span style=\"color: rgb(230,62,60);\">不使用时可点击停止按钮，不停止会扣算力积分</span>)<span class=\"easyimage easyimage-full\"><img alt=\"cke_169624.png\" src=\"cid:pic_8\"></span></p>  <p></p>  <p><span style=\"font-size: 20.0px;\"><strong>第四步：安装cmake (以下示例命令基于arm架构)</strong></span></p>  <pre><br><code class=\"language-javascript\">cd /home/ma-user<br>wget https://cmake.org/files/v3.20/cmake-3.20.0-rc5-linux-aarch64.tar.gz<br>tar -xzvf cmake-3.20.0-rc5-linux-aarch64.tar.gz<br>sed -i '$a export PATH=/home/ma-user/cmake-3.20.0-rc5-linux-aarch64/bin:$PATH' ~/.bashrc</code></pre>  <p></p>  <p><span style=\"font-size: 20.0px;\"><strong>第五步：安装CANN包 （以下示例命令基于arm架构）</strong></span></p>  <p>在<a href=\"cid:link_0\" rel=\"nofollow\" target=\"_blank\">资源下载中心-昇腾社区 (hiascend.com)</a>根据自己系统架构下载对应toolkit包然后拖动到自己环境上，或者直接在调试环境上使用wget下载，示例下载命令</p>  <pre><br><code class=\"language-javascript\">wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/CANN/CANN%208.1.RC1/Ascend-cann-toolkit_8.1.RC1_linux-aarch64.run</code></pre>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_97277.png\" src=\"cid:pic_9\"></span></p>  <p>下载后使用chmod命令给CANN包可执行权限，示例：</p>  <pre><br><code class=\"language-javascript\">chmod +x Ascend-cann-toolkit_8.1.RC1_linux-aarch64.run</code></pre>  <p>然后安装CANN包，并把配置环境脚本执行命令写入bashrc文件，示例命令：</p>  <pre><br><code class=\"language-javascript\">./Ascend-cann-toolkit_8.1.RC1_linux-aarch64.run --full --quiet --force<br>sed -i '$a source /home/ma-user/Ascend/ascend-toolkit/set_env.sh' ~/.bashrc<br><br>sed -i '$a export PATH=/home/ma-user/anaconda3/aarch64-conda-linux-gnu/bin:$PATH' ~/.bashrc</code></pre>  <p>注意，如果环境在安装CANN包之前已经有 /home/ma-user/Ascend/ascend-toolkit/目录存在，说明环境上已有默认CANN包，为了避免受影响，可以先删除该目录。</p>  <p></p>  <p><span style=\"font-size: 20.0px;\"><strong>第六步：下载Samples仓样例，测试环境是否正常</strong></span></p>  <pre><br><code class=\"language-javascript\">cd /home/ma-user<br>git clone https://gitee.com/ascend/samples.git<br>cd /home/ma-user/samples/operator/ascendc/0_introduction/3_add_kernellaunch/AddKernelInvocationNeo <br>~/.bashrc<br>bash run.sh -r npu -v Ascend910A<br><br></code></pre>  <p>运行结果如图：</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_101672.png\" src=\"cid:pic_0\"></span></p>  <p>至此，基于启智平台的Ascend C开发运行环境已搭建完成。</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0255146200919945019-1-1.html",
        "clean_data": "问题核心描述     在启智平台搭建Ascend C开发环境需按以下步骤操作：   1  注册启智账号并绑定微信，获取50算力积分 新用户专享 。   2  创建项目后进入看板，点击项目创建调试任务，选择NPU及镜像。   3  安装cmake arm架构示例 ：下载aarch64版本，解压并配置环境变量。         bash      cd  home ma user      wget https   cmake org files v3 20 cmake 3 20 0 rc5 linux aarch64 tar gz      tar  xzvf cmake 3 20 0 rc5 linux aarch64 tar gz      sed  i   a export PATH  home ma user cmake 3 20 0 rc5 linux aarch64 bin  PATH     bashrc            4  安装CANN工具包 arm架构示例 ：         bash      chmod  x Ascend cann toolkit 8 1 RC1 linux aarch64 run        Ascend cann toolkit 8 1 RC1 linux aarch64 run   full   quiet   force      sed   a source  home ma user Ascend ascend toolkit set env sh     bashrc      sed   a export PATH  home ma user anaconda3 aarch64 conda linux gnu bin  PATH     bashrc                 注意  ：若  home ma user Ascend ascend toolkit  目录已存在，需先删除以避免冲突。   5  测试环境：克隆昇腾样本仓库，运行标量加法样例验证，避免扣分需及时停止调试任务。      关键关联     标题中 Ascend C开发环境 需对应CANN安装、cmake配置及测试样例全流程。",
        "created_at": "2024-03-19T03:22:04+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T03:04:35+08:00"
    },
    {
        "id": 569,
        "source_id": "20780853",
        "title": "CVE-2022-22818",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-22818](https://nvd.nist.gov/vuln/detail/CVE-2022-22818)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe {% debug %} template tag in Django 2.2 before 2.2.27, 3.2 before 3.2.12, and 4.0 before 4.0.2 does not properly encode the current context. This may lead to XSS.\n\n漏洞公开时间：2022-02-03 10:15:00\n漏洞创建时间：2025-06-08 00:20:36\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-22818\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDELX",
        "clean_data": "CVE 2022 22818：Django 3 2 7以下版本中，    debug    模板标签存在跨站脚本漏洞 XSS ，因未正确编码上下文。需升级至2 2 27 3 2 12 4 0 2及以上版本修复 漏洞公开时间20220203，详情参考NIST链接 。",
        "created_at": "2025-06-08T00:20:36+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:20:36+08:00"
    },
    {
        "id": 571,
        "source_id": "20780916",
        "title": "CVE-2022-34749",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-34749](https://nvd.nist.gov/vuln/detail/CVE-2022-34749)\n漏洞归属组件：mistune\n漏洞归属的版本：0.8.4\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn mistune through 2.0.2, support of inline markup is implemented by using regular expressions that can involve a high amount of backtracking on certain edge cases. This behavior is commonly named catastrophic backtracking.\n\n漏洞公开时间：2022-07-26 07:15:00\n漏洞创建时间：2025-06-08 00:41:12\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-34749\n",
        "url": "https://gitee.com/ascend/modelzoo-TensorFlow-bak/issues/ICDENO",
        "clean_data": "CVE 2022 34749：mistune 0 8 4因内联标记正则回溯漏洞存在DoS风险，需升级至0 8 5  2 0 3 或禁用内联标记输入。  解析流程： 1  核心要点提取：mistune组件 0 8 4版本 正则回溯漏洞 DoS 拒绝服务 风险 修复建议 2  去除冗余： 通过特定输入 简化为 禁用内联标记输入 ，CVSS分值无实际值可忽略 3  重组信息：关联组件版本 漏洞编号 攻击类型 修复方案 4  联动标题：使用CVE编号作为主标识，补充关键组件信息和解决方案",
        "created_at": "2025-06-08T00:41:12+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:41:13+08:00"
    },
    {
        "id": 572,
        "source_id": "20780923",
        "title": "CVE-2024-37890",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-37890](https://nvd.nist.gov/vuln/detail/CVE-2024-37890)\n漏洞归属组件：ws\n漏洞归属的版本：8.17.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nws is an open source WebSocket client and server for Node.js. A request with a number of headers exceeding theserver.maxHeadersCount threshold could be used to crash a ws server. The vulnerability was fixed in ws@8.17.1 (e55e510) and backported to ws@7.5.10 (22c2876), ws@6.2.3 (eeb76d3), and ws@5.2.4 (4abd8f6). In vulnerable versions of ws, the issue can be mitigated in the following ways: 1. Reduce the maximum allowed length of the request headers using the --max-http-header-size=size and/or the maxHeaderSize options so that no more headers than the server.maxHeadersCount limit can be sent. 2. Set server.maxHeadersCount to 0 so that no limit is applied.\n\n漏洞公开时间：2024-06-18 04:15:13\n漏洞创建时间：2025-06-08 00:41:19\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-37890\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDENV",
        "clean_data": "CVE 2024 37890  ：Node js WebSocket库 ws 在8 17 1及部分旧版本中存在因请求头数量超出 server maxHeadersCount 限制导致服务器崩溃的漏洞。缓解方法包括：限制请求头长度 通过   max http header size 或 maxHeaderSize 参数 ，或设置 server maxHeadersCount 0 消除限制。漏洞已在 ws 8 17 1 、 ws 7 5 10 、 ws 6 2 3 、 ws 5 2 4 修复。",
        "created_at": "2025-06-08T00:41:19+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:41:19+08:00"
    },
    {
        "id": 89,
        "source_id": "20648956",
        "title": "MakeTensorPtrCanonicalizer 补齐功能：支持 社区 FA 用例",
        "body": "",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICAKU4",
        "clean_data": "MakeTensorPtrCanonicalizer需完善补齐功能以支持社区FA用例",
        "created_at": "2025-05-26T16:03:04+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-05-26T16:03:04+08:00"
    },
    {
        "id": 174,
        "source_id": "02114177751569170015",
        "title": "Add算子调用体验",
        "body": "<div class=\"cke-article\">设置路径时要注意是否正确设置了，因为这一步如果多打了字母或者少打了字母不会报错。</div>",
        "url": "https://www.hiascend.com/forum/thread-02114177751569170015-1-1.html",
        "clean_data": "Add算子调用需严格校验路径拼写，因路径错误不会触发显式报错。建议开发者检查路径配置的正确性以避免算子调用失效。",
        "created_at": "2025-03-19T07:26:09+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-19T07:26:09+08:00"
    },
    {
        "id": 573,
        "source_id": "20780927",
        "title": "CVE-2023-31047",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-31047](https://nvd.nist.gov/vuln/detail/CVE-2023-31047)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn Django 3.2 before 3.2.19, 4.x before 4.1.9, and 4.2 before 4.2.1, it was possible to bypass validation when using one form field to upload multiple files. This multiple upload has never been supported by forms.FileField or forms.ImageField (only the last uploaded file was validated). However, Django_x27;s \"Uploading multiple files\" documentation suggested otherwise.\n\n漏洞公开时间：2023-05-07 10:15:08\n漏洞创建时间：2025-06-08 00:41:44\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-31047\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDENZ",
        "clean_data": "标题：CVE 2023 31047   描述：Django 3 2 7及以下版本在单字段多文件上传时存在验证绕过漏洞。官方文档误称支持form FileField多文件验证，实际仅校验最后一个文件，导致前端上传多文件易触发安全问题。建议升级至3 2 19、4 1 9或4 2 1及以上版本。",
        "created_at": "2025-06-08T00:41:45+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:41:45+08:00"
    },
    {
        "id": 574,
        "source_id": "20780929",
        "title": "CVE-2024-4067",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-4067](https://nvd.nist.gov/vuln/detail/CVE-2024-4067)\n漏洞归属组件：micromatch\n漏洞归属的版本：4.0.8\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe NPM package `micromatch` prior to 4.0.8 is vulnerable to Regular Expression Denial of Service (ReDoS). The vulnerability occurs in `micromatch.braces()` in `index.js` because the pattern `.*` will greedily match anything. By passing a malicious payload, the pattern matching will keep backtracking to the input while it doesn_x27;t find the closing bracket. As the input size increases, the consumption time will also increase until it causes the application to hang or slow down. There was a merged fix but further testing shows the issue persists. This issue should be mitigated by using a safe pattern that won_x27;t start backtracking the regular expression due to greedy matching. This issue was fixed in version 4.0.8.\n\n漏洞公开时间：2024-05-14 23:42:47\n漏洞创建时间：2025-06-08 00:41:57\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-4067\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEO1",
        "clean_data": "CVE 2024 4067：micromatch  4 0 8 存在 ReDoS 漏洞，因贪婪匹配      导致应用挂起。建议升级至 4 0 8 修复。",
        "created_at": "2025-06-08T00:41:58+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:41:58+08:00"
    },
    {
        "id": 575,
        "source_id": "20780930",
        "title": "CVE-2023-30861",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-30861](https://nvd.nist.gov/vuln/detail/CVE-2023-30861)\n漏洞归属组件：flask\n漏洞归属的版本：1.1.2\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nFlask is a lightweight WSGI web application framework. When all of the following conditions are met, a response containing data intended for one client may be cached and subsequently sent by the proxy to other clients. If the proxy also caches `Set-Cookie` headers, it may send one client_x27;s `session` cookie to other clients. The severity depends on the application_x27;s use of the session and the proxy_x27;s behavior regarding cookies. The risk depends on all these conditions being met.\n\n1. The application must be hosted behind a caching proxy that does not strip cookies or ignore responses with cookies.\n2. The application sets `session.permanent = True`\n3. The application does not access or modify the session at any point during a request.\n4. `SESSION_REFRESH_EACH_REQUEST` enabled (the default).\n5. The application does not set a `Cache-Control` header to indicate that a page is private or should not be cached.\n\nThis happens because vulnerable versions of Flask only set the `Vary: Cookie` header when the session is accessed or modified, not when it is refreshed (re-sent to update the expiration) without being accessed or modified. This issue has been fixed in versions 2.3.2 and 2.2.5.\n\n漏洞公开时间：2023-05-03 02:15:00\n漏洞创建时间：2025-06-08 00:41:59\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-30861\n",
        "url": "https://gitee.com/ascend/ascend-industrial/issues/ICDEO2",
        "clean_data": "CVE 2023 30861  Flask 1 1 2缓存漏洞   当Flask应用使用永久会话  session permanent True  且在未修改会话数据的场景下，若部署在不剥离 Set Cookie 头的缓存代理后端，可能导致会话cookie跨客户端泄露。修复方案升级至2 3 2 2 2 5版本。触发条件包括：   1  背后缓存代理未处理cookie缓存   2  会话未被显式访问 修改仅自动续期   3  页面未设置 Cache Control  private     漏洞公开于2023 05 03，NIST数据库创建时间为2025 06 08。详情见 NIST链接  https   nvd nist gov vuln detail CVE 2023 30861 。",
        "created_at": "2025-06-08T00:41:59+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:42:00+08:00"
    },
    {
        "id": 576,
        "source_id": "20780935",
        "title": "CVE-2024-45296",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-45296](https://nvd.nist.gov/vuln/detail/CVE-2024-45296)\n漏洞归属组件：path-to-regexp\n漏洞归属的版本：3.3.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\npath-to-regexp turns path strings into a regular expressions. In certain cases, path-to-regexp will output a regular expression that can be exploited to cause poor performance. Because JavaScript is single threaded and regex matching runs on the main thread, poor performance will block the event loop and lead to a DoS. The bad regular expression is generated any time you have two parameters within a single segment, separated by something that is not a period (.). For users of 0.1, upgrade to 0.1.10. All other users should upgrade to 8.0.0.\n\n漏洞公开时间：2024-09-10 03:15:13\n漏洞创建时间：2025-06-08 00:42:12\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-45296\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEO7",
        "clean_data": "CVE 2024 45296：path to regexp 3 3 0版本中，路径参数间若非句号分隔的正则表达式会引发性能降级 潜在DoS风险 。解决方案：0 1分支用户升级至0 1 10，其他用户升级至8 0 0。",
        "created_at": "2025-06-08T00:42:13+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T00:42:13+08:00"
    },
    {
        "id": 581,
        "source_id": "20781013",
        "title": "CVE-2023-46695",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-46695](https://nvd.nist.gov/vuln/detail/CVE-2023-46695)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nAn issue was discovered in Django 3.2 before 3.2.23, 4.1 before 4.1.13, and 4.2 before 4.2.7. The NFKC normalization is slow on Windows. As a consequence, django.contrib.auth.forms.UsernameField is subject to a potential DoS (denial of service) attack via certain inputs with a very large number of Unicode characters.\n\n漏洞公开时间：2023-11-02 14:15:08\n漏洞创建时间：2025-06-08 01:11:26\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-46695\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDEQD",
        "clean_data": "CVE 2023 46695：Django 3 2 7存在Unicode归一化处理缓慢漏洞，攻击者通过向UsernameField提交大量特殊Unicode字符可触发Windows系统DoS攻击。建议升级至Django 3 2 23 4 1 13 4 2 7以上版本。",
        "created_at": "2025-06-08T01:11:26+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-08T01:11:27+08:00"
    },
    {
        "id": 626,
        "source_id": "20812903",
        "title": "CVE-2023-7104",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-7104](https://nvd.nist.gov/vuln/detail/CVE-2023-7104)\n漏洞归属组件：sqlite\n漏洞归属的版本：5.1.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nA vulnerability was found in SQLite SQLite3 up to 3.43.0 and classified as critical. This issue affects the function sessionReadRecord of the file ext/session/sqlite3session.c of the component make alltest Handler. The manipulation leads to heap-based buffer overflow. It is recommended to apply a patch to fix this issue. The associated identifier of this vulnerability is VDB-248999.\n\n漏洞公开时间：2023-12-29 18:15:13\n漏洞创建时间：2025-06-10 18:10:04\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-7104\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICE3C7",
        "clean_data": "CVE 2023 7104：SQLite 5 1 1版本的sessionReadRecord函数存在Heap based Buffer Overflow漏洞 SQLite3  3 43 0 ，建议通过补丁修复。详情见 NIST CNVD CVE 2023 7104  https   nvd nist gov vuln detail CVE 2023 7104",
        "created_at": "2025-06-10T18:10:04+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-10T18:10:04+08:00"
    },
    {
        "id": 170,
        "source_id": "0275179994858784018",
        "title": "赛题argmaxwithvalue解题思路以及代码",
        "body": "<div class=\"cke-article\"><p><span><span><span>主线任务是使用不同的方法解决argmaxwithvalue。以体现不同的方法对最后算子性能的提升。具体计划如下：</span></span></span></p>  <ol>  <li><span><span><span>样例1使用GetValue,SetValue完成。</span></span></span></li>  <li><span><span><span>样例2 910服务器上使用多核以及DataCopyPad完成。</span></span></span></li>  <li><span><span><span>样例3 在样例2的基础上使用DoubleBuffer以及ReduceMax完成。</span></span></span></li> </ol>  <p><span><span><span>现阶段完成了样例1以及样例2，样例3可以使用DoubleBuffer策略，ReduceMax需要一定的学习与测试调试过程，后续空余时间继续研究与调试。</span></span></span></p>  <p></p>  <p><span><span><span>算子问题简述：给定数据data,shape为[d0, d1, d2,…,dn], 并给定di,获取di维上最大值，并把对应位置信息也需要返回。</span></span></span></p>  <p><span><span><span>Input0:data,shape as [d0, d1, d2, …, dn]</span></span></span></p>  <p><span><span><span>Input1:dimension di</span></span></span></p>  <p><span><span><span>Output0:values, shape as [d0,…di-1,di+1,…,dn]</span></span></span></p>  <p><span><span><span>Output1:indice, shape as [d0,…di-1,di+1,…,dn]</span></span></span></p>  <p></p>  <ol>  <li><span><span><span>样例1使用GetValue,SetValue在单核上完成</span></span></span></li> </ol>  <p style=\"margin-left: 24.0px;\"><span><span><span>解决思路：使用类似transpose的思想，把需要处理的具体的dimension(di)，transpose为最后一维。即从</span></span></span></p>  <p style=\"margin-left: 24.0px;\"><span><span><span>[d0,…di-1,di,di+1,…,dn]，transpose as </span></span></span></p>  <p style=\"margin-left: 24.0px;\"><span><span><span>[d0,…di-1,di+1,…,dn,di]</span></span></span></p>  <p><span><span><span>       然后采取类似数数的思想，从最后一维开始++（加一），当达到维度的Size时，便向前进1 .</span></span></span></p>  <p style=\"text-indent: 21.0pt;\"><span><span><span>如data.shape = (2, 3, 4, 5, 6), dimension = 2。先把dimension对应的维度放置到最后即（2，3，5，6，4）。</span></span></span></p>  <p style=\"text-indent: 21.0pt;\"><span><span><span>如当前的indice为[0,0,0,0,3]，下一个indice为[0, 0, 0, 1,0] (说明，最后一维度时逢4进1)，</span></span></span></p>  <p style=\"text-indent: 21.0pt;\"><span><span><span>又如当前的indice为[0,0,0,5,3]，下一个indice为[0, 0, 1, 0,0] (说明，最后一维度时逢4进1，倒数第二维逢6进1).</span></span></span></p>  <p style=\"text-indent: 21.0pt;\"><span><span><span>然后算法要做的是，已知当前indice为[I0, I1,…,Ii-1,Ii+1,…,In,0 ] 比较得出从</span></span></span></p>  <p><span><span><span>[I0, I1,…,Ii-1,Ii+1,…,In,0 ] 到[I0, I1,…,Ii-1,Ii+1,…,In,di_size - 1 ]的最大值，并把最大值与index使用SetValue接口写于Output0,Output1对应的[I0, I1,…,Ii-1,Ii+1,…,In]的位置上。</span></span></span></p>  <p><span><span><span>       如何根据indice获取对应offset是关键：</span></span></span></p>  <p><span><span><span>       dn 的加1 的offset为1</span></span></span></p>  <p><span><span><span>       dn -1 的加1 的offset为dn</span></span></span></p>  <p><span><span><span>       dn-2 的加1 的offet为dn * dn-1</span></span></span></p>  <p><span><span><span>       …</span></span></span></p>  <p><span><span><span>       d0 的加1 的offet为d1 * d2 *…* dn</span></span></span></p>  <p style=\"text-indent: 21.0pt;\"><span><span><span>如data.shape = (2, 3, 4, 5, 6), 需要计算dimension = 2。加1偏移列表dimensionOffsetList = [3*4*5*6, 4*5*6, 5*6, 6,1] = [360, 120, 30, 6, 1]，经过transpose为：dimensionOffsetList = [360, 120, 6, 1，30]，</span></span></span></p>  <p style=\"text-indent: 21.0pt;\"><span><span><span>如当前的indice为[1,2,3,4,4],则对应的offset为360*1+120*2+6*3+1*4+30*4，通过计算的offset获取对应的值，当最后一维加1时，对应的offset为之前的+30.比较[1,2,3,4,0:4],把最大值与对应的标签记录在[1,2,3,4]的位置上。</span></span></span></p>  <p style=\"text-indent: 21.0pt;\"><span><span><span>以此方法遍历所有的数据。最后获得Output0:values, shape as [d0,…di-1,di+1,…,dn]， Output1:indice, shape as [d0,…di-1,di+1,…,dn]</span></span></span></p>  <p style=\"text-indent: 21.0pt;\"></p>  <p style=\"text-indent: 21.0pt;\"><span><span><span>此方法由于用了gm上的GetValue与SetValue，不同核上存在一致性的问题，所以只能单核执行。</span></span></span></p>  <p></p>  <ol>  <li><span><span><span>样例2 910服务器上使用多核以及DataCopyPad完成。</span></span></span></li> </ol>  <p style=\"margin-left: 24.0px;\"><span><span><span>多核涉及tiling策略：如下</span></span></span></p>  <p style=\"margin-left: 24.0px;\"><span><span><span>计算大核的个数：bigCoreCount</span></span></span></p>  <p style=\"margin-left: 24.0px;\"><span><span><span>计算小核的个数：smallCoreCount</span></span></span></p>  <p style=\"margin-left: 24.0px;\"><span><span><span>计算大核需要处理的单元数：bigCoreDealCount（一个单元为处理的dimension从0到dimensionSize）</span></span></span></p>  <p style=\"margin-left: 24.0px;\"><span><span><span>计算小核需要处理的单元数：smallCoreDealCount</span></span></span></p>  <p style=\"margin-left: 24.0px;\"></p>  <p style=\"text-indent: 18.0pt;\"><span><span><span>对于每个核，通过叠加计算，计算开始的indice，以及要处理的单元数。每个单元处理完把对于的结果写于对于的indice的位置上。</span></span></span></p>  <p style=\"text-indent: 18.0pt;\"><span><span><span>使用DataCopyPad把gm上的数据搬运到lm上，lm上的位置需要考虑32对齐，然后每个核各自比较得到最大值并且记录。搬出同样使用DataCopyPad，gm上可以不考虑32对齐。因为各个aicore在各自的lm上写入，所以不存在一致性问题。并且通过EnQue&amp;DeQue保持数据处理的正确顺序。</span></span></span></p>  <p style=\"margin-left: 24.0px;\"></p>  <p><span><span><span>3、样例3 在样例2的基础上使用DoubleBuffer以及ReduceMax完成，目前只完成DoubleBuffer功能。分别在CopyIn与CopyOut的函数位置上记录当前读出与写入的位置。保证读入数据的位置与写入的位置的正确性。</span></span></span></p>  <p><span><span><span>       具体如下：</span></span></span></p>  <p><span><span><span>       CopyIn:</span></span></span></p>  <p><span><span><span><span class=\"easyimage easyimage-full\"><img alt=\"cke_189.png\" src=\"cid:pic_0\"></span></span></span></span></p>  <p><span><span><span>       CopyOut:</span></span></span></p>  <p><span><span><span><span class=\"easyimage easyimage-full\"><img alt=\"cke_190.png\" src=\"cid:pic_1\"></span></span></span></span></p>  <p></p>  <p><span><span><span>由于时间等的各种原因，ReduceMax函数正在调试中</span></span></span></p>  <p></p>  <p><span><span><span>可优化空间：</span></span></span></p>  <ol>  <li><span><span><span>datacopypad采取保守的方法，每次只取了一个dimensionSize的数据大小，没有充分利用所有的ub。</span></span></span></li>  <li><span><span><span>ReduceMax（后续补上）</span></span></span></li> </ol>  <p style=\"margin-left: 24.0px;\"></p>  <p><span><span><span>遇到问题：使用ReduceMax只求出了MaxValue，但没有给出indice。</span></span></span></p>  <p></p>  <p>源代码可以可联系楼主：13510421536</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0275179994858784018-1-1.html",
        "clean_data": "事件标题  argmaxwithvalue算子不同实现方案及性能优化问题  正文   针对argmaxwithvalue算子开发实现不同优化方案： 1  样例1 单核实现 ：采用维度转置战略将目标维度移至末尾，通过逐位递增逻辑遍历数据 di size 1  如 5 6   6 5  ，利用GetObject和SetObject接口进行数据处理。存在核间一致性问题导致单核运行。 2  样例2 多核实现 ：在910服务器上使用tiling划分大核 小核数量 360 120等参数 ，通过DataCopyPad实现GM LM数据搬运 考虑32字节对齐 ，各核独立处理完成后使用EnQue DeQue保证输出顺序。 3  样例3 DoubleBuffer ReduceMax ：基于样例2框架实现DoubleBuffer数据流转，CopyIn CopyOut接口记录读写偏移。当前遇到ReduceMax仅能输出最大值无法获取索引的问题，需进一步调试。  待解决问题：ReduceMax如何记录最大值索引，提升DataCopyPad利用率 当前未完全使用UB资源 。",
        "created_at": "2025-04-14T06:34:19+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-17T08:56:17+08:00"
    },
    {
        "id": 171,
        "source_id": "0275179975724822015",
        "title": "【解决方案】【FAQ】解决OpenEuler24.03系统编译时fatal error: 'cstdint' file not found报错问题",
        "body": "<div class=\"cke-article\"><h1 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-transform: none;vertical-align: baseline;white-space: normal;word-spacing: 0.0px;\">问题现象：</h1>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\"> fatal error: 'cstdint' file not found<br> #include &lt;cstdint&gt;<br>          ^~~~~~~~~<br> 1 error generated.</p>  <h1 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-transform: none;vertical-align: baseline;white-space: normal;word-spacing: 0.0px;\">问题原因：</h1>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">C++库未包含</p>  <h1 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-transform: none;vertical-align: baseline;white-space: normal;word-spacing: 0.0px;\">解决方案：</h1>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">Ⅰ：添加环境变量(根据安装版本进行修改)</p>  <pre style=\"background-color: rgb(240,240,240);box-sizing: border-box;color: rgb(42,43,49);font-size: 16.0px;font-style: normal;font-weight: 400;letter-spacing: normal;overflow: auto;padding: 0.0px;position: relative;text-transform: none;vertical-align: baseline;word-spacing: 0.0px;\">\nexport CPLUS_INCLUDE_PATH=/usr/include/c++/12:/usr/include/c++/12/aarch64-openEuler-linux:$CPLUS_INCLUDE_PATH\n复制</pre>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">Ⅱ：若通过方案I未解决</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">执行gcc --version 和 g++ --version看两者版本是否一致</p>  <p style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(42,43,49);letter-spacing: normal;min-height: 28.8px;text-transform: none;vertical-align: baseline;white-space: normal;word-break: break-word;word-spacing: 0.0px;\">如果版本不一致，请卸载其中一个，然后安装版本一致的gcc或g++即可解决问题。</p>  <h3 style=\"background-color: rgb(255,255,255);box-sizing: border-box;color: rgb(51,51,51);letter-spacing: normal;text-transform: none;vertical-align: baseline;white-space: normal;word-spacing: 0.0px;\">若依旧无法解决您的问题，可以到工单及论坛反馈您的问题</h3></div>",
        "url": "https://www.hiascend.com/forum/thread-0275179975724822015-1-1.html",
        "clean_data": "问题现象：编译时报   fatal error   cstdint  file not found  。   问题原因：系统缺少C  库支持。   解决方案：   1  添加环境变量  export CPLUS INCLUDE PATH  usr include c   12  usr include c   12 aarch64 openEuler linux   CPLUS INCLUDE PATH    需根据实际库路径调整 。   2  若未解决，检查  gcc   version  与  g     version  版本一致性，不一致则卸载并安装相同版本编译器。",
        "created_at": "2025-04-14T01:15:25+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-14T01:15:25+08:00"
    },
    {
        "id": 586,
        "source_id": "20785179",
        "title": "CVE-2024-29180",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-29180](https://nvd.nist.gov/vuln/detail/CVE-2024-29180)\n漏洞归属组件：webpack-dev-middleware\n漏洞归属的版本：5.3.4\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nPrior to versions 7.1.0, 6.1.2, and 5.3.4, the webpack-dev-middleware development middleware for devpack does not validate the supplied URL address sufficiently before returning the local file. It is possible to access any file on the developer_x27;s machine. The middleware can either work with the physical filesystem when reading the files or it can use a virtualized in-memory `memfs` filesystem. If `writeToDisk` configuration option is set to `true`, the physical filesystem is used. The `getFilenameFromUrl` method is used to parse URL and build the local file path. The public path prefix is stripped from the URL, and the `unsecaped` path suffix is appended to the `outputPath`. As the URL is not unescaped and normalized automatically before calling the midlleware, it is possible to use `%2e` and `%2f` sequences to perform path traversal attack.\n\nDevelopers using `webpack-dev-server` or `webpack-dev-middleware` are affected by the issue. When the project is started, an attacker might access any file on the developer_x27;s machine and exfiltrate the content. If the development server is listening on a public IP address (or `0.0.0.0`), an attacker on the local network can access the local files without any interaction from the victim (direct connection to the port). If the server allows access from third-party domains, an attacker can send a malicious link to the victim. When visited, the client side script can connect to the local server and exfiltrate the local files. Starting with fixed versions 7.1.0, 6.1.2, and 5.3.4, the URL is unescaped and normalized before any further processing.\n\n漏洞公开时间：2024-03-22 01:15:09\n漏洞创建时间：2025-06-09 05:10:03\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-29180\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDHY3",
        "clean_data": "CVE 2024 29180 webpack dev middleware 5 3 4 漏洞提醒：   影响组件：webpack dev middleware中未处理URL编码导致路径遍历漏洞   风险：攻击者可通过 2e  2f绕过路径校验读取开发者本地敏感文件   修复建议：升级至7 1 0 6 1 2 5 3 4 ，新版已实现URL解码和路径规范化处理  详情参考：https   nvd nist gov vuln detail CVE 2024 29180",
        "created_at": "2025-06-09T05:10:03+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T05:10:03+08:00"
    },
    {
        "id": 590,
        "source_id": "20785888",
        "title": "CVE-2022-24999",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-24999](https://nvd.nist.gov/vuln/detail/CVE-2022-24999)\n漏洞归属组件：qs\n漏洞归属的版本：6.5.3\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nqs before 6.10.3, as used in Express before 4.17.3 and other products, allows attackers to cause a Node process hang for an Express application because an __ proto__ key can be used. In many typical Express use cases, an unauthenticated remote attacker can place the attack payload in the query string of the URL that is used to visit the application, such as a[__proto__]=b&a[__proto__]&a[length]=100000000. The fix was backported to qs 6.9.7, 6.8.3, 6.7.3, 6.6.1, 6.5.3, 6.4.1, 6.3.3, and 6.2.4 (and therefore Express 4.17.3, which has \"deps: qs@6.9.7\" in its release description, is not vulnerable).\n\n漏洞公开时间：2022-11-27 06:15:10\n漏洞创建时间：2025-06-09 09:11:08\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-24999\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIHS",
        "clean_data": "CVE 2022 24999：qs 6 5 3版本存在可通过  proto  键构造URL参数导致Node进程挂起的漏洞，建议升级至qs 6 9 7或6 8 3等已修复版本。",
        "created_at": "2025-06-09T09:11:08+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:09+08:00"
    },
    {
        "id": 591,
        "source_id": "20785890",
        "title": "CVE-2024-42367",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-42367](https://nvd.nist.gov/vuln/detail/CVE-2024-42367)\n漏洞归属组件：aiohttp\n漏洞归属的版本：3.7.4\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\naiohttp is an asynchronous HTTP client/server framework for asyncio and Python. Prior to version 3.10.2, static routes which contain files with compressed variants (`.gz` or `.br` extension) are vulnerable to path traversal outside the root directory if those variants are symbolic links. The server protects static routes from path traversal outside the root directory when `follow_symlinks=False` (default).  It does this by resolving the requested URL to an absolute path and then checking that path relative to the root. However, these checks are not performed when looking for compressed variants in the `FileResponse` class, and symbolic links are then automatically followed when performing the `Path.stat()` and `Path.open()` to send the file. Version 3.10.2 contains a patch for the issue.\n\n漏洞公开时间：2024-08-12 21:38:34\n漏洞创建时间：2025-06-09 09:11:11\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-42367\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIHU",
        "clean_data": "CVE 2024 42367  aiohttp  3 10 2 存在路径遍历漏洞，当静态路由处理压缩文件  gz  br 存在符号链接时可能绕过默认的根目录保护。修复方式：升级至3 10 2及以上版本。详情参考  NVD链接  https   nvd nist gov vuln detail CVE 2024 42367",
        "created_at": "2025-06-09T09:11:11+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:11+08:00"
    },
    {
        "id": 592,
        "source_id": "20785891",
        "title": "CVE-2023-47627",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-47627](https://nvd.nist.gov/vuln/detail/CVE-2023-47627)\n漏洞归属组件：aiohttp\n漏洞归属的版本：3.7.4\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\naiohttp is an asynchronous HTTP client/server framework for asyncio and Python. The HTTP parser in AIOHTTP has numerous problems with header parsing, which could lead to request smuggling. This parser is only used when AIOHTTP_NO_EXTENSIONS is enabled (or not using a prebuilt wheel). These bugs have been addressed in commit `d5c12ba89` which has been included in release version 3.8.6. Users are advised to upgrade. There are no known workarounds for these issues.\n\n漏洞公开时间：2023-11-15 05:15:12\n漏洞创建时间：2025-06-09 09:11:14\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-47627\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIHV",
        "clean_data": "CVE 2023 47627   aiohttp 3 7 4 HTTP请求走私漏洞：头解析器存在多处缺陷，导致请求走私风险。该问题影响启用AIOHTTP NO EXTENSIONS或使用非预编译wheel的场景。已通过提交d5c12ba89修复 3 8 6 版本 ，建议升级规避。当前无临时修复方案。",
        "created_at": "2025-06-09T09:11:14+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:14+08:00"
    },
    {
        "id": 593,
        "source_id": "20785894",
        "title": "CVE-2022-33987",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-33987](https://nvd.nist.gov/vuln/detail/CVE-2022-33987)\n漏洞归属组件：got\n漏洞归属的版本：11.8.6\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe got package before 12.1.0 (also fixed in 11.8.5) for Node.js allows a redirect to a UNIX socket.\n\n漏洞公开时间：2022-06-19 05:15:00\n漏洞创建时间：2025-06-09 09:11:17\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-33987\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIHY",
        "clean_data": "CVE 2022 33987  node js got包在12 1 0之前的版本存在UNIX套接字重定向漏洞，建议升级至11 8 5或12 1 0  即使问题版本号显示11 8 6，但实际修复需关注11 8 5和12 1 0 。漏洞公开于2022年6月19日，详情参考： NIST  https   nvd nist gov vuln detail CVE 2022 33987",
        "created_at": "2025-06-09T09:11:17+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:18+08:00"
    },
    {
        "id": 595,
        "source_id": "20785926",
        "title": "CVE-2021-23364",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-23364](https://nvd.nist.gov/vuln/detail/CVE-2021-23364)\n漏洞归属组件：browserslist\n漏洞归属的版本：4.24.3\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe package browserslist from 4.0.0 and before 4.16.5 are vulnerable to Regular Expression Denial of Service (ReDoS) during parsing of queries.\n\n漏洞公开时间：2021-04-29 00:15:00\n漏洞创建时间：2025-06-09 09:11:34\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-23364\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIIU",
        "clean_data": "CVE 2021 23364  browserslist 4 0 0 4 16 5 版本解析查询时存在正则表达式拒绝服务 ReDoS 漏洞。",
        "created_at": "2025-06-09T09:11:34+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:34+08:00"
    },
    {
        "id": 596,
        "source_id": "20785929",
        "title": "CVE-2021-23343",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-23343](https://nvd.nist.gov/vuln/detail/CVE-2021-23343)\n漏洞归属组件：path-parse\n漏洞归属的版本：1.0.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nAll versions of package path-parse are vulnerable to Regular Expression Denial of Service (ReDoS) via splitDeviceRe, splitTailRe, and splitPathRe regular expressions. ReDoS exhibits polynomial worst-case time complexity.\n\n漏洞公开时间：2021-05-04 17:15:00\n漏洞创建时间：2025-06-09 09:11:38\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-23343\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIIX",
        "clean_data": "CVE 2021 23343：path parse组件1 0 7版本中splitDeviceRe splitTailRe splitPathRe正则表达式存在ReDoS漏洞，最坏情况时间复杂度为多项式级。漏洞公开时间2021 05 04，创建时间存在异常 显示2025 06 09，建议核实",
        "created_at": "2025-06-09T09:11:38+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:39+08:00"
    },
    {
        "id": 597,
        "source_id": "20785932",
        "title": "CVE-2024-41818",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-41818](https://nvd.nist.gov/vuln/detail/CVE-2024-41818)\n漏洞归属组件：fast-xml-parser\n漏洞归属的版本：4.4.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nfast-xml-parser is an open source, pure javascript xml parser. a ReDOS exists on currency.js. This vulnerability is fixed in 4.4.1.\n\n漏洞公开时间：2024-07-30 00:15:05\n漏洞创建时间：2025-06-09 09:11:40\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-41818\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDIJ0",
        "clean_data": "CVE 2024 41818  fast xml parser 4 4 1 版本在 currency js 中存在正则表达式拒绝服务 ReDOS 漏洞。建议升级至 4 4 1 修复版本以消除风险。",
        "created_at": "2025-06-09T09:11:40+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:11:41+08:00"
    },
    {
        "id": 161,
        "source_id": "0226183888355612029",
        "title": "模型训练打印loss报错507015",
        "body": "<div class=\"cke-article\"><p>问题描述：</p>  <p>在模型训练过程中，运行到loss.backward()之前打印loss无报错，运行后backward之后打印loss报错，报错内容如下</p>  <p>[W NPUStream.cpp:368] Warning: NPU warning, error code is 507015[Error]:  </p>  <p>[Error]: The aicore execution is abnormal.  </p>  <p>Rectify the fault based on the error information in the ascend log. </p>  <p>EH9999: Inner Error! </p>  <p>rtDeviceSynchronize execute failed, reason=[aicore exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:50] </p>  <p>EH9999  wait for compute device to finish failed, runtime result = 507015.[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161] </p>  <p>TraceBack (most recent call last): </p>  <p> (function npuSynchronizeDevice) </p></div>",
        "url": "https://www.hiascend.com/forum/thread-0226183888355612029-1-1.html",
        "clean_data": "模型训练中在loss backward  之后打印loss时触发NPU异常错误507015，表现为aicore执行异常、设备等待失败及Ascend日志提示。需检查模型计算资源占用情况，确认backward后loss值是否仍可访问，排查设备同步或内存泄漏问题。",
        "created_at": "2025-05-29T08:05:56+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-04T01:21:39+08:00"
    },
    {
        "id": 183,
        "source_id": "02108172651410861230",
        "title": "deb格式和run格式的区别",
        "body": "<div class=\"cke-article\">我下载了Ascend-cann-toolkit_8.0.RC3_linux-x86_64.deb到ubuntu，双击安装，在/usr/local/Ascend下存在Ascend-cann-toolkit_8.0.RC3_linux-x86_64.run。这和直接下载Ascend-cann-toolkit_8.0.RC3_linux-x86_64.run有什么区别吗？</div>",
        "url": "https://www.hiascend.com/forum/thread-02108172651410861230-1-1.html",
        "clean_data": "deb格式是Ubuntu系统的原生命令行安装包，需通过dpkg apt安装且自动处理依赖；run格式为通用二进制安装脚本，需手动执行且不自动处理依赖。二者打包逻辑不同，deb包解压后不会残留 run文件，用户操作中出现的 run文件可能是安装过程中的临时组件。建议Debian系系统优先选择 deb包。",
        "created_at": "2025-01-19T06:43:31+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-22T08:58:38+08:00"
    },
    {
        "id": 112,
        "source_id": "20732767",
        "title": "CVE-2025-30167",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-30167](https://nvd.nist.gov/vuln/detail/CVE-2025-30167)\n漏洞归属组件：jupyter\n漏洞归属的版本：1.0.0\nCVSS V3分值：\n&emsp;BaseScore: 7.3 High\n&emsp;Vector: CVSS:3.1/AV:L/AC:L/PR:L/UI:R/S:U/C:H/I:H/A:H\n\n漏洞简述：\nJupyter Core is a package for the core common functionality of Jupyter projects. When using Jupyter Core prior to version 5.8.0 on Windows, the shared `%PROGRAMDATA%` directory is searched for configuration files (`SYSTEM_CONFIG_PATH` and `SYSTEM_JUPYTER_PATH`), which may allow users to create configuration files affecting other users. Only shared Windows systems with multiple users and unprotected `%PROGRAMDATA%` are affected. Users should upgrade to Jupyter Core version 5.8.0 or later to receive a patch. Some other mitigations are available. As administrator, modify the permissions on the `%PROGRAMDATA%` directory so it is not writable by unauthorized users; or as administrator, create the `%PROGRAMDATA%\\jupyter` directory with appropriately restrictive permissions; or as user or administrator, set the `%PROGRAMDATA%` environment variable to a directory with appropriately restrictive permissions (e.g. controlled by administrators _or_ the current user).\n\n漏洞公开时间：2025-06-04 01:15:21\n漏洞创建时间：2025-06-04 09:55:06\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-30167\n",
        "url": "https://gitee.com/ascend/modelzoo-TensorFlow-bak/issues/ICCDI7",
        "clean_data": "CVE 2025 30167：Jupyter 5 8 0 Windows版本权限漏洞，共享 PROGRAMDATA 目录下的配置文件可能被修改影响多用户环境。建议升级至5 8 0 ，或通过限制 PROGRAMDATA  jupyter目录权限规避风险 管理员手动设置只读 可访问目录权限 。CVSS 7 3 High评分。",
        "created_at": "2025-06-04T09:55:06+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": [
            "[]"
        ],
        "source_closed": false,
        "updated_at": "2025-06-10T11:25:06+08:00"
    },
    {
        "id": 180,
        "source_id": "0236177061362063063",
        "title": "在运行run.sh时出现报错",
        "body": "<div class=\"cke-article\"><p><span class=\"easyimage easyimage-full\"><img alt=\"145e73c4adb22cd2e61418e8c90798eb_0.png\" src=\"cid:pic_0\"></span></p>  <p>原因是没有下载最新的CANN版本，版本最新的才可以进行匹配。</p>  <p>解决的方法是到下载的官网中更新最新的版本包</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0236177061362063063-1-1.html",
        "clean_data": "标题：运行run sh报错   内容：未安装最新CANN版本导致无法匹配。需从官网下载最新版本包更新。",
        "created_at": "2025-03-11T07:42:42+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-11T07:42:42+08:00"
    },
    {
        "id": 185,
        "source_id": "0215171571606938196",
        "title": "TBE的自动优化程度怎么样，想要达到同样性能（不追求极致性能）与Ascend C相比哪个更容易呀",
        "body": "<div class=\"cke-article\"><p>由于之前使用过Cuda和Triton在GPU上进行算子开发，有一个经验就是：用Cuda开发的算子经过全方位的非常深度的优化，性能才能追平用triton直接开发的算子，一旦优化不够，性能和triton差距往往很大。因为triton有很成熟的自动优化机制，但是cuda所有的优化都要自己来，而且当输入数据的尺寸不固定时，优化难度就更大了。而且triton的算子开发难度很小，也不需要怎么考虑优化的问题，就是简单将算子的计算逻辑实现了就够了，但是性能却能达到cuda经过很大程度优化的性能，性价比极高。</p>  <p></p>  <p>所以我看到华为在NPU上开发算子也提供了两套方案：TBE和Ascend C。前者基于python开发，后者基于C++开发。我目前的理解是TBE就相当于是NPU上的Triton，也可以自动优化，开发难度低，简单实现就能达到很高的性能。Ascend则相当于Cuda，开发难度大，往往需要非常深度的优化才能在性能上接近用TBE实现的算子，没有一定开发经验想要超过TBE基本不可能。</p>  <p>所以如果刚接触这两套开发工具链，想要开发NPU上的算子，而且算子的输入形状是可变的。但是不追求极致性能（但是性能也要过得去，最起码要达到极致性能的70%），使用哪一个更加容易达到呢？</p></div>",
        "url": "https://www.hiascend.com/forum/thread-0215171571606938196-1-1.html",
        "clean_data": "TBE与Ascend C性能开发对比分析： 问：输入形状可变但无需极致性能时，哪套工具链更容易达到70  性能？ 答：TBE方案更易实现预期目标。其Python框架内置自定义级联自动优化机制 如结构化分解 通用图优化 ，可适应动态输入形状，开发者仅需完成算子逻辑定义即可获得较优性能。Ascend C作为底层C  框架要求手动优化数据通道、core利用率等细节，对新手存在陡峭的学习曲线且代码调试周期较长。",
        "created_at": "2025-01-06T18:46:47+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-20T11:48:46+08:00"
    },
    {
        "id": 598,
        "source_id": "20786168",
        "title": "InferSession和torch加载不同的卡时，代码退出报错",
        "body": "一、问题现象（附报错日志上下文）：\r\nInferSession和torch加载不同的卡时，代码退出报错\r\n\r\n\r\n\r\n二、软件版本:\r\n-- CANN 版本 (8.0.0):  \r\n--Tensorflow/Pytorch/MindSpore 版本:\r\n--Python 版本 (Python 3.11.6):\r\n-- MindStudio版本 (ais-bench 0.0.2):\r\n--操作系统版本 (openEuler release 24.03 (LTS)):\r\n\r\n三、测试步骤：\r\n代码片断：\r\n\r\n```\r\nfrom ais_bench.infer.interface import InferSession\r\n\r\nmodel_path_asr = '/root/torch_npu_sample/asr_model_dynamic.om'\r\nencoder111 = InferSession(1, model_path_asr)\r\ndevice = torch.device('npu:3')\r\nparam_val = torch.randn(1, 32).to(device)\r\n```\r\n\r\n\r\n四、日志信息:\r\n# python torch_npu_sample_new1.py\r\n/usr/local/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\r\n  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\r\n[INFO] acl init success\r\n[INFO] open device 1 success\r\n[INFO] create new context\r\n[INFO] load model /root/torch_npu_sample/asr_model_dynamic.om success\r\n[INFO] create model description success\r\n[INFO] unload model success, model Id is 1\r\n[INFO] end to reset device 1",
        "url": "https://gitee.com/ascend/tools/issues/ICDIPK",
        "clean_data": "精炼版：   跨算子卡退出异常：InferSession device1 与Torch device3 混合加载模型时，进程资源未正确释放导致错误码500002，能否强制统一设备加载？    核心逻辑链：   1  标题直接点出资源冲突 不同卡混合加载  2  代码片断展示device id 1和device npu 3的分配差异 3  日志提取关键资源管理点：acl init   open device 1   load model   unload model 4  留存报错核心特征 加载om模型失败 及关联环境信息 8 0 0   Python 3 11",
        "created_at": "2025-06-09T09:21:39+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:21:40+08:00"
    },
    {
        "id": 27,
        "source_id": "19732619",
        "title": "L0上M和L1上M不一致时精度问题",
        "body": "",
        "url": "https://gitee.com/ascend/ascend-linear-algebra-ops/issues/IBQXSB",
        "clean_data": "L0 L1上M配置不一致导致精度差异。建议检查以下三点： 1  统一各级M参数数值 2  确认上板流程中参数对齐规则 3  验证NPU缓存机制是否兼容不同层级配置  注：问题描述缺失具体场景 如框架 芯片版本 模型类型 ，如需更准确方案请补充：1 不一致形态 数值 维度 数据类型  2 具体报错日志或性能对比数据",
        "created_at": "2025-03-05T15:54:21+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-03-05T15:54:21+08:00"
    },
    {
        "id": 599,
        "source_id": "20786755",
        "title": "CVE-2022-25858",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-25858](https://nvd.nist.gov/vuln/detail/CVE-2022-25858)\n漏洞归属组件：terser\n漏洞归属的版本：5.37.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThe package terser before 4.8.1, from 5.0.0 and before 5.14.2 are vulnerable to Regular Expression Denial of Service (ReDoS) due to insecure usage of regular expressions.\n\n漏洞公开时间：2022-07-16 04:15:00\n漏洞创建时间：2025-06-09 09:41:04\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-25858\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDJ5V",
        "clean_data": "CVE 2022 25858：Terser组件正则表达式不安全使用引发ReDoS漏洞      Terser 5 37 0及旧版 4 8 1前、5 14 2前 因正则表达式逻辑缺陷可能导致拒绝服务攻击，建议升级至安全版本以修复风险。",
        "created_at": "2025-06-09T09:41:04+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:41:04+08:00"
    },
    {
        "id": 600,
        "source_id": "20786759",
        "title": "CVE-2021-3807",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2021-3807](https://nvd.nist.gov/vuln/detail/CVE-2021-3807)\n漏洞归属组件：ansi-regex\n漏洞归属的版本：6.0.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nansi-regex is vulnerable to Inefficient Regular Expression Complexity\n\n漏洞公开时间：2021-09-17 15:15:00\n漏洞创建时间：2025-06-09 09:41:06\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2021-3807\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDJ5Z",
        "clean_data": "CVE 2021 3807：ansi regex组件6 0 1版本存在正则表达式效率低导致性能问题的漏洞，建议升级最新稳定版本以修复。",
        "created_at": "2025-06-09T09:41:06+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:41:06+08:00"
    },
    {
        "id": 601,
        "source_id": "20786764",
        "title": "CVE-2023-23931",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-23931](https://nvd.nist.gov/vuln/detail/CVE-2023-23931)\n漏洞归属组件：cryptography\n漏洞归属的版本：2.1.4\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\ncryptography is a package designed to expose cryptographic primitives and recipes to Python developers. In affected versions `Cipher.update_into` would accept Python objects which implement the buffer protocol, but provide only immutable buffers. This would allow immutable objects (such as `bytes`) to be mutated, thus violating fundamental rules of Python and resulting in corrupted output. This now correctly raises an exception. This issue has been present since `update_into` was originally introduced in cryptography 1.8.\n\n漏洞公开时间：2023-02-08 05:15:09\n漏洞创建时间：2025-06-09 09:41:12\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-23931\n",
        "url": "https://gitee.com/ascend/modelzoo-TensorFlow-bak/issues/ICDJ64",
        "clean_data": "cryptography 2 1 4版本CVE 2023 23931修复： update into 方法现已正确拒绝不可变buffer对象     该漏洞源于cryptography实现的 update into 方法长期 自v1 8起 错误接受仅提供不可变buffer的Python对象 如 bytes  ，导致数据篡改。修复版本中若检测到此类不可变对象，将抛出异常避免输出污染。建议升级至2 1 4以上版本。",
        "created_at": "2025-06-09T09:41:12+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:41:12+08:00"
    },
    {
        "id": 602,
        "source_id": "20786771",
        "title": "CVE-2023-26159",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-26159](https://nvd.nist.gov/vuln/detail/CVE-2023-26159)\n漏洞归属组件：follow-redirects\n漏洞归属的版本：1.15.3\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nVersions of the package follow-redirects before 1.15.4 are vulnerable to Improper Input Validation due to the improper handling of URLs by the url.parse() function. When new URL() throws an error, it can be manipulated to misinterpret the hostname. An attacker could exploit this weakness to redirect traffic to a malicious site, potentially leading to information disclosure, phishing attacks, or other security breaches.\n\n漏洞公开时间：2024-01-02 13:15:08\n漏洞创建时间：2025-06-09 09:41:15\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-26159\n",
        "url": "https://gitee.com/ascend/Asight/issues/ICDJ6B",
        "clean_data": "CVE 2023 26159 follow redirects 1 15 3 URL解析漏洞    follow redirects 1 15 3版本中，url parse  函数因输入验证不足，导致new URL  异常时可能出现域名解析错误，存在流量劫持风险。升级至1 15 4及以上版本可修复。",
        "created_at": "2025-06-09T09:41:15+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:41:15+08:00"
    },
    {
        "id": 604,
        "source_id": "20786774",
        "title": "CVE-2022-28347",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-28347](https://nvd.nist.gov/vuln/detail/CVE-2022-28347)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nA SQL injection issue was discovered in QuerySet.explain() in Django 2.2 before 2.2.28, 3.2 before 3.2.13, and 4.0 before 4.0.4. This occurs by passing a crafted dictionary (with dictionary expansion) as the **options argument, and placing the injection payload in an option name.\n\n漏洞公开时间：2022-04-12 13:15:00\n漏洞创建时间：2025-06-09 09:41:18\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-28347\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDJ6E",
        "clean_data": "CVE 2022 28347：Django 3 2 7及以下版本QuerySet explain  存在SQL注入漏洞，攻击者可通过构造携带字典扩展的  options参数进行利用。建议升级至3 2 13以上版本修复。",
        "created_at": "2025-06-09T09:41:18+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:41:18+08:00"
    },
    {
        "id": 605,
        "source_id": "20786776",
        "title": "CVE-2022-25881",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-25881](https://nvd.nist.gov/vuln/detail/CVE-2022-25881)\n漏洞归属组件：http-cache-semantics\n漏洞归属的版本：4.1.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nThis affects versions of the package http-cache-semantics before 4.1.1. The issue can be exploited via malicious request header values sent to a server, when that server reads the cache policy from the request using this library.\n\n漏洞公开时间：2023-01-31 13:15:11\n漏洞创建时间：2025-06-09 09:41:19\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-25881\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDJ6G",
        "clean_data": "http cache semantics 组件 CVE 2022 25881 漏洞：未说明基础评分如何通过恶意请求头利用缓存策略解析漏洞。",
        "created_at": "2025-06-09T09:41:20+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T09:41:20+08:00"
    },
    {
        "id": 606,
        "source_id": "20787544",
        "title": "CVE-2025-22150",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-22150](https://nvd.nist.gov/vuln/detail/CVE-2025-22150)\n漏洞归属组件：undici\n漏洞归属的版本：6.21.1\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nUndici is an HTTP/1.1 client. Starting in version 4.5.0 and prior to versions 5.28.5, 6.21.1, and 7.2.3, undici uses `Math.random()` to choose the boundary for a multipart/form-data request. It is known that the output of `Math.random()` can be predicted if several of its generated values are known. If there is a mechanism in an app that sends multipart requests to an attacker-controlled website, they can use this to leak the necessary values. Therefore, an attacker can tamper with the requests going to the backend APIs if certain conditions are met. This is fixed in versions 5.28.5, 6.21.1, and 7.2.3. As a workaround, do not issue multipart requests to attacker controlled servers.\n\n漏洞公开时间：2025-01-22 02:15:14\n漏洞创建时间：2025-06-09 10:10:52\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-22150\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDJRS",
        "clean_data": "CVE 2025 22150：undici 4 5 0至6 21 1版本中multipart form data请求边界使用 Math random   生成，攻击者可预测边界值篡改API请求。需升级至5 28 5、6 21 1或7 2 3以上版本，或避免向攻击者控制的服务器发送multipart请求。",
        "created_at": "2025-06-09T10:10:53+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T10:10:53+08:00"
    },
    {
        "id": 146,
        "source_id": "0240174274074453006",
        "title": "atlas800 安装了Ascend-cann使用后有提示算法问题，想问问是什么原因导致的",
        "body": "<div class=\"cke-article\"><p>atlas800 安装的操作系统是ununtu，系统内核是5.4.0.26，用的是altas 300I pro推理卡，然后cann版本是 Ascend-cann-toolkit_6.0.2.1，想请教下是什么原因导致的，附图是故障图和安装的cann类型</p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_1060.png\" src=\"cid:pic_1\"></span></p>  <p><span class=\"easyimage easyimage-full\"><img alt=\"cke_2985.jpeg\" src=\"cid:pic_0\"></span></p></div>",
        "url": "https://www.hiascend.com/forum/thread-0240174274074453006-1-1.html",
        "clean_data": "在ATLAS 800设备使用ATLAS 300I Pro推理卡安装ASCEND CANN TOOLKIT 6 0 2 1时，遇到算法提示错误。已提供：   系统环境：Ubuntu 5 4 0 26内核   CANN版本：6 0 2 1   带故障截图及CANN安装类型说明  当前核心问题指向：确认CANN工具包版本与300I Pro推理卡的芯片型号 310P 310Q 的兼容性，建议检查官方适配列表，重点关注驱动 内核 系统版本的组合匹配，以及算法依赖架构的建立状态。",
        "created_at": "2025-02-07T01:27:54+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-02-07T06:32:27+08:00"
    },
    {
        "id": 607,
        "source_id": "20787549",
        "title": "CVE-2025-1413",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2025-1413](https://nvd.nist.gov/vuln/detail/CVE-2025-1413)\n漏洞归属组件：resolve\n漏洞归属的版本：1.22.8\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nDaVinci Resolve on MacOS was found to be installed with incorrect file permissions (rwxrwxrwx). This is inconsistent with standard macOS security practices, where applications should have drwxr-xr-x permissions. Incorrect permissions allow for Dylib Hijacking. Guest account, other users and applications can exploit this vulnerability for privilege escalation. This issue affects DaVinci Resolve on MacOS in versions before 19.1.3.\n\n漏洞公开时间：2025-02-28 17:15:11\n漏洞创建时间：2025-06-09 10:10:56\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2025-1413\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDJRX",
        "clean_data": "CVE 2025 1413：DaVinci Resolve for MacOS 19 1 3前版本因权限设置不当 rwxrwxrwx 偏离drwxr xr x标准，存在Dylib Hijacking漏洞，允许guest账户权限提升。",
        "created_at": "2025-06-09T10:10:56+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T10:10:56+08:00"
    },
    {
        "id": 608,
        "source_id": "20787555",
        "title": "CVE-2024-45590",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-45590](https://nvd.nist.gov/vuln/detail/CVE-2024-45590)\n漏洞归属组件：body-parser\n漏洞归属的版本：1.20.3\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nbody-parser is Node.js body parsing middleware. body-parser &lt;1.20.3 is vulnerable to denial of service when url encoding is enabled. A malicious actor using a specially crafted payload could flood the server with a large number of requests, resulting in denial of service. This issue is patched in 1.20.3.\n\n漏洞公开时间：2024-09-11 00:15:21\n漏洞创建时间：2025-06-09 10:11:01\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-45590\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDJS3",
        "clean_data": "CVE 2024 45590  Node js中间件body parser在1 20 3版本前，因启用URL编码解析功能存在DoS漏洞。攻击者可构造大量请求耗尽服务器资源，该问题已在1 20 3中修复，建议用户升级至最新版本。",
        "created_at": "2025-06-09T10:11:01+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T10:11:02+08:00"
    },
    {
        "id": 611,
        "source_id": "20790776",
        "title": "CVE-2023-24580",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-24580](https://nvd.nist.gov/vuln/detail/CVE-2023-24580)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nAn issue was discovered in the Multipart Request Parser in Django 3.2 before 3.2.18, 4.0 before 4.0.10, and 4.1 before 4.1.7. Passing certain inputs (e.g., an excessive number of parts) to multipart forms could result in too many open files or memory exhaustion, and provided a potential vector for a denial-of-service attack.\n\n漏洞公开时间：2023-02-15 09:15:10\n漏洞创建时间：2025-06-09 12:11:19\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-24580\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDM9K",
        "clean_data": "标题：CVE 2023 24580   问题：Django 3 2 7中multipart request parser因处理大量文件部分导致DOS攻击，如何修复？    解析输出满足以下要求：   1  保留核心组件 Django 、版本 3 2 7 、攻击类型 DOS攻击 、触发条件 大量文件部分处理    2  使用疑问句形式直观关联标题内容   3  去除CVSS评分数据 非关键 ，保留最简漏洞特征描述",
        "created_at": "2025-06-09T12:11:19+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T12:11:19+08:00"
    },
    {
        "id": 613,
        "source_id": "20790928",
        "title": "CVE-2023-23969",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2023-23969](https://nvd.nist.gov/vuln/detail/CVE-2023-23969)\n漏洞归属组件：django\n漏洞归属的版本：3.2.7\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nIn Django 3.2 before 3.2.17, 4.0 before 4.0.9, and 4.1 before 4.1.6, the parsed values of Accept-Language headers are cached in order to avoid repetitive parsing. This leads to a potential denial-of-service vector via excessive memory usage if the raw value of Accept-Language headers is very large.\n\n漏洞公开时间：2023-02-02 03:15:08\n漏洞创建时间：2025-06-09 12:40:55\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2023-23969\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDMDS",
        "clean_data": "CVE 2023 23969：Django 3 2 7因缓存Accept Language头解析值导致内存过载，存在拒绝服务漏洞。建议升级至3 2 17、4 0 9或4 1 6及以上版本。",
        "created_at": "2025-06-09T12:40:55+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T12:40:55+08:00"
    },
    {
        "id": 616,
        "source_id": "20795229",
        "title": "HandWritingTrainAndInfer中python3 main.py步骤报错",
        "body": "一、问题现象（附报错日志上下文）：\r\n香橙派鲲鹏pro开发板刷入ai pro开发板的Ubuntu镜像后部署该案例时在训练步骤报错\r\n![输入图片说明](https://foruda.gitee.com/images/1749455713234364920/264d349f_11448268.png \"测试运行main.png\")\r\n\r\n已经提前测试ACLHelloWorld验证acl库安装成功\r\n![输入图片说明](https://foruda.gitee.com/images/1749456250328354658/fe9571a5_11448268.png \"测试acl库.png\")\r\n\r\n二、软件版本:\r\n-- CANN 版本 7.0.0 \r\n--Tensorflow/Pytorch/MindSpore 版本:Pytorch 2.1.0\r\n--Python 版本 (e.g., Python 3.7.5):Python3.9.23\r\n--操作系统版本 (e.g., Ubuntu 18.04):Ubuntu22.04\r\n![输入图片说明](https://foruda.gitee.com/images/1749455762741754204/36ad8113_11448268.png \"固件驱动和CANN版本.png\")\r\n![输入图片说明](https://foruda.gitee.com/images/1749455929024773010/5c98a645_11448268.png \"python&torch&ubuntu版本.png\")\r\n三、测试步骤：\r\n\r\n设置环境变量减小算子编译内存占用。\r\nexport TE_PARALLEL_COMPILER=1\r\nexport MAX_COMPILE_CORE_NUMBER=1\r\n\r\n运行训练脚本。\r\npython3 main.py",
        "url": "https://gitee.com/ascend/EdgeAndRobotics/issues/ICDPP9",
        "clean_data": "HandWritingTrainAndInfer训练脚本执行报错：在Ubuntu22 04 CANN7 0 0 PyTorch2 1 0 Python3 9 23环境下，设置编译资源限制环境变量后仍存在运行时错误，指示需排查PyTorch版本与CANN的兼容性及代码环境适配问题。   问题诊断路径：关键点为操作系统及三方库版本组合异常，建议优先确认CANN7 0 0官方兼容的PyTorch版本。次级排查方向是检查main py中手写算子实现是否与当前DEVICE平台匹配，或是否存在手动编译转换流程缺失",
        "created_at": "2025-06-09T16:04:36+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": true,
        "updated_at": "2025-06-11T10:09:57+08:00"
    },
    {
        "id": 617,
        "source_id": "20796212",
        "title": "香橙派鲲鹏pro使用openEuler镜像实现Yolov8n目标识别快速迁移实例时卡住",
        "body": "一、问题现象（附报错日志上下文）：\r\n参考以下链接\r\nhttps://zhuanlan.zhihu.com/p/693402190\r\nhttps://blog.csdn.net/mao_hui_fei/article/details/139356518\r\n\r\n在转换pt模型->onnx模型->om模型成功后，运行python3 main.py --model yolov8n.om时终端输出卡在acl init success\r\n![输入图片说明](https://foruda.gitee.com/images/1749457274811292642/11720e92_11448268.png \"测试运行.png\")\r\n\r\n在使用香橙派鲲鹏pro并刷入ai pro的ubuntu22.04镜像时可以完全根据手上已有的步骤复现成功\r\n![输入图片说明](https://foruda.gitee.com/images/1749457326884462806/5a6b031e_11448268.png \"屏幕截图\")\r\n\r\n由于openEuler没有自带conda环境，所以所有依赖均手动安装，并且成功运行到最后一步为止，使用python3.9的py39环境替代HwHiAiUser用户的base环境。\r\n![输入图片说明](https://foruda.gitee.com/images/1749457432543076124/7fa2dd2c_11448268.png \"create py39.png\")\r\n\r\n二、软件版本:\r\n-- CANN 版本 (e.g., CANN 3.0.x，5.x.x):  8.0.RC3.alpha003\r\n--Tensorflow/Pytorch/MindSpore 版本:     torch 2.7.1\r\n--Python 版本 (e.g., Python 3.7.5):      Python 3.9.23\r\n--操作系统版本 (e.g., Ubuntu 18.04):      openEuler 22.03\r\n\r\n三、测试步骤：\r\n将yolov8.pt模型转换为om模型\r\n![输入图片说明](https://foruda.gitee.com/images/1749458002515005207/c0dff840_11448268.png \"trans2.png\")\r\n\r\n添加导入 from ais_bench.infer.interface import InferSession\r\n模型导入修改为 model = InferSession(device_id=0, model_path=\"yolov8n.om\") \r\n使用命令运行 python3 main.py --model yolov8n.om\r\n调用修改后的ultralytics/examples//YOLOv8-OpenCV-ONNX-Python/main.py文件\r\n\r\nmain.py如下\r\n\r\n```\r\nimport argparse\r\nfrom typing import Any, Dict, List\r\n\r\nimport cv2.dnn\r\nimport numpy as np\r\n\r\nfrom ultralytics.utils import ASSETS, YAML\r\nfrom ultralytics.utils.checks import check_yaml\r\n\r\nfrom ais_bench.infer.interface import InferSession\r\n\r\nCLASSES = YAML.load(check_yaml(\"coco8.yaml\"))[\"names\"]\r\ncolors = np.random.uniform(0, 255, size=(len(CLASSES), 3))\r\n\r\n\r\ndef draw_bounding_box(\r\n    img: np.ndarray, class_id: int, confidence: float, x: int, y: int, x_plus_w: int, y_plus_h: int\r\n) -> None:\r\n    \"\"\"\r\n    Draw bounding boxes on the input image based on the provided arguments.\r\n\r\n    Args:\r\n        img (np.ndarray): The input image to draw the bounding box on.\r\n        class_id (int): Class ID of the detected object.\r\n        confidence (float): Confidence score of the detected object.\r\n        x (int): X-coordinate of the top-left corner of the bounding box.\r\n        y (int): Y-coordinate of the top-left corner of the bounding box.\r\n        x_plus_w (int): X-coordinate of the bottom-right corner of the bounding box.\r\n        y_plus_h (int): Y-coordinate of the bottom-right corner of the bounding box.\r\n    \"\"\"\r\n    label = f\"{CLASSES[class_id]} ({confidence:.2f})\"\r\n    color = colors[class_id]\r\n    cv2.rectangle(img, (x, y), (x_plus_w, y_plus_h), color, 2)\r\n    cv2.putText(img, label, (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\r\n\r\ndef main(onnx_model: str, input_image: str) -> List[Dict[str, Any]]:\r\n    \"\"\"\r\n    Load ONNX model, perform inference, draw bounding boxes, and display the output image.\r\n\r\n    Args:\r\n        onnx_model (str): Path to the ONNX model.\r\n        input_image (str): Path to the input image.\r\n\r\n    Returns:\r\n        (List[Dict[str, Any]]): List of dictionaries containing detection information such as class_id, class_name,\r\n            confidence, box coordinates, and scale factor.\r\n    \"\"\"\r\n    # Load the ONNX model\r\n    #model: cv2.dnn.Net = cv2.dnn.readNetFromONNX(onnx_model)\r\n    model = InferSession(device_id=0, model_path=\"yolov8n.om\")\r\n\r\n    # Read the input image\r\n    original_image: np.ndarray = cv2.imread(input_image)\r\n    [height, width, _] = original_image.shape\r\n\r\n    # Prepare a square image for inference\r\n    length = max((height, width))\r\n    image = np.zeros((length, length, 3), np.uint8)\r\n    image[0:height, 0:width] = original_image\r\n\r\n    # Calculate scale factor\r\n    scale = length / 640\r\n\r\n    # Preprocess the image and prepare blob for model\r\n    blob = cv2.dnn.blobFromImage(image, scalefactor=1 / 255, size=(640, 640), swapRB=True)\r\n    model.setInput(blob)\r\n\r\n    # Perform inference\r\n    outputs = model.forward()\r\n\r\n    # Prepare output array\r\n    outputs = np.array([cv2.transpose(outputs[0])])\r\n    rows = outputs.shape[1]\r\n    boxes = []\r\n    scores = []\r\n    class_ids = []\r\n\r\n    # Iterate through output to collect bounding boxes, confidence scores, and class IDs\r\n    for i in range(rows):\r\n        classes_scores = outputs[0][i][4:]\r\n        (minScore, maxScore, minClassLoc, (x, maxClassIndex)) = cv2.minMaxLoc(classes_scores)\r\n        if maxScore >= 0.25:\r\n            box = [\r\n                outputs[0][i][0] - (0.5 * outputs[0][i][2]),  # x center - width/2 = left x\r\n                outputs[0][i][1] - (0.5 * outputs[0][i][3]),  # y center - height/2 = top y\r\n                outputs[0][i][2],  # width\r\n                outputs[0][i][3],  # height\r\n            ]\r\n            boxes.append(box)\r\n            scores.append(maxScore)\r\n            class_ids.append(maxClassIndex)\r\n\r\n    # Apply NMS (Non-maximum suppression)\r\n    result_boxes = cv2.dnn.NMSBoxes(boxes, scores, 0.25, 0.45, 0.5)\r\n\r\n    detections = []\r\n    for i in range(len(result_boxes)):\r\n        index = result_boxes[i]\r\n        box = boxes[index]\r\n        detection = {\r\n            \"class_id\": class_ids[index],\r\n            \"class_name\": CLASSES[class_ids[index]],\r\n            \"confidence\": scores[index],\r\n            \"box\": box,\r\n            \"scale\": scale,\r\n        }\r\n        detections.append(detection)\r\n        draw_bounding_box(\r\n            original_image,\r\n            class_ids[index],\r\n            scores[index],\r\n            round(box[0] * scale),\r\n            round(box[1] * scale),\r\n            round((box[0] + box[2]) * scale),\r\n            round((box[1] + box[3]) * scale),\r\n        )\r\n\r\n    # Display the image with bounding boxes\r\n    cv2.imshow(\"image\", original_image)\r\n    cv2.waitKey(0)\r\n    cv2.destroyAllWindows()\r\n\r\n    return detections\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument(\"--model\", default=\"yolov8n.onnx\", help=\"Input your ONNX model.\")\r\n    parser.add_argument(\"--img\", default=str(ASSETS / \"bus.jpg\"), help=\"Path to input image.\")\r\n    args = parser.parse_args()\r\n    main(args.model, args.img)\r\n\r\n\r\n\r\n```\r\n\r\n",
        "url": "https://gitee.com/ascend/samples/issues/ICDQGK",
        "clean_data": "香橙派鲲鹏Pro使用openEuler镜像运行YOLOv8n目标识别实例卡在acl init success      在openEuler 22 03系统下，使用CANN 8 0 RC3 alpha003和 InferSession 加载yolov8n om模型后，程序在打印 acl init success 后停滞无响应。对比同环境配置，Ubuntu22 04镜像可正常运行，推测问题与openEuler环境中的依赖安装或AscendCL接口调用兼容性有关。建议检查以下要点：   1    依赖完整性  ：确认手动安装的第三方库 如OpenCV、Python包 版本与AscendCL兼容。   2    AscendCL配置  ：检查 InferSession 初始化参数、环境变量 如 LD LIBRARY PATH  及设备ID有效性。   3    模型接口逻辑  ：验证代码是否包含必要的异步处理 如 model forward   需配合队列管理 。",
        "created_at": "2025-06-09T16:39:54+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T09:45:09+08:00"
    },
    {
        "id": 132,
        "source_id": "0237181022913671008",
        "title": "GroundingDino在Altas300上模型转换失败",
        "body": "<p>使用 Altas300 对 GroundingDino 进行模型部署，导出的 onnx 模型为动态模型，在转换为 om 模型时，固定了其尺寸。</p> <ul> <li>模型转换指令为<pre><code class=\"language-bash\">atc --model=groundingdino_swint_ogc.onnx --framework=5 --output=groundingdino --soc_version=Ascend310 --input_shape=&quot;img:1,3,800,1200;input_ids:1,6;attention_mask:1,6;position_ids:1,6;token_type_ids:1,6;text_token_mask:1,6,6&quot;\n</code></pre> </li> <li>在模型转换过程中的输出为：<pre><code class=\"language-bash\">ATC start working now, please wait for a moment.\n...\nATC run failed, Please check the detail log, Try 'atc --help' for more information\nE10042: 2025-04-26-11:53:07.780.080 GenerateOfflineModel execute failed.\n        TraceBack (most recent call last):\n        op[/Concat_3], the input shape dims should be equal except merge axis,shapes:[[1, ], [1, 1, ], ]axis:0[FUNC:ConcatInferShapeCommon][FILE:split_combination_ops.cc][LINE:1213]\n        Call InferShapeAndType for node:/Concat_3(ConcatD) failed[FUNC:Infer][FILE:infershape_pass.cc][LINE:120]\n        process pass InferShapePass on node:/Concat_3 failed, ret:4294967295[FUNC:RunPassesOnNode][FILE:base_pass.cc][LINE:570]\n        build graph failed, graph id:0, ret:1343242270[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1615]\n        GenerateOfflineModel execute failed.\n</code></pre> </li> </ul> <p>我在论坛上查找了相似问题，最相似的问题是 “华为atlas 200idka2和atlas 200dk部署groundingdino出现的问题” 以及 “[GroundingDINO]ONNX模型转OM模型过程中遇到input shape dim未对齐问题” 等。前者似乎成功解决了这个问题，但是显示帖子被删除，后者版主回复了两个参考思路。</p> <ul> <li>针对第一个思路，使用 <code>onnxsim</code> 进行优化后转换，爆同样的错误。</li> <li>针对第二个思路，我使用下方代码删除了 <code>concat 3 4 5 6</code> 四个算子的 <code>unsqueeze</code> 节点，在进行模型转换时，没有报 <code>concat</code> 算子问题，但是爆了几百个算子不支持问题，报错信息类似于 <code>No supported Ops kernel and engine are found for [/encoder/blocks.1/attn/Einsum], optype [Einsum]</code><pre><code>import onnx\n\n# concat 3 (3 4 5)\n# concat 4 (6 7 8)\n# concat 6 (9 10)\n# concat 7 (11 12)\n# concat 9 (13)\n# concat 10 (14)\n# concat 11 (15 16)\n# concat 13 (17 18 19 20 21 22)\n# concat 14 (23 24 25 26 27 28)\n\ndef main(node_name_del, node_name_main):\n    model = onnx.load(&quot;groundingdino_swint_ogc_modified.onnx&quot;)\n    graph = model.graph\n\n    # 创建映射：unsqueeze_output → 原始 input\n    unsqueeze_map = {}\n\n    # 记录要删除的节点\n    nodes_to_remove = []\n\n    for node in graph.node:\n        if node.name in node_name_del:\n            unsqueeze_map[node.output[0]] = node.input[0]\n            nodes_to_remove.append(node)\n\n    # 替换 Concat_3 中的输入\n    for node in graph.node:\n        if node.name == node_name_main:\n            node.input[:] = [unsqueeze_map.get(inp, inp) for inp in node.input]\n\n    # 移除 unsqueeze 节点\n    for node in nodes_to_remove:\n        graph.node.remove(node)\n\n    onnx.save(model, &quot;groundingdino_swint_ogc_modified.onnx&quot;)\n\nnode_name_main_list = [&quot;/Concat_3&quot;, &quot;/Concat_4&quot;, &quot;/Concat_6&quot;, &quot;/Concat_7&quot;] # &quot;/Concat_9&quot;, &quot;/Concat_10&quot;, &quot;/Concat_11&quot;, &quot;/Concat_13&quot;, &quot;/Concat_14&quot;\nnode_name_del_dict = {\n    &quot;/Concat_3&quot;: [&quot;/Unsqueeze_3&quot;, &quot;/Unsqueeze_4&quot;, &quot;/Unsqueeze_5&quot;],\n    &quot;/Concat_4&quot;: [&quot;/Unsqueeze_6&quot;, &quot;/Unsqueeze_7&quot;, &quot;/Unsqueeze_8&quot;],\n    &quot;/Concat_6&quot;: [&quot;/Unsqueeze_9&quot;, &quot;/Unsqueeze_10&quot;],\n    &quot;/Concat_7&quot;: [&quot;/Unsqueeze_11&quot;, &quot;/Unsqueeze_12&quot;],\n    &quot;/Concat_9&quot;: [&quot;/Unsqueeze_13&quot;],\n    &quot;/Concat_10&quot;: [&quot;/Unsqueeze_14&quot;],\n    &quot;/Concat_11&quot;: [&quot;/Unsqueeze_15&quot;, &quot;/Unsqueeze_16&quot;],\n    &quot;/Concat_13&quot;: [&quot;/Unsqueeze_17&quot;, &quot;/Unsqueeze_18&quot;, &quot;/Unsqueeze_19&quot;, &quot;/Unsqueeze_20&quot;, &quot;/Unsqueeze_21&quot;, &quot;/Unsqueeze_22&quot;],\n    &quot;/Concat_14&quot;: [&quot;/Unsqueeze_23&quot;, &quot;/Unsqueeze_24&quot;, &quot;/Unsqueeze_25&quot;, &quot;/Unsqueeze_26&quot;, &quot;/Unsqueeze_27&quot;, &quot;/Unsqueeze_28&quot;],\n}\nfor node_name_main in node_name_main_list:\n    print(f&quot;Processing {node_name_main}...&quot;)\n    node_name_del = node_name_del_dict[node_name_main]\n    main(node_name_del, node_name_main)\n</code></pre> </li> </ul> ",
        "url": "https://www.hiascend.com/forum/thread-0237181022913671008-1-1.html",
        "clean_data": "GroundingDino在Atlas300上ATC转OM模型失败：Concat轴维度不统一导致联结推理错误   1  模型转换时人为固定onnx动态维度后仍报错      失败节点  Concat 3维度冲突  1    1 1         报错代码链  ConcatInferShapeCommon 1213  InfershapePass 120  base pass cc 570  2  测试过两种优化方案：     1  onnxsim简化模型   仍存Concat维度统一问题     2  移除Unsqueeze前驱节点   消除Concat问题但出现84个不支持算子 Einsum等  3  模型来源与转换参数：      ONNX路径 atc   input shape 各层硬编码固定      SOC版本 Ascend310      关键修改代码示例已提供  核心矛盾：动态模型硬编码固定尺寸后，Concat层张量拓扑结构仍存在非合并轴的维度差异。",
        "created_at": "2025-04-26T04:08:34+08:00",
        "topic_summary": "开发者在模型转换OM格式时在转换过程和推理时经常遇到报错，需要寻求支持",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-07T10:01:19+08:00"
    },
    {
        "id": 134,
        "source_id": "0201179571420801181",
        "title": "【解决方案】【FAQ】解决stub library cannot be used for execution报错问题",
        "body": "<div class=\"cke-article\"><h1>问题现象：</h1>  <p>执行ACL推理代码产生报错</p>  <p>[ERROR]: stub library cannot be used for execution, please check your environment variables and compilation options to make sure you use the correct ACL library.</p>  <h1>问题原因：</h1>  <p>未设置正确环境变量或动态库链接错误</p>  <h1>解决方案：</h1>  <p>Ⅰ：执行CANN包内置的环境变量脚本，重新进行编译</p>  <pre><br><code class=\"language-javascript\">cd /usr/local/Ascend/ascend-toolkit<br>source set_env.sh</code></pre>  <p>Ⅱ：若通过方案I未解决</p>  <p>执行readelf -a  命令，查看是否存在RPATH，由于RPATH的优先级要高于LD_LIBRARY_PATH，需要跳过指定的错误的Libary rpath</p>  <pre><br><code class=\"language-javascript\">readelf -a main //main为编译好的可执行文件</code></pre>  <p>若存在RPATH则需要将set(CMAKE_SKIP_RPATH TRUE)添加在CMakeLists.txt中<br> <span class=\"easyimage easyimage-full\"><img alt=\"cke_26344.png\" src=\"cid:pic_0\"></span></p>  <p>重新编译可执行文件</p>  <p></p>  <h3>若依旧无法解决您的问题，可以到工单及论坛反馈您的问题</h3></div>",
        "url": "https://www.hiascend.com/forum/thread-0201179571420801181-1-1.html",
        "clean_data": "解决方案 解决ACL推理代码报 stub library cannot be used for execution   当执行ACL推理代码出现该错误时，可能由环境变量或动态库路径配置错误导致： 1  优先执行CANN环境配置脚本并重新编译           cd  usr local Ascend ascend toolkit    source set env sh         2  若仍存在RPATH冲突：      通过 readelf  a main 检查可执行文件是否存在错误RPATH      在CMakeLists txt中添加  set CMAKE SKIP RPATH TRUE        重新编译可执行文件  若问题持续未解决，建议携带错误日志反馈至CANN社区。",
        "created_at": "2025-04-09T08:57:01+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-04-10T02:52:15+08:00"
    },
    {
        "id": 184,
        "source_id": "0215172418221605255",
        "title": "昇腾生态下，类似 nvitop 这样的 TUI",
        "body": "<div class=\"cke-article\"><p><span class=\"easyimage easyimage-full\"><img alt=\"image.png\" src=\"cid:pic_0\"></span></p>  <p></p>  <h3 style=\"box-sizing: border-box;\">快速入门</h3>  <p>使用 pip 安装 nputop，如下所示。</p>  <pre><br><code class=\"language-bash\">pip install nputop</code></pre>  <pre style=\"box-sizing: border-box;font-size: 13.6px;min-height: 52.0px;overflow: auto;word-break: normal;\">\n\n要启动一个 nputop 实例，请运行以下命令：\n</pre>  <pre><br><code class=\"language-bash\">nputop</code></pre></div>",
        "url": "https://www.hiascend.com/forum/thread-0215172418221605255-1-1.html",
        "clean_data": "昇腾生态实时资源监控TUI工具推荐  昇腾AI芯片目前官方未提供图形仪表盘工具 nputop实为第三方非原生工具 ，推荐使用AICPU Viewer或CANN命令行工具实现类似功能：   命令行监控： aicpu    am    npu smi  查看设备状态和资源使用   大屏监控：AICPU Viewer提供Web界面可视化资源管理和能效分析  注：社区开发者可通过CANN提供的诊断工具组合实现动态资源监控。",
        "created_at": "2025-01-16T13:57:02+08:00",
        "topic_summary": "开发者在编译、安装、调试和开发环境搭建过程中，因为版本、路径、权限等原因导致安装失败",
        "topic_closed": false,
        "source_type": "forum",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-01-16T13:57:02+08:00"
    },
    {
        "id": 620,
        "source_id": "20798894",
        "title": "CVE-2024-6827",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2024-6827](https://nvd.nist.gov/vuln/detail/CVE-2024-6827)\n漏洞归属组件：gunicorn\n漏洞归属的版本：20.1.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nGunicorn version 21.2.0 does not properly validate the value of the _x27;Transfer-Encoding_x27; header as specified in the RFC standards, which leads to the default fallback method of _x27;Content-Length,_x27; making it vulnerable to TE.CL request smuggling. This vulnerability can lead to cache poisoning, data exposure, session manipulation, SSRF, XSS, DoS, data integrity compromise, security bypass, information leakage, and business logic abuse.\n\n漏洞公开时间：2025-03-20 18:15:33\n漏洞创建时间：2025-06-09 19:40:19\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2024-6827\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDSJ2",
        "clean_data": "CVE 2024 6827：Gunicorn请求走私漏洞     Gunicorn 20 1 0因未正确校验 Transfer Encoding 请求头，导致默认回退至 Content Length ，存在TE CL请求走私风险，可能引发缓存污染、数据泄露、会话操控等攻击。建议升级至官方修复版本 如21 2 0以上 。漏洞详情请参考 NIST  https   nvd nist gov vuln detail CVE 2024 6827 。",
        "created_at": "2025-06-09T19:40:20+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T19:40:20+08:00"
    },
    {
        "id": 621,
        "source_id": "20799315",
        "title": "CVE-2022-4778",
        "body": "\n一、漏洞信息\n漏洞编号：[CVE-2022-4778](https://nvd.nist.gov/vuln/detail/CVE-2022-4778)\n漏洞归属组件：streamx\n漏洞归属的版本：2.21.0\nCVSS V3分值：\n&emsp;BaseScore: N/A None\n&emsp;Vector: N/A\n\n漏洞简述：\nStreamX applications from versions 6.02.01 to 6.04.34 are affected by a path traversal vulnerability that allows authenticated users to get unauthorized access to files on the server_x27;s filesystem.\nStreamX applications using StreamView HTML component with the public web server feature activated are affected.\n\n漏洞公开时间：2022-12-29 08:15:08\n漏洞创建时间：2025-06-09 20:40:07\n漏洞详情参考链接：\nhttps://nvd.nist.gov/vuln/detail/CVE-2022-4778\n",
        "url": "https://gitee.com/ascend/ai_assistant/issues/ICDSUR",
        "clean_data": "CVE 2022 4778：streamx 2 21 0版本若启用StreamView HTML组件及公共Web服务器功能，将导致认证用户可利用路径遍历漏洞未授权访问服务器文件系统。",
        "created_at": "2025-06-09T20:40:08+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-09T20:40:08+08:00"
    },
    {
        "id": 627,
        "source_id": "20817416",
        "title": "支持数据的非连续拷出",
        "body": "一、需求场景&价值\r\n在大模型中，按照index取值、计算等操作十分常见，例如scatter_add, one hot embedding等。以scatter add为例，计算公式如下：\r\ndst[index[i]] += src[i]\r\n\r\n实现kernel示例如下：\r\n```\r\n@triton.jit\r\ndef scatter_add_kernel(\r\n    input_ptr,      # 输入张量指针\r\n    index_ptr,      # 索引张量指针\r\n    source_ptr,     # 源张量指针\r\n    output_ptr,     # 输出张量指针\r\n    index_len: tl.constexpr,      # 源张量维度0大小\r\n    BLOCK_SIZE: tl.constexpr,  # 线程块大小\r\n):\r\n    pid = tl.program_id(0)\r\n    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\r\n    mask = offsets < index_len\r\n    idx = tl.load(index_ptr + offsets, mask=mask, other=0)\r\n    source_val = tl.load(source_ptr + offsets, mask=mask, other=0.0)\r\n    input_offset = tl.arange(0, BLOCK_SIZE)\r\n    input_offset += idx\r\n    tl.atomic_add(output_ptr + input_offset, source_val)\r\n```\r\n在进行aotomic add时，由于input_offset为外部传入的index，在实际执行时会报错。\r\n\r\n\r\n二、需求建议实现的规格\r\n支持数据的非连续拷出。\r\n\r\n三、竞品比较（选填）",
        "url": "https://gitee.com/ascend/triton-ascend/issues/ICE6TK",
        "clean_data": "标题：支持数据的非连续拷出   描述：Triton内核atomic add操作报错，因input offset为外部传入的index导致无法解析连续偏移量。需支持根据动态计算的索引进行非连续数据拷贝，实现类似scatter add的原子累加功能。",
        "created_at": "2025-06-11T09:50:22+08:00",
        "topic_summary": "",
        "topic_closed": false,
        "source_type": "issue",
        "history": "[]",
        "source_closed": false,
        "updated_at": "2025-06-11T09:50:22+08:00"
    }
]