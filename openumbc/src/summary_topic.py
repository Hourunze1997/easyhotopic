import requests
import json
import pandas as pd
from tqdm import tqdm
from openai import OpenAI
import time

def llm_summary(content):
    system_prompt = f"""
    - Role: ä¸“ä¸šçš„BMCä¸“å®¶å’ŒæŠ€æœ¯æ–‡æ¡£åˆ†æä¸“å®¶
    - Background: ç”¨æˆ·éœ€è¦ä»æä¾›çš„æ–‡æ¡£å†…å®¹ä¸­æç‚¼å‡ºBMCé¢†åŸŸå¼€å‘è€…å…³å¿ƒæˆ–äºŸéœ€è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼Œè¿™è¡¨æ˜ç”¨æˆ·å¯èƒ½æ­£åœ¨å¤„ç†ä¸BMCç›¸å…³çš„æŠ€æœ¯æ–‡æ¡£ï¼Œéœ€è¦å¿«é€Ÿå‡†ç¡®åœ°æå–å…³é”®ä¿¡æ¯ä»¥æŒ‡å¯¼å¼€å‘å·¥ä½œã€‚
    - Profile: ä½ æ˜¯ä¸€ä½åœ¨BMCï¼ˆBaseboard Management Controllerï¼ŒåŸºæ¿ç®¡ç†æ§åˆ¶å™¨ï¼‰é¢†åŸŸæ‹¥æœ‰æ·±åšä¸“ä¸šçŸ¥è¯†çš„ä¸“å®¶ï¼ŒåŒæ—¶ä¹Ÿæ“…é•¿æŠ€æœ¯æ–‡æ¡£çš„åˆ†æå’Œè§£è¯»ï¼Œèƒ½å¤Ÿç²¾å‡†åœ°è¯†åˆ«å‡ºæ–‡æ¡£ä¸­å¯¹å¼€å‘è€…å…·æœ‰é‡è¦æ„ä¹‰çš„é—®é¢˜ã€‚
    - Skills: ä½ å…·å¤‡å¯¹BMCæŠ€æœ¯çš„å…¨é¢ç†è§£ï¼ŒåŒ…æ‹¬ç¡¬ä»¶æ¶æ„ã€å›ºä»¶å¼€å‘ã€åè®®äº¤äº’ç­‰ï¼Œä»¥åŠå¯¹æŠ€æœ¯æ–‡æ¡£çš„æ·±åº¦åˆ†æèƒ½åŠ›ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®šä½å…³é”®ä¿¡æ¯å¹¶æç‚¼å‡ºæ ¸å¿ƒé—®é¢˜ã€‚
    - Goals: ä»æä¾›çš„æ–‡æ¡£å†…å®¹ä¸­ç²¾å‡†æç‚¼å‡ºBMCé¢†åŸŸå¼€å‘è€…å…³å¿ƒæˆ–äºŸéœ€è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚
    - Constrains: é—®é¢˜è¡¨è¿°éœ€èšç„¦å…·ä½“æ“ä½œåœºæ™¯ï¼ŒåŒ…å«æ˜ç¡®æŠ€æœ¯ä¸»ä½“ï¼Œä½“ç°å—ä¼—ï¼Œå­—æ•°æ§åˆ¶åœ¨30ä»¥å†…ï¼Œé‡‡ç”¨é™ˆè¿°å¥å‘ˆç°ï¼Œè¿”å›ç»“æœç”¨<summary>æ ‡ç­¾åŒ…è£¹ã€‚
    - OutputFormat: ä¸€å¥è¯ï¼Œç”¨<summary>æ ‡ç­¾åŒ…è£¹ã€‚
    - Workflow:
    1. ä»”ç»†é˜…è¯»å¹¶ç†è§£æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œè¯†åˆ«ä¸BMCå¼€å‘ç›¸å…³çš„éƒ¨åˆ†ã€‚
    2. ç¡®å®šæ–‡æ¡£ä¸­æ¶‰åŠçš„å…·ä½“æ“ä½œåœºæ™¯å’Œæ˜ç¡®æŠ€æœ¯ä¸»ä½“ã€‚
    3. æ ¹æ®BMCå¼€å‘è€…çš„è§†è§’ï¼Œæç‚¼å‡ºäºŸéœ€è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼Œå¹¶ç¡®ä¿è¡¨è¿°ç¬¦åˆè¦æ±‚ã€‚
    4. è¿”å›ç»“æœï¼Œä¿è¯åªæœ‰ä¸€ä¸ª<summary>æ ‡ç­¾åŒ…è£¹ï¼Œç»“æœè¦†ç›–å…±æ€§æè¿°ã€‚
    - Examples:
    - ä¾‹å­1ï¼šBMCå›ºä»¶å‡çº§ä¸­å¦‚ä½•ç¡®ä¿ç¡¬ä»¶å…¼å®¹æ€§
    - ä¾‹å­2ï¼šBMCå¼€å‘è€…å¦‚ä½•ä¼˜åŒ–å›ºä»¶æ€§èƒ½
    - ä¾‹å­3ï¼šBMCå›ºä»¶å¼€å‘ä¸­å¦‚ä½•é¿å…ç¡¬ä»¶å…¼å®¹æ€§ç¼ºé™·
    """
    start_time = time.time()
    openai_api_key = "sk-xxxx"
    openai_api_base = "https://api.siliconflow.cn/v1"
    client = OpenAI(
        api_key=openai_api_key,
        base_url=openai_api_base,
    )
    chat_outputs = client.chat.completions.create(
        model="Qwen/Qwen3-235B-A22B",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": content},
        ]
    )
    # print(chat_outputs.choices[0].message.content)
    end_time = time.time()
    elapsed_time= end_time - start_time
    print(f"exec time: {elapsed_time} s")
    return chat_outputs.choices[0].message.content

def merge_keywords(data):
    merged_keywords = {}
    for group_id, keyword_lists in data.items():
        # Flatten the list of lists into a single list of keywords
        all_keywords = [keyword for keyword_list in keyword_lists for keyword in keyword_list]
        # Remove duplicates by converting to a set and back to a list
        unique_keywords = list(set(all_keywords))
        merged_keywords[group_id] = unique_keywords

    return merged_keywords

def process_csv():
    input_file = "../data/topic_docs_merged_new.xlsx"
    tpoic_path = "../data/topic_info_merged_new.xlsx"
    output_file = "../data/topic_output_merged_new.xlsx"
    topics = {}
    hot_keys = {}
    topic_info = pd.read_excel(tpoic_path)
    for _, row in topic_info.iterrows():
        topic = str(row['Topic'])
        if topic == '-1':
            continue
        if topic not in topics:
            hot_keys[topic] = []
        hot_keys[topic].append((row['Aspect1'], row['Aspect1']))

    hot_keys = merge_keywords(hot_keys)
    print(hot_keys)
    df = pd.read_excel(input_file)
    for _, row in df.iterrows():
        topic = str(row['Topic'])
        if topic == '-1':
            continue
        if topic not in topics:
            topics[topic] = []
        topics[topic].append((row['Probability'], row['Document']))

    for topic in topics:
        topics[topic] = [content for _, content in sorted(
            topics[topic],
            key=lambda x: x[0],
            reverse=True
        )]
    # print(topics)
    summaries = {}
    with tqdm(topics.items(), desc="ğŸ“Š å¤„ç†è¿›åº¦", unit="topic", bar_format="{l_bar}{bar:20}{r_bar}") as pbar:
        for topic, contents in pbar:
            min_cluster = 15
            content_block = "\n".join(contents[:min_cluster])
            print(topic, len(contents), hot_keys[topic])
            hot_keys_topic = hot_keys[topic]
            content = f"""
            ä»¥ä¸‹æ˜¯ç¤¾åŒºå…³äºè¯¥çƒ­ç‚¹è¯é¢˜çš„å…³é”®è¯å’Œéƒ¨åˆ†å†…å®¹ï¼š
            å…³é”®è¯ï¼š{hot_keys_topic}
            å†…å®¹ï¼š{content_block}
            """
            # print(content)
            llm_summary_result = llm_summary(content)
            print(llm_summary_result)
            if '<summary>' in llm_summary_result:
                summary = llm_summary_result.split('<summary>')[1].split('</summary>')[0].strip()
                summaries[topic] = summary
    df['summary'] = df['Topic'].astype(str).apply(lambda x: summaries.get(x, ''))
    df.to_excel(output_file, index=False)
    topic_info['summary'] = topic_info['Topic'].astype(str).apply(lambda x: summaries.get(x, ''))
    topic_info.to_excel(tpoic_path, index=False)

if __name__ == "__main__":
    process_csv()
    # input_file = "../data/topic_docs_merged.xlsx"
    # df = pd.read_excel(input_file)
    # tpoic_path = "../data/topic_info_merged.xlsx"
    # topic_info = pd.read_excel(tpoic_path)
    # summaries = {}
    # for _, row in topic_info.iterrows():
    #     topic = str(row['Topic'])
    #     summary = row['summary']
    #     summaries[topic] = summary
    # print(summaries)
    # output_file = "../data/topic_output_merged.xlsx"
    # df['summary'] = df['Topic'].astype(str).apply(lambda x: summaries.get(x, ''))
    # df.to_excel(output_file, index=False)
